<html>
<head>
<title>Alife Newsletter</title>
<meta charset="UTF-8">
<link rel="alternate" type="application/rss+xml" title="Alife Newsletter RSS Feed" href="RSS.xml" />

<style>
  body {
         background-color:#f4f4f4;

       }

  .content {
    background-color:#ffffff;
    word-spacing:normal;
    max-width: 600px;
    margin: auto;
    margin-top: 100px;
    border: 1px solid black;
  }

  .header {
    background-color:#000000;
    color:#ffffff;
    max-width: 600px;
    padding: 20px 40px 40px 40px;
    margin: 0px;
  }

  .header img {
    max-width: 470px;
    margin-left: auto;
    margin-right: auto;
  }

  img {
    display: block;
    max-width: 550px;
    margin-left: auto;
    margin-right: auto;
  }

  h1 {
    margin-left: 20px;
    margin-right: 30px;
    font-size: 24px;
    font-family: Arial;
  }
  h2 {
    margin-left: 20px;
    margin-right: 30px;
    font-size: 18px;
    font-family: Arial;
  }
  h3 {
    margin-left: 20px;
    margin-right: 30px;
    font-size: 16px;
    font-family: Arial;
  }
  h4 {
    margin-left: 20px;
    margin-right: 30px;
    font-size: 14px;
    font-family: Arial;
  }
  p {
    color:#000000;
    font-family:Arial;
    font-size:13px; margin-left: 20px;
    margin-right: 30px;
    text-align: justify;
  }

  ul {text-align: justify; margin-left: 20px; margin-right: 30px }
  div {text-align: justify; margin-left: 20px; margin-right: 30px }
  li { color:#000000;font-family:Arial;font-size:13px; margin-left: 20px; margin-right: 30px }

  h1::before{
    content:'';
    position:relative;
    display:block;
    top:50%;
    height:2px;
    width: 500px;
    background:#000;
    margin-bottom: 15px;
    left:50%;
    z-index:1;
    -webkit-transform:translateX(-50%);
  }
</style>

</head>
<body>

  <div class="content">
    <div class="header">
      <h1>Alife News</h1>
      <h2>The Artificial Life Community Newsletter</h2>
      <img src="https://alife-newsletter.github.io/Newsletter/images/alifenewshead.png">
    </div>

<p><strong>Artificial Life Newsletter 009 -- [micro] organisms | cosms | scale</strong></p>
<h1 id="a-word-from-the-team">A word from the team</h1>
<p>Happy 2023, and welcome to the 9th issue of the Alife Newsletter!</p>
<p>For the first edition of 2023, we have some technical news: The newsletter now has an RSS feed! If you have an RSS reader, you can point it to <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">this link</a> to receive announcements of new editions of the newsletter. Give it a try!</p>
<p>The theme for this edition is "[micro] organisms | cosms | scale". For micro-organisms, we report on a novel idea for an wearable device that integrates living mold with electronics. For micro-cosms, we link a review of small programs that can generate complex worlds. And for micro-scale, we found a delightful art imagining the origins of life.</p>
<p>In adition, we have a paper review about life as information, and the syllabus of a new artificial life course, as well as CFP deadlines and announcements of PhD positions! We hope you find something that pique your interest.</p>
<p>As usual, we welcome contributions, ideas and suggestions to the newsletter at <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">this form</a>! In particular, we are specially interested in Master and PhD students who want to talk about their own research ideas. Do send us a line!</p>
<p>If you'd like to receive our news, you can subscribe by e-mail <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>, or by RSS <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">here</a>.</p>
<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>
<div class="toc">
<ul>
<li><a href="#paper-integrating-living-organisms-in-devices-to-implement-care-based-interactions">Paper: “Integrating Living Organisms in Devices to Implement Care-based Interactions”</a></li>
<li><a href="#alife-paper-review-the-world-as-evolving-information">ALife Paper Review: The World as Evolving Information</a></li>
<li><a href="#a-new-course-on-artificial-life">A new course on Artificial Life</a></li>
<li><a href="#hiring-phd-candidate-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence-at-the-university-of-oslo">Hiring PhD Candidate in Biologically Inspired methods for Robotics and Artificial Intelligence at the University of Oslo</a></li>
<li><a href="#abiogenesis-artwork-by-markos-r-kay">Abiogenesis (artwork by Markos R. Kay)</a></li>
<li><a href="#emergent-microcosms-a-blog-post-by-samuel-arbesman">Emergent Microcosms (a blog post by Samuel Arbesman)</a></li>
<li><a href="#upcoming-deadlines">Upcoming Deadlines</a></li>
<li><a href="#call-for-volunteers">Call for Volunteers</a></li>
</ul>
</div>

<h1 id="paper-integrating-living-organisms-in-devices-to-implement-care-based-interactions">Paper: “Integrating Living Organisms in Devices to Implement Care-based Interactions”</h1>
<p>By <a href="https://twitter.com/xjasminelu">Jasmine Lu</a> and <a href="https://twitter.com/plopesresearch">Pedro Lopes</a> (University of Chicago's Human Computer Integration Lab)</p>
<p><img alt="Slime mold watch" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/1-watch-textlabel.jpg" /></p>
<p>In this paper, we explore how embedding a living organism (in this case a slime mold, Physarum Polycephalum) as a functional component of a device, changes the user-device relationship. In our design, the user needs to care for the living organism (by providing food and water) in order for the device to work. When healthy, the organism participates in the device’s functionality by acting as a physical wire that enables power to the watch’s heart rate sensor. As such, caring for the device is intrinsic to its interaction design —with the user’s care, the slime mold becomes conductive and enables the sensor; conversely, without care, the slime mold dries and disables the sensor, and resuming care resuscitates the slime mold.</p>
<p>In addition to engineering this device, we also conducted a user study where participants wore our slime mold-integrated smartwatch for 9-14 days. We found that participants developed a unique connection towards their slime mold-integrated device, with many feeling a sense of responsibility and/or reciprocity.</p>
<p>Rather than a user-device relationship built on extractive use, our approach explores how devices can be designed to encourage the user to take on a caretaking role. We're excited about how our approach might foster new discussions about how we might rethink the user-device relationship. </p>
<p><img alt="How it works" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/6-interaction-graphic.jpg" /></p>
<p>Read <a href="http://lab.plopes.org/#integrating-living-organisms">our paper</a> or <a href="https://youtu.be/Bex91KV56PQ">watch the project video</a></p>
<h1 id="alife-paper-review-the-world-as-evolving-information">ALife Paper Review: The World as Evolving Information</h1>
<p><a href="https://arxiv.org/abs/0704.0304">https://arxiv.org/abs/0704.0304</a></p>
<p><em>Paper review by <a href="https://twitter.com/m_crosscombe">Michael Crosscombe</a></em></p>
<p>I recently transitioned into Artificial Life research and I have been digging through the digital archives to familiarise myself with some of the exciting ideas in the field. Given my outsider’s perspective, I find that I am most drawn to papers which offer a novel way of thinking about the world and, in doing so, provide a different lens through which we can approach the ongoing problems of the field.</p>
<p>One paper in particular is that of “The World as Evolving Information” by Carlos Gershenson. The author proposes that we adopt metaphors as our common language and then goes on to describe the world at different scales – not in terms of energy and matter, but in terms of information! Beginning simply, information is defined as “anything that an agent can sense, perceive or observe.” After additional notions to define an agent and its environment, it becomes clear why such an approach to thinking about the world is rather powerful. An agent simply acts on its environment (sense and response) and the environment is itself all that which interacts with the agent. From this simple setup, the author then introduces a list of “Tentative Laws of Information” with each law appearing reasonable and intuitive.</p>
<p>While not a solution to all of ALife’s open problems, I do think it is an interesting way to reframe existing problems and assess whether different approaches to tackling them can be taken. Consider, for example, collective behaviour. It is difficult to consider how large swarms of individuals coordinate to produce collective behaviour without considering the forms of information that are shared, propagated, and transformed to achieve said behaviour. We can also begin to consider the scales of these systems: Simplistic individuals are only capable of acting locally, and cannot perceive more complex information globally, such as the current state of the swarm or its coordinated collective behaviour. Yet the swarm, as a more complex entity, seems to be capable of producing more complex information (behaviours) than any one individual is capable of, and reasoning about the relationships between the micro and macro levels are much more intuitive when we think about them within the proposed framework.</p>
<p>A system more easily translated into the world of evolving information may be Cellular Automata (CA). These systems have well-defined, often deterministic rules about how information (the state of a cell) changes based on the information that an agent (the cell itself) can perceive. Such a discrete system should be rather trivial to quantify, but how would something more complex, such as Lenia, translate into the same world? This is far less trivial, but presumably still feasible.</p>
<p>At the end of the paper, frustratingly, the author hints that such a framework could be implemented in simulation. I am curious whether the author has made any progress in this direction; of creating an information-based simulation that implements the tentative laws outlined in the paper.</p>
<h1 id="a-new-course-on-artificial-life">A new course on Artificial Life</h1>
<p>by <a href="https://skriegman.github.io/">Sam Kriegman</a></p>
<p><img alt="robots" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/kriegman_bots.png" /></p>
<p>In this, my first year as assistant professor at Northwestern University, I am building out <a href="https://www.xenobot.group/">my research group</a> and teaching my very first course: Artificial Life. The syllabus is available <a href="https://docs.google.com/document/d/1jURIbvpQ0imcaMk-AHUmj_szZNtsA4lZAlcqXa6usXs/edit?usp=sharing">here</a>. One-hundred-and-thirty extremely bright and creative students are now learning about the wonderful world of ALife for the very first time, and I get to stand in front of them each week as Morpheus with a firehose of red pills, feeding them all of the beautiful and inspiring work of this community, and watching their minds explode.</p>
<p>Because Northwestern is on a quarter system, I have the impossible task of covering the entirety of ALife in just nine weeks. And, as a new assistant professor, I have been flying by the seat of my pants. I am writing this to share my excitement and, also, to solicit comments, compliments and criticisms from the community. You can email me directly or share anonymous feedback through the form linked in the footer of the syllabus.</p>
<p>This new ALife class stands firmly on the shoulders of <a href="https://www.reddit.com/r/ludobots/">Ludobots</a>, a reddit-based MOOC that gently guides students, step by step, toward evolving possible brains (neural controllers) of a motile creature (kinematic tree) in a virtual world (rigid body simulation). After completing Ludobots, however, the students in this new course will be thrown straight into the deep end: they will be tasked with evolving not only brains but bodies too, and to do so without step-by-step instructions. I have no idea how this will turn out. We could end up with 130 populations of wiggling worms of varying lengths and sizes, without any real “march of progress” in terms of morphological and behavioral complexity. But I think this is unlikely. Did I mention how incredibly bright these students are? I made sure to warn the students that the assignments will suddenly become much more challenging midway through the course. What I have not told them (yet) is that they will be working on a problem that no one really has any idea how to solve. Who knows, maybe one of them will end up solving it.</p>
<h1 id="hiring-phd-candidate-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence-at-the-university-of-oslo">Hiring PhD Candidate in Biologically Inspired methods for Robotics and Artificial Intelligence at the University of Oslo</h1>
<p>by Kai Olav Ellefsen, University of Oslo</p>
<p>The PhD research fellow will carry out research on AI and machine learning techniques (including search / optimization) for robotic systems, at the group of Robotics and Intelligent Systems (ROBIN). We wish to build on our previous and ongoing projects in Evolutionary Robotics with the aim of developing new methods for more robust and flexible robotic adaptation. This could include combining Evolutionary Robotics with recent advances from Deep Learning or more biologically inspired methods, such as Neuroevolution.</p>
<p>Qualifications: Applicants must have education equivalent to a Norwegian masters degree in computer science, robotics, or other relevant field. Thus, applicants should have a strong background in programming, as well as machine learning/artificial intelligence and robotics. Experience with Evolutionary Algorithms, Evolutionary Robotics, Quality Diversity optimization, Reinforcement Learning, and/or Neuroevolution are considered advantageous.</p>
<p>Pay grade (depending on qualifications and seniority):<br />
NOK 501 200 – 544 400 per year, approx.: € or $ 48,150 – 52,350</p>
<p><a href="https://www.jobbnorge.no/en/available-jobs/job/236645/phd-research-fellow-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence">Announcement Page</a></p>
<p>Deadline for applications: February 1st, 2023<br />
Applications are to be submitted through a web page and NOT by e-mail.</p>
<p>Contact for more information: Assoc. Prof. Kai Olav Ellefsen E-mail: kaiolae@ifi.uio.no</p>
<h1 id="abiogenesis-artwork-by-markos-r-kay">Abiogenesis (artwork by Markos R. Kay)</h1>
<p>shared by Lana</p>
<p><img alt="Video still" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/abiogenesis.png?h=200" /></p>
<p>I found this video imagining the origins of life in oil droplets mesmerising and wanted to share it with the community. <a href="https://www.mrkism.com/abiogenesis.html">The artist says</a>: </p>
<p>"Presented here is a conceptual reimagining of the "lipid world" theory which postulates that life originated from lipids forming membranes which would then envelop matter and nutrients to form protocells. Biological cells as we now know them can be thought of us membranes within membranes."
Watch the full video <a href="https://www.mrkism.com/abiogenesis.html">here</a>.</p>
<h1 id="emergent-microcosms-a-blog-post-by-samuel-arbesman">Emergent Microcosms (a blog post by Samuel Arbesman)</h1>
<p>shared by Lana</p>
<p><img alt="a screenshot of the game &quot;orb&quot;" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/orb.jpg" /></p>
<p>Sam Arbesman recently wrote a <a href="https://twitter.com/arbesman/status/1587456000856133633">vibrant Twitter thread</a>, full of videos and links to creative platforms, about the concept of "Emergent Microcosms". He ultimately released a long form version of his thought through his newsletter. Here is a short excerpt from the first paragraph, enjoy the whole post <a href="https://arbesman.substack.com/p/emergent-microcosms">here!</a></p>
<p>"In all the excitement around Large Language Models and other trendy aspects of Artificial Intelligence, I think that we’ve forgotten an under-appreciated group of computer programs: relatively small snippets of computer code that can generate complex and delightful virtual worlds. [...] Emergent microcosm is a fuzzy category, but it roughly spans biology and artificial life, complexity science, simulation, and creative coding." <a href="https://arbesman.substack.com/p/emergent-microcosms">Read Sam's post</a></p>
<h1 id="upcoming-deadlines">Upcoming Deadlines</h1>
<p>Please see below for some upcoming deadlines for some conferences relevant to the ALife community:</p>
<ol>
<li><a href="https://alife-japan.org/archives/event/第6回人工生命研究会">The 6th Workshop of Artificial Life Japan</a>: Submission of Title/Author for presentations: <strong>03 February 2023</strong></li>
<li><a href="https://gecco-2023.sigevo.org/Call-for-Papers">Gecco 2023 (Lisbon, Portugal &amp; Online)</a>: Paper Submission Deadline: <strong>10 February 2023</strong></li>
<li><a href="https://uncomp.uwe.ac.uk/art-of-cellular-automata-exhibition-spring-2023-bristol/">Art of Cellular Automata Exhibition</a>: Call for entries. Deadline: <strong>20 February 2023</strong></li>
<li><a href="https://sites.google.com/view/alife-2023/calls/call-for-papers-extended-abstracts?authuser=0">ALife 2023 (Sapporo, Japan &amp; Online)</a>: Paper Submission Deadline: <strong>3 March 2023</strong></li>
<li><a href="http://ro-man2023.org/paperSubmission/callForPapers">RO-MAN 2023 (Busan, South Korea &amp; Online)</a> Paper Submission Deadline: <strong>17 March 2023</strong></li>
</ol>
<h1 id="call-for-volunteers">Call for Volunteers</h1>
<ul>
<li>
<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>
</li>
<li>
<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>
</li>
<li>
<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>
</li>
</ul>

</div>
<!-- class = "content" -->

</body>
</html>
