<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
 <title>Artificial Life Newsletter</title>
 <link>https://alife-newsletter.github.io/Newsletter/</link>
 <description>The Artificial Life Newsletter Brings you the latest alife news!</description>
 <lastBuildDate>20 Feb 2026 06:29:54 GMT</lastBuildDate>
 <item>
  <title>The 23rd edition of the Alife Newsletter, January 2026</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_023.html</link>
  <guid>edition_023</guid>
  <pubDate>01 Jan 2026 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 23rd issue of the ALife Newsletter! We have come to the end of another year, and we hope that 2025 was a good year for you! Accordingly, we dedicate this edition to reflecting on the past, and preparing for the coming year. </p>

<p>So first, we bring to you the results and impressions from the <strong>Community Survey</strong> we've done earlier this year. What kind of answers did we get from the community? What did we learn? And how do we plan to move forward?</p>

<p>We have also prepared the second <strong>ALIFE Advent Calendar</strong>. Do you remember the first one in 2023? The theme for the advent calendar this year is <strong>Homecoming</strong>. From each newsletter editor, we bring three items that connects us to our roots as scientists, as ALifers, and as people. I hope this will be interesting and bring some nice reflections to you too!</p>

<div class="toc">

<ul>

<li><a href="#the-alife-newsletter-community-survey-numbers">The ALIFE Newsletter Community Survey: Numbers</a></li>

<li><a href="#the-2025-artificial-life-holiday-calendar">The 2025 Artificial Life Holiday Calendar</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="the-alife-newsletter-community-survey-numbers">The ALIFE Newsletter Community Survey: Numbers</h1>

<p><em>by Lana, Imy, Claus and Martha</em></p>

<p>Early this year, we conducted a survey to learn who reads the Artificial Life Newsletter, and what they expect from it. Thanks to all of you who contributed to our survey. Your answers have given us a better idea of who is reading the Newsletter, what you like about our work, and how we could improve moving forward.

There are many lessons that we can take from your answers to the surveys. Below are some of the things that came to mind as we read up your responses.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/how_found.png" /></p>

<p>Most of our respondents seem to have found us through social media or through our announcements at the ALife conference. We have been slacking a bit on the social media side, but it looks like it's worth putting the effort in!</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/how_access.png" /></p>

<p>Email is by far the most common way that you are reading the newsletter. But did you even know we have a RSS feed? We might not have been advertising it enough! It's right here: <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed</a></p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/how_often.png" /></p>

<p>A surprising number of subscribers read every edition! Or at least, the kind of people who tend to answer our surveys also tend to read every email from us...</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/why_read.png" /></p>

<p>Got it: images are important, and so are good titles for our stories. (But we promise not to turn everything into a youtube thumbnail)</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/what_want.png" /></p>

<p>One of our main goals with this survey was to learn what you enjoy about the Newsletter, so that we can do more of that. Summing up the different comments that we received, there was an overall theme of "Paper, People and Projects" as things that the readers most liked. 

We often include a list of interesting papers that we have found, so you can be sure that there will be more featured papers on the newsletter. The "People" part is interesting -- we used to make interviews, but they turned out to be very work intensive, and so we shifted focus to other things. But knowing that this was a favorite part of the newsletter gives us motivation to think of how add interviews again, hopefully without adding too much workload to the editorial team. That includes interviews with individuals, and also features on working groups and laboratories.</p>

<p>(On the other hand, very few people mentioned "book reviews" as one of the thing they liked in the newsletter, which was... interesting ^^;)</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/what_like.png" /></p>

<p>Thank you for showing some love to our writing team! We'll keep our text hand typed and AI free then.

On a similar topic, some comments that stood out to us were about how the variety of different voices and topics in each edition was a positive point. We are always happy to feature reader suggestions regarding what to cover, so please let us know what you would like to see featured in the newsletter. You may drop us a line using the feeback field at our <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">contribution form</a>.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/what_change.png" /></p>

<p>A common suggestion was to improve the Newsletter design. We will certainly look into reviewing our lovingly hand-crafted CSS, and also, if anyone among the readership has web-design experience, please do contact us!</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_023/who.png" /></p>

<p>We are glad to report that our readership is quite varied! Most of you are from outside academia, and within academia we have a good share of students. We will strive to keep our Newsletter full of things that appeal to all ALifers!</p>

<p>Although the Survey is over, we are always interested in hearing the opinions of our readers. Please do feel free to reach to us through social media (or our feedback form) with more comments and ideas about what you want to see in the Artificial Life Newsletter!</p>

<h1 id="the-2025-artificial-life-holiday-calendar">The 2025 Artificial Life Holiday Calendar</h1>

<p>Do you know of Christmas Advent Calendars? This is a Western tradition where a calendar is prepared with one box for each day of December. Every day, when you open one of the boxes, an enticing surprise is waiting for you: A treat, a message, an image.</p>

<p>With this spirit in mind, we have prepared our own ALIFE Holiday Calendar for you! Every day from today until January 5th, you can click the link below to find a new interesting ALIFE tidbit, brought to you by the ALIFE Newsletter Editors:</p>

<p><a href="https://app.myadvent.net/calendar?id=fe0siqi59f1pw1pmsvanvaocnkeon8p3">The ALIFE Advent Calendar!</a></p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The ALife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: </p>

<ul>

<li>Lana Sinapayen</li>

<li>Imy Khan</li>

<li>Mitsuyoshi Yamazaki</li>

<li>Claus Aranha</li>

<li>Gabriel Severino</li>

<li>Martha Emerson</li>

</ul>

<p>The newsletter is sent by e-mail and can also be accessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the 

<a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk 

about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 22nd edition of the Alife Newsletter, October 2025</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_022.html</link>
  <guid>edition_022</guid>
  <pubDate>13 Oct 2025 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 22nd issue of the ALife Newsletter! This edition was a <strong>Physical Print Edition</strong> which was distributed to participants of the International Conference on Artificial Life, 2025, in Kyoto.</p>

<p><img alt="A photo of stacks of the print editions of the Newsletter" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/Paper_Newsletter.jpg" /></p>

<p>Some of the content for this edition might not translate very well to a digital edition, but we did the best to adapt what could be adapted! In particular, because of space restrictions of the print media, the newsletter may look quite short digitally. But you do get to click links instead of scanning QR codes, so there are some upsides too!</p>

<p>Without further ado, we give you:</p>

<h1 id="artificial-life-newsletter-3rd-print-edition">Artificial Life Newsletter, 3rd Print Edition</h1>

<p>They say <em>"twice is a coincidence, three times is a pattern"</em>, so with this edition, we can say now it is a <strong>tradition</strong> to prepare print editions of the Artificial Life Newsletter to go with the Annual International Conference on Artificial Life!</p>

<div class="toc">

<ul>

<li><a href="#the-alife-newsletter-survey">The ALIFE Newsletter Survey</a></li>

<li><a href="#kinda-alife-related-things-in-kyoto">(Kinda) ALife related things in Kyoto</a></li>

<li><a href="#the-laziest-life-form-ever-this-microbe-ditched-almost-everything-and-still-survives">The Laziest Life Form Ever? This Microbe Ditched Almost Everything and Still Survives</a></li>

<li><a href="#origami-robots">Origami Robots</a></li>

<li><a href="#a-message-from-the-alife-2026-organizers">A Message from the ALIFE 2026 Organizers</a></li>

<li><a href="#upcoming-alife-y-conferences">Upcoming ALIFE-y Conferences</a></li>

<li><a href="#alife-2025-kyoto-bingo">ALIFE 2025 Kyoto Bingo</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="the-alife-newsletter-survey">The ALIFE Newsletter Survey</h1>

<p>In July we held a survey to learn more about who reads the Artificial Life Newsletter, and how we can improve it. Thank you all who answered our survey! </p>

<p>In the next edition, we will go in details about what we've learned from your answers. In the meantime, there is a teaser below. If you haven't participated yet, you can still <a href="https://docs.google.com/forms/d/e/1FAIpQLSefnAyyxWYtOlAKTnaB9w8wyHPro9BoOuB_f_ZPOrz-0VLOrw/viewform?usp=sharing">fill the newsletter survey questionnaire</a>.</p>

<h2 id="who-reads-the-artificial-life-newsletter">Who reads the Artificial Life Newsletter?</h2>

<p><img alt="A Bar Graph with information about the Newsletter Readership" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/chart.png" /></p>

<h1 id="kinda-alife-related-things-in-kyoto">(Kinda) ALife related things in Kyoto</h1>

<p>(<strong>NOTE</strong>: some locations have no English support. Check before you go)</p>

<h2 id="tech-and-nature">Tech and Nature</h2>

<ul>

<li><a href="https://www.teamlab.art/e/kyoto/">Team Lab Interactive Art Museum</a></li>

<li><a href="https://www.lightcycles-kyoto.com/">Night light up, botanical gardens</a></li>

<li><a href="https://www.kyoto-aquarium.com/news/details/6965.html">Light up around the Kyoto Aquarium</a></li>

</ul>

<h2 id="art-art">Art Art</h2>

<ul>

<li>The Osaka Expo (in Osaka) has exhibits by members of the ALife community!</li>

<li><a href="https://www.toei-eigamura.com/yokai/">Yokai (Japanese Monsters) festival at Toei Studio Park</a></li>

<li><a href="https://artrhizome.kyoto/">Art Rhizome Kyoto</a></li>

</ul>

<h2 id="nature-themed-sweets">Nature-themed Sweets</h2>

<ul>

<li><a href="https://thisis.website/shizen/">Edible flower bouquet in an ice cream cone (sweet bean paste)</a></li>

<li><a href="https://maps.app.goo.gl/vnrhnM4xi7uGrcmu9">"Fish in a pond" shaved ice</a></li>

<li><a href="http://rokujuan.com/">Flowers in transparent bracken jelly, in a historical house and garden</a></li>

</ul>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/ajisai-small.png" />

<img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/warabi.jpg" />

<img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/kingyo-2-small.png" /></p>

<h1 id="the-laziest-life-form-ever-this-microbe-ditched-almost-everything-and-still-survives">The Laziest Life Form Ever? This Microbe Ditched Almost Everything and Still Survives</h1>

<p>Researchers have discovered a microorganism so metabolically stripped-down, it might be right on the edge of what we would consider to be "alive".</p>

<p>Meet <em>Sukunaarchaeum mirabile</em> (named after a tiny Japanese deity), a microscopic hitchhiker that's taken the art of being lazy to the extreme. </p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/lazy_lifeform.png" /></p>

<p>The tiny archeon has ditched almost everything most life forms need to survive: it can't make its own food, can't process energy, can't even handle basic cellular housekeeping. Instead, it freeloads off a marine dinoflagellate, keeping only the bare minimum needed to copy itself: DNA replication and protein-making machinery. Its genome is absolutely tiny, at just 238 kilobases (1 kb = 1000 base pairs of DNA/RNA), making it the smallest archaeal genome ever found (less than half the size of the previous record holder)! </p>

<p>This is clearly an interesting discovery for ALifers since it blurs the boundaries between (living) cellular organisms and (non-living) viruses. <em>Sukunaarchaeum</em> has retained the core cellular machinery that viruses typically lack, yet its extreme host dependence and specialisation for pure genetic self-replication mirrors viral strategies. It provides a real-life example of how a biological system can be pared down to its most essential components, living a virus-like existence while still maintaining a "cellular" identity. It raises interesting questions about what we'd need to include in truly minimal artificial life forms.</p>

<ul>

<li>Paper: <a href="https://doi.org/10.1101/2025.05.02.651781">"A Cellular Entity Retaining only its Replicative Core: Hidden Archeal Lineage with an Ultra-reduced Genome"</a></li>

</ul>

<h1 id="origami-robots">Origami Robots</h1>

<p>When you hear the word origami, you might think of folded paper. But did you know that robots can form from origami too? It’s true.</p>

<p>It is actually possible to create robots that start out as flat sheets, then fold themselves into three-dimensional agents that can crawl like caterpillars, wriggle like earthworms, and even swim like fish. In some cases, a single sheet can generate an entire swarm of origami robots.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/Origami%20Caterpillar.png" /></p>

<p>So how does this work? (After all, paper doesn’t fold itself.) For these robots, smart materials are embedded in flat sheets. When activated by heat or electrical signals, the smart materials help the sheet fold along predetermined crease patterns, just as you might follow an origami pattern to turn a simple square of paper into an elegant paper crane.</p>

<p>To form a swarm, the material is designed to separate instead of folding, similar to kirigami (where paper is both cut and folded). After the agents separate themselves from the sheet, they fold themselves into their final shapes, creating a swarm of origami robots that can move independently while working together to complete a variety of potential tasks.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/Robot%20Swarms.png" /></p>

<p>Just as a packet of origami paper can yield infinite designs, these robots embody the principle of complexity from simplicity.</p>

<p>References: Rus (2018); Ackerman (2016); Wu (2024)</p>

<h1 id="a-message-from-the-alife-2026-organizers">A Message from the ALIFE 2026 Organizers</h1>

<p>We are happy to announce that the premiere International Conference on Artificial Life 2026 will take place in Waterloo, Ontario, Canada with the theme “Living and Lifelike Complex Adaptive Systems” !</p>

<p>The organizing committee currently consists of Chrystopher L. Nehaniv (University of Waterloo, Ontario, Canada), Peter Lewis (Ontario Tech University, Oshawa, Ontario, Canada), Hanna Derets (University of Waterloo, Ontario, Canada), Hiroki Sayama (Binghamton University, State University of New York, U.S.A.), and Kirsten Wright (University of Waterloo). <strong>The conference will be held on 17-21 August 2026</strong> at W. Laurier University in Waterloo with additional events at University of Waterloo and other locations nearby.</p>

<p>ALIFE 2026 will be held in tandem with the VII AMMCS International Conference (Applied Mathematics, Modeling and Computational Science). Thus, the 2026 AMMCS-ALIFE Congress is a major international and interdisciplinary event combining the AMMCS and ALIFE meetings.</p>

<p>Current plans are that registered ALIFE 2026 participants will be able to attend all plenary talks and sessions of AMMCS 2026, and vice versa. ALIFE 2026 is sponsored in part by the Waterloo Institute for Complexity and Innovation and the Canadian Network on Complex Systems.</p>

<p>We look forward to seeing you all in Waterloo, Ontario, Canada in 2026!</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/GeeseWaterlooImage.png" /></p>

<h1 id="upcoming-alife-y-conferences">Upcoming ALIFE-y Conferences</h1>

<p>If you still have energy left after ALIFE 2025, take a look at a selection by the newsletter editors of upcoming events. Some of these are still accepting paper submission!</p>

<p><a href="https://computationalsocialscience.org/conferences/css-2025-santa-fe/">International Conference of the Computational Social Science Society of the Americas (CSSSA)</a>

- Date: November 6-9, 2025;

- Location: Santa-Fe, USA;</p>

<p><a href="https://www.ssagsg.org/AsiaSim2025/index.html">24th Asia Simulation Conference (AsiaSim 2025)</a>

- Date: November 17-19, 2025;

- Location: Singapore;</p>

<p><a href="https://astrobio.pl/las25/">Life and Space Conference</a>

- Date: December 5-7, 2025;

- Location: Online;</p>

<p><a href="https://wccs-conference.org/wccs26/">World Conference on Complex Systems (WCCS26)</a>

- Paper Submission: November 1st, 2025 (abstract)

- Date: April 20-22, 2026

- Location: Marrakesh, Morocco</p>

<p><a href="https://cyprusconferences.org/aamas2026/">International Conference on Autonomous Agents and Multi Agent Systems (AAMAS 2026)</a>

- Paper Submission: October 8th, 2025

- Date: May, 25-29, 2026; 

- Location: Paphos, Cyprus;</p>

<p><a href="https://attend.ieee.org/wcci-2026">IEEE World Congress on Computational Intelligence (WCCI 2026)</a>

- Paper Submission: January 31st, 2026

- Date: June 21-26, 2026;

- Location: Maastricht, The Netherlands</p>

<h1 id="alife-2025-kyoto-bingo">ALIFE 2025 Kyoto Bingo</h1>

<p>We prepared a Kyoto-themed bingo for people to play in Kyoto. Participants can check the cells as they encounter various things in their stay in Kyoto. There is nothing to win, but this may become a keepsake of how much fun you had there.</p>

<p>Below is an example of the bingo. You can also access <a href="https://bingobaker.com/#68cd3e0490a3a47b">this website</a> to generate a new bingo card just for you.</p>

<p><img alt="Bingo of Things to do in Kyoto" src="https://alife-newsletter.github.io/Newsletter/images_edition_022/bingo-card-text.png" /></p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The ALife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: </p>

<ul>

<li>Lana Sinapayen</li>

<li>Imy Khan</li>

<li>Mitsuyoshi Yamazaki</li>

<li>Claus Aranha</li>

<li>Gabriel Severino</li>

<li>Martha Emerson</li>

</ul>

<p>The newsletter is sent by e-mail and can also be accessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the 

<a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk 

about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 21st edition of the Alife Newsletter, May 2025</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_021.html</link>
  <guid>edition_021</guid>
  <pubDate>05 May 2025 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 21st issue of the ALife Newsletter! </p>

<p><a href="https://forms.gle/QpQ68xhvSMt4wiv89">Never miss an issue by subscribing here</a>.</p>

<p>In this edition, we are proud to unveil our best-ever omnibus of ALife-related videos! Witness tiny lifelike pets made from sand, as well as the emergence of lifelike forms from bio-inspired music &amp; art. Explore DIY genetic engineering, see how vision/graphics models are used to both discover and create agents, and learn about the physics of living systems. Immerse yourself in ALife simulations, and you may even choose to become involved in one yourself!</p>

<p>This month, we have also focused on the origins of life, as well as the origin of eyes. And Complexity Cat is here to help us reach a new understanding of living systems.</p>

<p>As we look forward to the upcoming conference in Kyoto, there is another submission looming: the deadline for creating the official ALIFE2025 mascot! And to get in the spirit, be sure not to miss the most recent conference-themed What ALife! podcast.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">contribution form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other ALifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus, Gabriel and Martha</p>

<div class="toc">

<ul>

<li><a href="#paper-review-concomitant-formation-of-protocells-and-prebiotic-compounds-under-a-plausible-early-earth-atmosphere">Paper Review: "Concomitant formation of protocells and prebiotic compounds under a plausible early Earth Atmosphere"</a></li>

<li><a href="#paper-review-evolution-of-complex-chemical-mixtures-reveals-combinatorial-compression-and-population-synchronicity-matange-et-al-2025">Paper Review: Evolution of complex chemical mixtures reveals combinatorial compression and population synchronicity (Matange et al., 2025)</a></li>

<li><a href="#simulation-project-what-if-eye">Simulation Project: "What if Eye?"</a></li>

<li><a href="#blog-post-review-relational-biology-i-is-it-possible-to-simulate-life-complexity-cat">Blog Post Review: "Relational Biology I: Is it possible to simulate life? - Complexity Cat"</a></li>

<li><a href="#alife-videos">ALife Videos</a></li>

<li><a href="#competition-design-the-official-mascot-for-alife2025">Competition: Design the Official Mascot for ALIFE2025!</a></li>

<li><a href="#podcast-what-alife-bonus-episode-on-alife-2025">Podcast: What ALife! Bonus Episode on ALIFE 2025</a></li>

<li><a href="#conferences-and-calls">Conferences and Calls</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="paper-review-concomitant-formation-of-protocells-and-prebiotic-compounds-under-a-plausible-early-earth-atmosphere">Paper Review: "Concomitant formation of protocells and prebiotic compounds under a plausible early Earth Atmosphere"</h1>

<p>Summary by Claus</p>

<p><a href="https://tech.lgbt/@ngaylinn">Nate Gaylinn</a> shared on Mastodon a <a href="https://www.pnas.org/doi/10.1073/pnas.2413816122">paper about a recent experiment on the origins of life</a>. In this paper, the authors prepare an environment that mimics the conditions of early earth, and conduct lighting experiments in this environment. The goal was to find evidence of the early blocks of life, and understand the range of necessary conditions for life on earth and possibly in other worlds.</p>

<p>Or, as <a href="https://tech.lgbt/@ngaylinn/114002744361757569">Nate puts it much better in his original post</a>: </p>

<blockquote>

<p>"Like Miller and Urey before them, these researchers simulated a tiny pond on ancient earth, and struck it with "lightning."</p>

<p>They confirmed this produces biochemicals, but this time they used advanced microscopy to show it also produces tiny bubbles that look surprisingly lifelike on their own, and could serve as shelters for protolife.</p>

<p>Awesome finding! This really could have been important for life's origins (though, to be properly alive, the protocell would need to be able to make its own vesicle, and divide it). It's a little disheartening, though, as this new evidence makes the search for microbial fossils that much harder.</p>

<p>Understanding what life is and how it made itself what we see today is a real challenge. We're coming onto the scene a few billion years too late! Mostly, we must rely on our imagination and simulations, so when we get some new clues from the physical sciences, that's always a treat. This experiment shows us a new affordance available to primordial life, and gives some clues about how to interpret microfossils in the archaeological record.</p>

</blockquote>

<p>The paper itself is not very long, and has nice pictures of the experimental setup, so make sure to give it a read!</p>

<h1 id="paper-review-evolution-of-complex-chemical-mixtures-reveals-combinatorial-compression-and-population-synchronicity-matange-et-al-2025">Paper Review: Evolution of complex chemical mixtures reveals combinatorial compression and population synchronicity (Matange et al., 2025)</h1>

<p>Summary by Imy</p>

<p>The previous paper presented by Claus is not the only Origins of Life paper to make it into this issue. This recent paper, written by Kavita Matange and colleagues, published in Nature Chemistry and accessible <a href="https://williams.chemistry.gatech.edu/publications/LDW_162.pdf">here,</a>

offers another perspective in the ongoing quest to understand the origins of life here on Earth. It aims to understand how the simple prebiotic chemicals readily available on early Earth might have transitioned into the more complex molecular assemblies necessary for the emergence of life. </p>

<p>Rather than focusing on individual reactions, this study examines the behaviour of entire chemical systems under simulated early Earth conditions. The authors developed an experimental model simulating early Earth conditions using fluctuating water activity and near-ambient temperatures to drive the evolution of organic molecule mixtures containing key functional groups.</p>

<p>The researchers observed three key phenomena: (1) the chemical systems underwent continuous change without reaching a stable equilibrium, (2) they demonstrated 'combinatorial compression' where a limited number of products were formed despite a large number of possible combinations, indicating stringent chemical selection, and (3) different molecular species exhibited 'synchronicity of molecular populations', meaning their concentrations rose and fell in coordinated ways. These findings suggest that even simple environmental fluctuations could drive a non-chaotic progression towards molecular complexity.</p>

<p>Their findings challenge the idea of a purely chaotic prebiotic environment. Instead, they observed that their chemical systems underwent continuous change without reaching equilibrium, demonstrating combinatorial compression with stringent chemical selection and a surprising synchronicity of molecular populations. The authors propose that simple environmental oscillations could have acted as a powerful engine for the generation of increasingly complex chemical species, the very building blocks of life.</p>

<p>You can read the paper using the link above, or the <a href="https://scitechdaily.com/not-so-random-after-all-scientists-uncover-surprising-new-clues-to-the-origin-of-life/">press release here</a>.</p>

<h1 id="simulation-project-what-if-eye">Simulation Project: "What if Eye?"</h1>

<p><em>Summary by Claus</em></p>

<p>The MIT Media Lab, Camera Culture group, has recently published a project called <a href="https://eyes.mit.edu/">"What if Eye?"</a>. This project aims to computationally simulate the evolution of visual systems, from early light sensors to fully fledged lensed eyes.</p>

<p><img alt="Screenshots of the What if Eye simulator" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/whatifeye.png" /></p>

<p>The simulation occurs in virtual creatures who have to solve tasks in a 2D environment using visual input. Evolution controls both the physical characteristics of these eyes (number of eyes, lensing, etc), as well as the neural network that reads and processes the signals produced by them. </p>

<p><img alt="Figure 1 of the &quot;What If Eye&quot; Paper" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/WIE_paper.png" /></p>

<p>The project's webpage has links to both the <a href="https://arxiv.org/pdf/2501.15001">paper describing the simulation and evolutionary framework</a>, as well as a <a href="https://github.com/cambrian-org/ACI">link to the simulation software on github</a>. </p>

<h1 id="blog-post-review-relational-biology-i-is-it-possible-to-simulate-life-complexity-cat">Blog Post Review: "Relational Biology I: Is it possible to simulate life? - Complexity Cat"</h1>

<p>Summary by Imy</p>

<p>What's the real difference between a biological model and a simulation, and why is this distinction crucial for understanding life?</p>

<p>Complexity Cat recently started <a href="https://amahury.github.io/posts/trilogy-relational-biology-I/">a new blog series</a> exploring the field of relational biology, pioneered by Robert Rosen. Moving beyond a purely reductionist view of life's molecular components, relational biology emphasises the organisational relationships and interactions that define living systems. This first post introduces these ideas to readers, and directly tackles a common misinterpretation that Rosen outright denied the possibility of simulating life.</p>

<p>Instead, the blog post argues that Rosen's work (alongside that of his mentor, Nicolas Rashevsky) suggests that traditional, algorithmic simulations may inherently struggle to capture the essence of living systems, particularly their closure to efficient causation i.e. the ability of a system's components to generate and maintain their own organisation. The blog post clarifies the Rosen's distinction between abstract models and computational simulations and discusses how relational approaches offer a different lens for understanding the fundamental principles of life. </p>

<p>Read the <a href="https://amahury.github.io/posts/trilogy-relational-biology-I/">full blog post</a> over on Complexity Cat.</p>

<p>As an aside, <a href="https://amahury.github.io/">Complexity Cat</a> is an excellent and frequently updated resource for those interested in ALife. It is managed by <a href="https://twitter.com/amahury0">Amahury J. L. Díaz</a> and colleagues, so feel free to explore and follow their blog.</p>

<h1 id="alife-videos">ALife Videos</h1>

<p>Shared by Lana</p>

<p>In this edition we have collected quite a few interesting videos, here they all are for your viewing pleasure!</p>

<p>"The Physics of Living Systems" with Chris Kempes for "Reason with Science" 

<img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/kempes.png" /></p>

<p>"This episode is with Chris Kempes, a professor at the Santa Fe Institute, working at the fascinating intersection of physics and biology. Chris joins us to talk about some of the most profound questions about life starting from fundamental definitions to exploring life's potential multiple origins guided by the laws of physics. Join us as we explore the role of energy landscapes in Prebiotic chemistry, the physical basis of microbial behaviors, scaling laws that govern life's metabolic patterns, and how collective behaviors emerge in multicellular organisms. Let's embark on a journey to rethink life's mysteries through the lens of physics."</p>

<p><a href="https://www.youtube.com/watch?v=2rvJoa31-KI">https://www.youtube.com/watch?v=2rvJoa31-KI</a></p>

<p>"Hypercycle – Let There Be Artificial Life" by Jeffrey Ventrella and Jean-Claude Heudin</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/hypercycle.png" /></p>

<p>"A collaboration between visual artist and Artificial Life researcher Jeffrey Ventrella and AI researcher and composer Jean-Claude Heudin. Both the video and the music are created using bio-inspired algorithms showing the emergence of life-like forms."

The entry after this one is also by Jeffrey Ventrella!</p>

<p><a href="https://youtu.be/nMuyJQ0GXSk">https://youtu.be/nMuyJQ0GXSk</a> </p>

<p>"Clusters - an Asymmetrifcal Particle System with Emergent Patterns" by Jeffrey Ventrella</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/ventrella.png" /></p>

<p>"This is a video explaining the Clusters particle algorithm. Explore it in real-time at ventrella.com/clusters"</p>

<p><a href="https://vimeo.com/1048238799">https://vimeo.com/1048238799</a></p>

<p>"London 1940" by ‪Tom Barbalet</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/barbalet.png" /></p>

<p>"Tom talks about his London1940.org simulation project that really needs a particular kind of developer to pick it up."</p>

<p><a href="https://www.youtube.com/watch?v=pD-PNwk-Z9E">https://www.youtube.com/watch?v=pD-PNwk-Z9E</a></p>

<p>"Rewriting DNA to make custom monstrosities" by The Thought Emporium</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/dna.png" /></p>

<p>"In this video we take a deep dive into the world of genetic engineering. What is it, what's it's history, how does it work, and how you can do it too! We explore a variety of custom printer pieces of DNA, and see all the amazing things they do when you put them into a living organism. We've got things that glow, smell, and even things that behave like electrical circuits and transistors."</p>

<p><a href="https://www.youtube.com/watch?v=10OUPyamn1w">https://www.youtube.com/watch?v=10OUPyamn1w</a></p>

<p>"Dear Humans: Meet Ferro Pets!"</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/ferropet.png" /></p>

<p>A video showcasing a clever use of ferromagnetic sand and "lifelike" behavior.</p>

<p><a href="https://www.youtube.com/watch?v=koN1SnLldGU">https://www.youtube.com/watch?v=koN1SnLldGU</a></p>

<p>“Robots and Artificial Life from Visual Foundation Models”, a talk by Phillip Isola (MIT) for Spring 2025 GRASP on Robotics.

<img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/isola.png" /></p>

<p>ABSTRACT

"I will talk about two ways we can design agents with the help of powerful vision/graphics models. In the first project, LucidSim, we augment a traditional robotics simulation engine (MuJoCo) with visual detail from an image generative model. The generator adds diversity and realism to the barebones MuJoCo content, and results in a RGB-only policy trained entirely in sim that generalizes zero-shot to the real world. In the second project, ASAL, we use a visual recognition model to search for artificial lifeforms that display distinct and interesting behaviors. This process can discover cellular automata that are open-ended like Conway’s Game of Life, particle swarms that flock like Boids, and more."</p>

<p><a href="https://www.youtube.com/live/MywO2yL4b68">https://www.youtube.com/live/MywO2yL4b68</a></p>

<p>"Simulation of Ontogenesis"</p>

<p>Simulife Hub is a youtube channel with many simulations of tenets of Artificial Life, from plant generation to the evolution of altruism. Here is their latest video, about multicellularity.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_021/simulife.png" /></p>

<p>"All cells have the same genome, but each cell must perform tasks according to its position in the growing organism.

To do this, cells must somehow interact with each other and regulate the expression of their genes.

This project is dedicated to exploring this process.

I'm not a biologist. While delving into this topic,

I'm trying to model these processes on a computer and create videos based on the results of my experiments."</p>

<p><a href="https://www.youtube.com/watch?v=qwJNeq-WABU">https://www.youtube.com/watch?v=qwJNeq-WABU</a></p>

<h1 id="competition-design-the-official-mascot-for-alife2025">Competition: Design the Official Mascot for ALIFE2025!</h1>

<p>by Imy</p>

<p>Hey! Want to win a free registration to this year's ALIFE 2025 conference?</p>

<p>The 2025 Artificial Life conference is happening in Kyoto, Japan, and we want YOU to design the official mascot to be the face of the conference. We're seeking a unique character to embody the spirit of ALIFE - whatever that means to you. This is your opportunity to leave a lasting mark on the ALIFE community and become a part of conference history and folklore.</p>

<p>All you need to do is submit your visual sketch or rendering, a catchy and memorable name, and an optional short backstory explaining your mascot's connection to artificial life and the ALIFE 2025 conference. The winning design will become the official face of the conference, featured on the website, social media, merchandise, and potentially even as a life-sized costume!</p>

<p>Did we already mention winning a free registration to the ALIFE 2025 conference?</p>

<p>All community members – researchers, students, enthusiasts, and artists – are encouraged and invited to participate. Let your imagination flourish and help us bring the ALIFE 2025 spirit to life!</p>

<p>The deadline for submissions is June 15th, 2025. Don't miss this exciting chance to contribute your vision and potentially attend ALIFE 2025 for free! Submit your design today!</p>

<p>Check the <a href="https://tinyurl.com/ALIFEMascotCompetition">submission page</a> for full submission details.</p>

<h1 id="podcast-what-alife-bonus-episode-on-alife-2025">Podcast: What ALife! Bonus Episode on ALIFE 2025</h1>

<p>by Imy</p>

<p>And speaking of the ALIFE 2025 conference, <a href="https://open.spotify.com/episode/6Tlr0cmBzPL5yqqHy8UvLx?si=5906034150ef4f90">check out this bonus episode of the What ALife! podcast</a> where Imy spoke with Alyssa Adams (vice chair of the ALIFE 2025 conference), for a short overview of the conference, its ambitions, and a look at what goes into the planning of a scientific conference. Much has changed since this podcast was recorded, but it's still worth listening to if you want to get a feel for what the conference is going to be about!</p>

<h1 id="conferences-and-calls">Conferences and Calls</h1>

<p>The deadline for ALIFE 2025 has been extended by one week, so it is not too late to submit your paper!</p>

<ul>

<li><a href="https://2025.alife.org/submit">ALIFE 2025 conference</a> (Virtual and In-Person in Kyoto, Japan). October 6-10 2025. Full Papers/Summaries submission: May 11th 2025.</li>

</ul>

<p>Here is a short list of conferences and symposia that have active calls:</p>

<ul>

<li><a href="https://icsr2025.eu/call-for-papers/">International Conference on Social Robotics + AI</a> (In-Person in Naples, Italy). September 10-12 2025. Full Papers submission: May 9th 2025.</li>

<li><a href="https://ecta.scitevents.org/">Evolutionary Computation Theory and Applications</a> (In-Person in Marbella, Spain). October 22-24 2025. Regular Paper submission: May 19th 2025.</li>

<li><a href="wivace2025.diism.unisi.it">WIVACE 2025: XIX International Workshop on Artificial Life and Evolutionary Computation</a>. (In-Person in Siena, Italy). September 3-5 2025. Abstract/Paper submission: May 30th 2025.</li>

<li><a href="https://complexnetworks.org">Complex Networks 2025</a> (In-Person in Binghamton, New York). December 9-11, 2025. Regular Paper submission: September 2nd 2025.</li>

</ul>

<p>This symposium will be exploring the intersection between complexity science and anarchism. The week will feature an unconference style, emphasizing a self-organized exchange of ideas, and camping!</p>

<ul>

<li><a href="https://clea.research.vub.be/complex-anarchism-symposium-19-23-may-2025-in-brussels">Complex Anarchism Symposium</a> (In-Person in Brussels, Belgium). May 19-23 2025. Confirmation of Participation: May 4th 2025 (or later, if space allows).</li>

</ul>

<p>Here are some other events of interest:</p>

<ul>

<li><a href="https://iutdijon.u-bourgogne.fr/ccs-france/">FRCCS 2025</a> (In-Person in Bordeaux, France). May 21-23 2025.</li>

<li>Gecco Workshop: <a href="https://evolving-self-organisation-workshop.github.io/">Evolving Self-organisation</a>. (Virtual and In-Person in Málaga, Spain). July 14-18 2025.</li>

<li><a href="https://www.animalbehaviorsociety.org/2025/abstracts.php">The Animal Behavior Society</a> (Virtual and In-Person in Baltimore, Maryland). July 8-12 2025.</li>

<li><a href="https://www.ro-man2025.org/">RO-MAN 2025</a> (Virtual and In-Person in Eindhoven, the Netherlands). August 25-29 2025.</li>

</ul>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The ALife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino

- Martha Emerson</p>

<p>The newsletter is sent by e-mail and can also be accessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 20th edition of the Alife Newsletter, March 2025</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_020.html</link>
  <guid>edition_020</guid>
  <pubDate>07 Mar 2025 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 20th issue of the ALife Newsletter! </p>

<p><a href="https://forms.gle/QpQ68xhvSMt4wiv89">Never miss an issue by subscribing here</a>.</p>

<p>In this edition, we learn about a 13 million Euro push to create a minimal living system, explore a cool interactive website all about Turing machines, and envision systems to light up the space of infinite possible intelligences.</p>

<p>A review of the literature reveals bacteria trained to perform computations, a snapshot of ALife-as-it-was over 20 years ago, and a new class of life that has been colonizing us all along.</p>

<p>In the land of opportunity, the University of Oslo is hiring a postdoc focusing on bio-inspired AI, the Tölvera Python library is accepting applications for Google Summer of Code 2025, and we have a roundup of conferences with active calls. Plus, Jitka Čejková is preparing a book to commemorate 40 years of ALife conferences, to be filled with <em>your</em> stories and memories!</p>

<p>Last, but not least, we are glad to welcome a new member to the ALife Newsletter team: a warm welcome to Martha Emerson!</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">contribution form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other ALifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus, Gabriel and Martha</p>

<div class="toc">

<ul>

<li><a href="#a-web-introduction-to-the-turing-machine">A Web Introduction to the Turing Machine</a></li>

<li><a href="#building-our-way-out-beyond-the-machine-learning-mote">Building Our Way Out: Beyond the Machine Learning Mote</a></li>

<li><a href="#13mn-minilife-project-aims-to-create-artificial-life-from-scratch">€13mn ‘MiniLife’ project aims to create artificial life from scratch</a></li>

<li><a href="#bactoneurons">Bactoneurons</a></li>

<li><a href="#hiring-postdoctoral-researcher-position-in-biologically-inspired-artificial-intelligence">Hiring: Postdoctoral researcher position in Biologically Inspired Artificial Intelligence</a></li>

<li><a href="#tolvera-at-google-summer-of-code-2025">Tölvera at Google Summer of Code 2025</a></li>

<li><a href="#obelisks-a-new-class-in-the-tree-of-life">Obelisks: A new class in the tree of life</a></li>

<li><a href="#paper-review-collective-intelligence-of-the-artificial-life-community-on-its-own-successes-failures-and-future-rasmussen-et-al-2003">Paper Review - Collective Intelligence of the Artificial Life Community on Its Own Successes, Failures, and Future (Rasmussen et al., 2003)</a></li>

<li><a href="#40-years-of-artificial-life-conferences">40 Years of Artificial Life Conferences</a></li>

<li><a href="#conferences-and-calls">Conferences and Calls</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="a-web-introduction-to-the-turing-machine">A Web Introduction to the Turing Machine</h1>

<p>shared by Lana</p>

<p><strong>Webpage: <a href="https://samwho.dev/turing-machines/">https://samwho.dev/turing-machines/</a></strong></p>

<p>One of the most famous concepts in computer science is the concept of the "Turing machine" and its exciting associate, "Turing completeness". The <a href="http://game-of-life.daneaiulian.com/index.php">Game of Life</a> is Turing complete! DNA is a Turing machine! Biology and computers brought together, a topic of interest to ALifers since the beginnings of the field. But wait, what does any of this mean, and why do people get excited about it? Whether you learned about it in school and need a refresher, have never really known what it is and how it relates to Alan Turing, or know exactly what it means and would like to have fun with beautiful, interactive animations, this website is for you. As stated in the introduction,</p>

<blockquote>

<p>"By the end of this post, you will know:</p>

<ul>

<li>What a Turing Machine is.</li>

<li>What can and cannot be computed.</li>

<li>What it means to be Turing complete.</li>

<li>How modern computers relate to Turing machines.</li>

<li>How to write and run your own programs for a Turing machine."</li>

</ul>

</blockquote>

<p><img alt="screenshot showing an interactive Turing machine" src="https://alife-newsletter.github.io/Newsletter/images_edition_020/turing-machine.png" /></p>

<h1 id="building-our-way-out-beyond-the-machine-learning-mote">Building Our Way Out: Beyond the Machine Learning Mote</h1>

<p>Shared by Jack, Founder, <a href="http://æ.is">Afhverju Ekki</a></p>

<p>Jack shares <a href="https://builders.mozilla.org/building-our-way-out/">an opinion piece at the Mozilla Foundation <em>Builders</em> project</a></p>

<blockquote>

<p>Picture the space of all possible forms of intelligence. Now zoom in — way in — until you see a tiny mote. That’s where we’re stuck right now: trapped in the speck of machine learning and large language models.</p>

<p>While these tools are impressive, they represent just a fraction of this possibility space. AI discourse risks becoming a closed loop, with concerns about ML’s impact met only with proposals for better ML models, reinforcing our fixation. How do we build outward to see and benefit from intelligence in all its wonderfully diverse embodiments?</p>

</blockquote>

<h1 id="13mn-minilife-project-aims-to-create-artificial-life-from-scratch">€13mn ‘MiniLife’ project aims to create artificial life from scratch</h1>

<p>Written by <a href="http://imytk.github.io">Imy</a></p>

<p>Can we create life de novo? </p>

<p>This remains one of the grand aims of the artificial life community, both for the study of life-as-it-is, and also for life-as-it-could-be. (Christopher Langton mentioned in his 1989 essay that, "One way to pursue the study of artificial life [is] to attempt to create life in vitro.")</p>

<p>But this is not an easy task, as anyone involved in artificial life will tell you. Since we're still in disagreement about what the minimal conditions would be to call a system "living", and perhaps even less clear on how we would identify that these conditions have been met, it is perhaps no surprise that we don't see many (funded) long-term projects that are driven by the idea of trying to create life from scratch.</p>

<p>Recently, the MiniLife project, led by evolutionary biologist Professor Eörs Szathmary of the <a href="https://www.parmenides-foundation.org/news/parmenides-foundation-wins-erc-synergy-grant">Parmenides Foundation</a> along with 3 other PIs, received a 13 million Euro grant by the European Research Council (ERC) to do just that. The six-year project consists of a team of biologists and chemists across a number of universities with the aim of producing metabolically active cells that grow, divide, and evolve within a chemical system.</p>

<blockquote>

<p>''Our approach to creating the first artificial chemical living system takes the following steps: (1) Identification of new, and development of existing, autocatalytic (super)systems that function as chemical (and informational) replicators. (2) Coupling of metabolism with chemical replicators. (3) Coupling of autocatalysis to compartment growth and division. (4) Synthesis of a chemical supersystem comprising all three components (replication, metabolism and compartmentalisation). (5) Demonstrating minimal Darwinian evolution upon subjecting the systems synthesized in 1-3 to out-of-equilibrium selection regimes. (6) Approaching a minimal living system by enhancing of the evolvability of the triple systems developed in 4.''</p>

</blockquote>

<p>Though many of the news articles of this project are behind paywalls, you can read more details about the project <a href="https://www.parmenides-foundation.org/news/parmenides-foundation-wins-erc-synergy-grant">on the Parmenides Foundation website</a>.</p>

<h1 id="bactoneurons">Bactoneurons</h1>

<p>Shared by Lana</p>

<p><img alt="An illustration of two containers with bacteria receiving questions as math problems and &quot;replying&quot; yes or no" src="https://alife-newsletter.github.io/Newsletter/images_edition_020/bactoneuron.png" /></p>

<p>Graphical abstract by Sangram Bagh</p>

<p>You may have heard of using computers to simulate bacteria, but have you heard of using bacteria to perform computations?

<a href="https://www.nature.com/articles/d44151-024-00175-8">That is what a team at the Saha Institute of Nuclear Physics (!) in India did in this paper</a>.</p>

<p>They created different types of <em>e. coli</em> so that each type could be used to perform one type of computation, and used those bacterial cells to emulate a computational neural network. Chemicals are used as inputs to the network, and the output is read as proteins created by the bacteria. The team managed to solve tasks such as asking whether a small number is prime or not! All hail the bactoneurons.</p>

<h1 id="hiring-postdoctoral-researcher-position-in-biologically-inspired-artificial-intelligence">Hiring: Postdoctoral researcher position in Biologically Inspired Artificial Intelligence</h1>

<p>Shared by Kai Olav Ellefsen, University of Oslo</p>

<p><strong>Links:</strong></p>

<ul>

<li><a href="https://www.jobbnorge.no/en/available-jobs/job/273057/dstrain-msca-postdoctoral-fellowships-in-computational-and-natural-sciences-up-to-18-positions">Job Description</a></li>

<li><a href="https://www.uio.no/dscience/english/dstrain/research-areas2025/informatics/biologically-inspired-artificial-intelligence-for-/index.html">Specifics on the position related to bio-inspired AI</a></li>

</ul>

<p><strong>Postdoctoral researcher position in Biologically Inspired Artificial Intelligence for Adaptive and Efficient Robots at the University of Oslo</strong></p>

<p>The position is funded through DSTrain - a 5-year postdoctoral programme that will award 36 postdoctoral fellowship positions of 36 months each in two calls over the programme period within the overarching frame of data science. The programme will train researchers and innovators with disciplinary, interdisciplinary and transferable skills and a foundation in data science methods enabling them to become Europe’s digital leaders across disciplines and sectors.</p>

<p>Salary range: 49.000 - 56.000 EUR depending on qualifications</p>

<h1 id="tolvera-at-google-summer-of-code-2025">Tölvera at Google Summer of Code 2025</h1>

<p>Shared by Jack Armitage, Tölvera</p>

<p>Tölvera has been accepted to Google Summer of Code 2025, as a sub-organisation under the Python Software Foundation! 🎉</p>

<p>Tölvera is a Python library designed for composing together and interacting with basal agencies, inspired by fields such as artificial life (ALife) and self-organising systems. It provides creative coding-style APIs that allow users to combine and compose various built-in behaviours, such as flocking, slime mold growth, and swarming, and also author their own.</p>

<p>Google Summer of Code (GSoC) is a global program that offers new contributors over 18 an opportunity to be paid for contributing to an open source project over a three month period.</p>

<p>To find out more and learn how to apply, <a href="https://afhverjuekki.github.io/tolvera/gsoc">read Tölvera's GSoC page</a>.</p>

<p>Discussion will take place on the Tölvera Discord's #gsoc channel</p>

<h1 id="obelisks-a-new-class-in-the-tree-of-life">Obelisks: A new class in the tree of life</h1>

<p>Shared by Lana</p>

<p><strong><a href="https://www.biorxiv.org/content/10.1101/2024.01.20.576352v1">Preprint at Biorxiv</a></strong></p>

<p><strong><a href="https://www.sciencealert.com/obelisks-entirely-new-class-of-life-has-been-found-in-the-human-digestive-system">Pop-sci writeup at Science alert</a></strong></p>

<p><img alt="obelisk" src="https://alife-newsletter.github.io/Newsletter/images_edition_020/obelisk.png" /></p>

<p>An analysis of Obelisk Alpha, one of the types of obelisks discovered by the team. Credit: Ivan N. Zheludev, Robert C. Edgar, Maria Jose Lopez-Galiano, Marcos de la Peña, Artem Babaian, Ami S. Bhatt, Andrew Z. Fire</p>

<p>In a preprint published last year, scientists announced that they had found RNA-based elements that, despite having a lot in common with viruses, do not have a protective coating: their RNA is just rolled in the shape of a rod and exposed to the outside world. This makes them an entirely new class of life, right next to viruses and bacteria. The researchers named these rods of RNA "obelisks".

While it is unclear what obelisks actually do, they seem to be very numerous and can be found inside the human gut: obelisks were detected in up to 10% of the data analyzed by the research team. Even more striking, once they knew what to look for, the researchers found evidence of obelisk RNA in existing public datasets.

What other classes of life could we be missing? And could ALife simulations point out these gaps in our understanding of the tree of life?</p>

<h1 id="paper-review-collective-intelligence-of-the-artificial-life-community-on-its-own-successes-failures-and-future-rasmussen-et-al-2003">Paper Review - Collective Intelligence of the Artificial Life Community on Its Own Successes, Failures, and Future (Rasmussen et al., 2003)</h1>

<p>Written by <a href="http://imytk.github.io">Imy</a></p>

<p>In a departure from typical ALife research, this paper offers a refreshing introspective view of our field and community, and so I really wanted to bring it to people's attention. Rasmussen et al.'s 2003 study, <a href="https://direct.mit.edu/artl/article-abstract/9/2/207/2428/Collective-Intelligence-of-the-Artificial-Life">'Collective Intelligence of the Artificial Life Community on Its Own Successes, Failures, and Future,'</a> presents a rare qualitative survey of ALife practitioners (specifically, some of the attendees at the Artificial Life VII conference), offering a snapshot of the community's self-perception at the time. Perhaps some of you reading this even remember filling in this survey!</p>

<p>Attendees of the Artificial Life VII conference were asked to complete a web-based survey, seeking to collect their opinions on the successes and failures of ALife as a scientific discipline, as well as the organisation of the wider ALife community. Respondents cited the advancement of bottom-up modeling, sharpening the definition of life, and helping to better understand evolution as some of the main accomplishments of the field, but also voiced concerns regarding the field's overly-theoretical focus, methodological rigor, and lack of connection with other disciplines. </p>

<p>The paper provides a nice historical glimpse into the community's perception of its own maturity and direction, and is certainly worth reading if you're curious to see how the community perceived itself in the early 2000s. Given how much progress we have seen in ALife (both as a field and a community), I (personally) think it would be interesting to replicate this study twenty years on to see how these opinions may have changed. </p>

<h1 id="40-years-of-artificial-life-conferences">40 Years of Artificial Life Conferences</h1>

<p>By Jitka Cejkova</p>

<p><img alt="A colorful banner with the number 40 in red and purple and blue, and the text &quot;Celebrate 40 years of Artificial Life" src="https://alife-newsletter.github.io/Newsletter/images_edition_020/celebrate.png" /></p>

<p>The first Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems took place in September 1987. The 40th anniversary of the artificial life conference series is approaching! In honor of this milestone, I am planning to prepare a book and would greatly appreciate your help in gathering materials to support its creation or to celebrate the anniversary in another way.</p>

<p>To begin, I would like to ask for your cooperation in identifying which ALIFE or ECAL conferences you attended. If you could kindly <a href="https://forms.gle/yvZivLcJwr9HQgYz9">mark the relevant conferences in this first simple form</a>, that would be incredibly helpful.</p>

<p>I would also welcome any materials and notes you might have related to these conferences. For this purpose, I’ve prepared this <a href="https://forms.gle/ztydm653jbKqGGSy7">second form</a>. If you could scan or photograph any relevant materials (printed materials, programs, posters, badges, conference gifts, etc.), I would greatly appreciate it. The older, the better! Additionally, your personal stories and memories related to the artificial life community would be of great interest to me. This could include personal anecdotes, key scientific moments, stories about key figures (whether they are still with us or have sadly passed), as well as your overall impressions, experiences, or any memories related to the artificial life field and past conferences.</p>

<p>I would be especially grateful to hear from those of you who are ALIFE "veterans," including organizers or participants from previous years who might be willing to answer follow-up questions.</p>

<p>I would also appreciate it if you could share this call for contribution with your ALIFE colleagues, including retired members or those who were once actively involved in the conferences.</p>

<p>Thank you!</p>

<p>Jitka Čejková</p>

<p>(Education and Outreach Chair of The International Society for Artificial Life)</p>

<p>email: robot100.cz@gmail.com </p>

<h1 id="conferences-and-calls">Conferences and Calls</h1>

<p>It's quite a busy time for conference calls at the moment! Here is a short list of conferences and other symposia that have active calls. Special thanks to Eleni Nisioti at IT University of Copenhagen.</p>

<ul>

<li>Gecco Workshop: <a href="https://evolving-self-organisation-workshop.github.io/">Evolving Self-organisation</a>. Málaga, Spain from July 14 to July 18 (Virtual and In-Person). Submission deadline: March 26, 2025. </li>

<li><a href="https://ecta.scitevents.org/">Evolutionary Computation Theory and Applications</a> (Virtual and In-Person in Marbella, Spain). October 22-24 2025. Regular paper submission: May 19th 2025.</li>

<li><a href="https://www.animalbehaviorsociety.org/2025/abstracts.php">The Animal Behavior Society</a> (Virtual and In-Person in Baltimore, Maryland). July 8-12 2025. Abstract Submission Deadline: March 21st 2025.</li>

<li><a href="https://icsr2025.eu/calls">International Conference on Social Robotics + AI</a> (In Person in Naples, Italy). September 10-12th 2025. Full Papers submission: March 28th 2025.</li>

<li><a href="https://embodied-intelligence.org/">Embodied Intelligence 2025</a> (Online). April 2-4 2025. Free registration.</li>

<li><a href="https://www.ro-man2025.org/">RO-MAN 2025</a> (Eindhoven and Online). Full papers submission deadline: March 20th 2025.</li>

<li><a href="wivace2025.diism.unisi.it">WIVACE 2025XIX International Workshop on Artificial Life and Evolutionary Computation</a>. Siena, Italy. September 3-4 2025. Abstract/Paper submission: May 30th 2025</li>

<li>And finally, the <a href="https://2025.alife.org">ALIFE 2025 conference</a> has published several calls for special sessions, workshops, and tutorials. The call for papers is officially going live soon, but the deadline for submissions is May 4th! Mark your calendars!</li>

</ul>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The ALife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino

- Martha Emerson</p>

<p>The newsletter is sent by e-mail and can also be accessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 19th edition of the Alife Newsletter, December 2024</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_019.html</link>
  <guid>edition_019</guid>
  <pubDate>20 Dec 2024 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 19th issue of the Alife Newsletter! The theme for the newslettert is "Together", thinking about the holidays seasons that are fast approaching.</p>

<p>If you get together with your friends over the New Year's break, how about showing them some alife-y news from this newsletter, as a conversation starter?</p>

<p>This time we are recommending a youtube channel about cute (and sometime scary) bears that evolve, and also an interactive slime mold simulation for those feeling more adventurous. Or maybe you would appreciate a psychedelic video about artificial plants?</p>

<p>On a more academic side, we bring a call for a special issue on Artificial Life in the Nature Portfolio Journal (NPJ series), and a review of the recent Low Carbon Computing Workshop. Also don't forget to prepare yourself for ALIFE 2025, in Kyoto this year.</p>

<p>And if you are feeling lost, we bring a message from a company that is reaching out to young alifer's researchers to help them figure out possible career paths after they acquire their PhDs.</p>

<p>If you are Japanese or a Japanese speaker, you might be interested in the <a href="https://sites.google.com/view/alifenewsletterjapan/home">Japanese Version of the Alife Newsletter</a>, recently released by ALIFE researchers in Japan with the goal of strenghtening the community over there!</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">contribution form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other Alifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel</p>

<div class="toc">

<ul>

<li><a href="#another-simulation-youtube-channel-8-little-bears">Another Simulation Youtube Channel: 8 Little Bears</a></li>

<li><a href="#interactive-physarum">Interactive Physarum</a></li>

<li><a href="#call-for-papers-unnatural-histories-investigating-the-improbable-with-experimental-evolution-and-artificial-life">Call For Papers: Unnatural Histories: Investigating the Improbable with Experimental Evolution and Artificial Life</a></li>

<li><a href="#low-carbon-computing-2024-workshop">Low Carbon Computing 2024 Workshop</a></li>

<li><a href="#odd-bizarre-plant-forms">Odd: bizarre plant forms</a></li>

<li><a href="#career-development-hints-for-emerging-researchers">Career Development Hints for Emerging Researchers</a></li>

<li><a href="#recruiting-alife-2025-reviewers">Recruiting: ALife 2025 reviewers</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="another-simulation-youtube-channel-8-little-bears">Another Simulation Youtube Channel: 8 Little Bears</h1>

<p>By Claus</p>

<p>In recent years, several youtube channels featuring evolution simulators 

have sprung into existence. They are great, and we hope to feature more of 

them here (send us your favorite!).</p>

<p>You might remember "The Bibites", featured in the <a href="https://alife-newsletter.github.io/Newsletter/edition_004.html">4th edition of the newsletter</a>, with virtual individuals with a quite detailed internal biology.</p>

<p>This time we want to feature <a href="https://www.youtube.com/@EightLittleBears">"8 little bears"</a>, a channel which also describes an evolution simulation using the Unity engine. This time, the simulator focuses in the environment and the ecological relations between the creatures, such as predation, competition, grouping and migration. </p>

<p>In this simulation, each cell has different temperature, rainfall, and amount of biological matter, affecting the ability of the cell to support the virtual creatures. This in turn leads to interesting emergent ecological relations such as overpopulation, competition, migration, etc.</p>

<p>Each video lasts between 10-20 minutes, and features some small change to the creatures or the environment of the simulation, such as new diets, or a bigger map. The authors has a great eye to the visual site, with cute graphics for the creatures and environment that makes the simulation come alive, and fun to watch.</p>

<p>I hope you enjoy them, and again, <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">let us know if you have a suggestion of a nice channel with alife-y content</a>!</p>

<h1 id="interactive-physarum">Interactive Physarum</h1>

<p>shared by Lana</p>

<p>You may have seen Slim Mold simulations before, but have you seen many <em>interactive</em> slime mold simulations?

"<a href="https://github.com/Bleuje/interactive-physarum">Interactive physarum</a>" by user Bleuje (Etienne Jacob) on github is an interactive exploration of the parameter space leading to slime-mold-like patterns. This work is based on the work of <a href="http://cargocollective.com/sagejenson/physarum">Sage Jenson</a>.

Go visit Etienne Jacob's project to see beautiful screenshots and run the simulation, or watch the demo video <a href="https://www.youtube.com/watch?v=4hLtjlaVzsk">here</a>.

In fact, go have a look at <a href="https://www.youtube.com/@bleuje">the entire channel</a>, you won't regret it!</p>

<p><img alt="Screenshot showing a physarum pattern from the simulation" src="https://alife-newsletter.github.io/Newsletter/images_edition_019/phys.png" /></p>

<p>Image credit: Etienne Jacob</p>

<h1 id="call-for-papers-unnatural-histories-investigating-the-improbable-with-experimental-evolution-and-artificial-life">Call For Papers: Unnatural Histories: Investigating the Improbable with Experimental Evolution and Artificial Life</h1>

<p>Shared by Lana</p>

<p><a href="https://www.nature.com/npjcomplex">NPJ Complexity</a> is launching a special collection on Artificial Life. Submission deadline: September 2025!</p>

<p>"<a href="https://www.nature.com/collections/hahjddiich">Unnatural Histories: Investigating the Improbable with Experimental Evolution and Artificial Life</a>"</p>

<p>The study of life has traditionally focused on documenting and understanding what exists and what has existed — the actual rather than the possible. However, as François Jacob astutely observed, our scientific understanding is inherently shaped by the limitations of our collective imagination. It is only through confronting the vast landscape of what <em>could be</em> with what actually <em>is</em> that we begin to comprehend the fundamental principles governing living systems.</p>

<p>By leveraging modern tools from Experimental Evolution, Synthetic Biology, and Artificial Life, researchers can now empirically investigate paths not taken by natural evolution and gain concrete experimental insights rather than being limited to theoretical speculation. In this spirit, npj Complexity is launching a special collection on "Unnatural Histories". This collection will showcase research that goes beyond conventional natural history to examine alternative biological worlds and unexplored evolutionary trajectories.</p>

<p><img alt="Illustration showing a plant growing in a futuristic petri dish" src="https://alife-newsletter.github.io/Newsletter/images_edition_019/npj.jpg" /></p>

<h1 id="low-carbon-computing-2024-workshop">Low Carbon Computing 2024 Workshop</h1>

<p><em>By Claus</em></p>

<p>With the growing cost of computing in ICT and Machine Learning, and concerns about climate change and sustainability, some researchers have started to look at how to develop alternate computing systems, including new devices, programming languages, and computational processes, that have a smaller impact on our environment.</p>

<p>In this context, the <a href="https://www.sicsa.ac.uk/loco/loco2024/">1st International Workshop on Low Carbon Computing (LOCO)</a> was held early in December, gathering people with all sorts of interesting ideas about how to measure and reduce the environmental impact of computing. The abstracts and short papers presented at the workshop are now available online, and soon the videos of the presentations will be as well.</p>

<p>For me as an ALIFE researcher, there is something about low carbon and permacomputing that goes beyond the (very important) concerns about sustainability and environmental impact.</p>

<p>The evolution of life on earth was a process that took hundreds of millions of years. Even though it was a world spanning process, it took many false starts and a long process for life to evolve from the "primordial soup" to the diversity of species that we have today. How can we expect our computational process to be any different?</p>

<p>Although we are not there yet (?), I do believe that eventually we will want to create digital evolution simulations, or even robots, that will run for decades, if not more. This goes against the trend of our technological landscape, where the lifetime of each generation of digital devices seems shorter than the last. </p>

<p>I invite the Alife community to consider computing platforms that can robustly work for years, independently from changes around itself and without putting undue burden on the environment. </p>

<h1 id="odd-bizarre-plant-forms">Odd: bizarre plant forms</h1>

<p>Shared by Lana</p>

<p><a href="https://vimeo.com/1018644295?share=copy">"Odd"</a> is a beautiful, psychedelic exploration of artificial plant forms by artist Hiroshi Takagishi. From the video description:</p>

<p>"Odd is inspired by the contradictions of bizarre plant forms that reveal hidden regularities and beauty within seemingly chaotic nature. The unique curves and protrusions of the bizarre plants suggest potential movement. I imagines the moment when this stationary plant is in motion and recreates it as media art."</p>

<p><img alt="Screenshot from the movie showing a bubbling cactus" src="https://alife-newsletter.github.io/Newsletter/images_edition_019/odd.png" />

Image credit: Hiroshi Takagishi</p>

<h1 id="career-development-hints-for-emerging-researchers">Career Development Hints for Emerging Researchers</h1>

<p><em>Shared by Andrew Cusick, ProPhounD Co-Founder, and Jevin Lortie, PhD</em></p>

<p>ProPhounD and the Emerging Researchers Association (ERA) recently 

hosted a career development event for organizations hiring talent 

with advanced degrees and professionals that are a match for those 

roles. To respond to the call from attendees seeking guidance on 

how to find a purpose-driven career, Andrew Cusick, ProPhounD 

Co-Founder and Jevin Lortie, PhD, compiled a road map from PhDs 

who’ve pursued alternate career paths with their advanced degrees 

to help you “get unstuck”.</p>

<p><a href="https://www.pro-phound.com/blog/gettingunstuck">More details about this road map, and ideas about the many possible 

paths for a PhD can be read at ProPhound's full blog post</a></p>

<h1 id="recruiting-alife-2025-reviewers">Recruiting: ALife 2025 reviewers</h1>

<p>By Lana</p>

<p>The ALife 2025 conference is looking for reviewers! </p>

<p>Are you involved in ALife or ALife-related research?

Are you interested in reviewing papers, helping authors improving their work, and making sure that high quality papers are presented at the conference?

Self-nominate by emailing lana.sinapayen@gmail.com. Student nominations welcome!</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 18th edition of the Alife Newsletter, October 2024</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_018.html</link>
  <guid>edition_018</guid>
  <pubDate>01 Oct 2024 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 18th issue of the Alife Newsletter! We hope you enjoyed the ALife conference if you joined it, anfor those who didn't, we hope to see you for ALife 2025 in Kyoto! 

But if if you couldn't be there this year, don't worry! Gabriel has written a retrospective for this edition of the newsletter. Also, you can now read the <a href="https://alife-newsletter.github.io/Newsletter/edition_017.html">online version of edition 17</a>, that was available physically during the conference.

<strong>The theme of the December edition will be "TOGETHER". <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">Send us</a> your contributions, paper reviews, art, ALifey videos before November 30th to be featured in the TOGETHER edition!</strong></p>

<p>In this edition, we are happy to share several contributions from our readings about the projects that they have been working on, including a tool for HyperNEAT, a multi-agent library, and even a picture book version of a paper!</p>

<p>Also in this edition, Lana review's Greg Egan's newest book, which is based on existing ALife research. You can also read about a fascinating project where a mushroom is used as a robot's brain!</p>

<p>Finally, we would like to highlight our side project <a href="https://github.com/ALife-Newsletter/alife_social">Alife Socials</a>. This is a list of the different social media used by alifers (Mastodon, Bluesky, Threads, and even good old blogs!) Make sure to add yours too. <strong>Huge thanks to Adam Stanton for formatting and automating the page!</strong></p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">contribution form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other Alifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel</p>

<div class="toc">

<ul>

<li><a href="#contributions-from-the-readers">Contributions from the readers</a></li>

<li><a href="#software-review-the-simsulator-michael-finn">Software Review: The Simsulator (Michael Finn)</a></li>

<li><a href="#software-showcase-call-for-collaborators-tolvera-jack-armitage">Software Showcase &amp; Call for Collaborators: Tölvera (Jack Armitage)</a></li>

<li><a href="#book-review-morphotrophic-by-greg-egan-2024">Book Review: Morphotrophic, by Greg Egan (2024)</a></li>

<li><a href="#the-carpentopod">The Carpentopod</a></li>

<li><a href="#alife-2024-retrospective">ALife 2024 Retrospective</a></li>

<li><a href="#an-oyster-mushroom-for-a-brain">An Oyster Mushroom for a Brain</a></li>

<li><a href="#links-roundup">Links roundup</a></li>

<li><a href="#domestic-camouflage">Domestic Camouflage</a></li>

<li><a href="#upcoming-deadlines-and-events">Upcoming Deadlines and Events</a></li>

<li><a href="#game-of-life-on-a-klein-bottle">Game of Life on a Klein Bottle</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="contributions-from-the-readers">Contributions from the readers</h1>

<p>arranged by Claus</p>

<p>Several of our readers sent their projects to share through the newsletter. Take a look!</p>

<p>If you would like to talk about your project (even if it is still in progress), send us a message through the <a href="https://forms.gle/QpQ68xhvSMt4wiv89">feedback form</a>, send us a message through discord (we are all on the ISAL discord server), or send a message to our <a href="https://fediscience.org/@alifenewsletter">Mastodon account</a>! </p>

<p>We are always happy to highlight the work of our readers. Please add a short blurb (300 words or less) describing what you want to share. Pictures are specially welcome!</p>

<h2 id="how-to-train-your-drone-a-pictorial-by-joseph-la-delfa">"How to Train your Drone", a pictorial by Joseph La Delfa:</h2>

<p>What if you wrote a paper in the shape of a picture book? That's what Joseph did with his paper published at DIS24, about the design and testing of a system called "how to train your drone", that grants users partial control over the shape of the drone's sensory apparatus. In doing so, bespoke control mappings and behaviour emerges.</p>

<p>You can <a href="https://dl.acm.org/doi/10.1145/3643834.3660737">read it in the ACM digital library</a> -- take a look, the paper is very pleasing to the eye! We need more creative designs to break away from the boring walls of text-and-equations.</p>

<p>The paper also draws some parallels between Alife and “research through design”. RtD is a family of design practices that focus more on emergence than problem solving. Joseph thinks there should be more bridges between the two communities. </p>

<p>You can see <a href="https://youtu.be/OWNibNLjtdU">Joseph talk about the parallels between the two communities at the ERA workshop in this video!</a> He also recommends a video documentary about RtD called <a href="https://vimeo.com/961000450">Permission to muck about</a>.</p>

<h2 id="hyperneat-substrate-design-tool-by-b-from-the-isal-discord-server">HyperNEAT Substrate design tool, by b from the ISAL Discord Server</h2>

<p>b has been developing a tool for defining HyperNEAT substrates to help simplify the process. The tool is currently used by them for their own projects, but they are looking for people to check their work and provide feedback!</p>

<p><a href="https://tkwn2080.github.io/substrate-designer">You can check you the tool in b's website.</a> The basic idea is to allow the user to visually design semi-complex HyperNEAT substrates in a way that can easily interface with code. In particular, b is using this to construct spiking neural networks.</p>

<h2 id="exploring-emergent-complexity-with-mettagrid-by-david-bloomin">Exploring Emergent Complexity with MettaGrid, by David Bloomin</h2>

<p>David is developing MettaGrid, an open-source environment for investigating competition, cooperation and alignment in multi-agent AI systems. It’s built to be highly performant, processing 800k+ steps per second, enabling rapid experimentation and analysis of complex social dynamics.</p>

<p>Key features:

- Fully customizable, allowing arbitrary objects and actions

- Novel reward-sharing mechanisms mimicking familial bonds

- Highly multi-agent supporting anywhere from a few to a few thousand agents

- Integrated with a reinforcement learning framework, allowing for fast and easy training of policies</p>

<p>MettaGrid provides a testbed for studying the evolution of cooperation, altruism, and general intelligence in artificial agents. Its flexible, open-ended design allows for easy adaptation to specific research interests.</p>

<p>David invites the readers to join them in pushing the boundaries of artificial life and multi-agent systems. Your expertise could be crucial in unlocking new insights into AI alignment and cooperation.</p>

<h3 id="links">Links:</h3>

<ul>

<li><a href="https://github.com/Metta-AI/mettagrid">MettaGrid environment code</a></li>

<li><a href="https://github.com/Metta-AI/metta">MettaAI project, research plan, and code</a></li>

<li><a href="https://discord.gg/XrGETJYSe7">Discord</a></li>

</ul>

<h1 id="software-review-the-simsulator-michael-finn">Software Review: The Simsulator (Michael Finn)</h1>

<p>Shared by <a href="http://twitter.com/imy_tk">Imy Khan</a></p>

<p>Making ALife more accessible to the masses is one of the coolest things our community can do.</p>

<p>Michael Finn has reintroduced Sims' famous <a href="https://karlsims.com/evolved-virtual-creatures.html">Evolved Virtual Creatures</a> into the world: this time, no coding required! The Simsulator is an open-source platform for simulating Sims' Evolved Virtual Creatures, providing tools to evolve, breed, experiment on the virtual creatures. This is a really great piece of software for those who haven't yet had a chance to be hands-on with EVC and want an intuitive way to play with (and study) them. It's also a really great educational tool, providing a really accessible, intuitive way to explore artificial life and evolutionary computation.</p>

<p><img alt="Simsulator" src="https://github.com/mycoolfin/the-simsulator/raw/main/Media/ground_trial.gif" /></p>

<p><img alt="Simsulator" src="https://github.com/mycoolfin/the-simsulator/raw/main/Media/underwater.gif" /></p>

<p>This software was also demonstrated at ALIFE 2024, and you can read the corresponding paper <a href="https://direct.mit.edu/isal/proceedings/isal2024/36/84/123510">here</a>. The Simsulator works across all platforms, is packed full of interesting sandbox features, and (from what I hear) has a VR version in the works!</p>

<p><a href="https://github.com/mycoolfin/the-simsulator?tab=readme-ov-file">Download The Simsulator</a></p>

<h1 id="software-showcase-call-for-collaborators-tolvera-jack-armitage">Software Showcase &amp; Call for Collaborators: Tölvera (Jack Armitage)</h1>

<p>Edited by Imy Khan</p>

<p>Jack Armitage is a postdoctoral researcher at the <a href="https://iil.is/">Intelligent Instruments Lab, Iceland</a>: an interdisciplinary research lab that investigates the role of artificial intelligence in new musical instruments. </p>

<p>Based on a desire for more diversity of real-time AI (and ALife) in music interaction, Jack developed a library called <a href="https://intelligent-instruments-lab.github.io/tolvera/">Tölvera</a>. Tölvera is a Python library designed for composing together and interacting with basal agencies, inspired by fields such as artificial life (ALife) and self-organising systems. It provides creative coding-style APIs that allow users to combine and compose various built-in behaviours, such as flocking, slime mold growth, and swarming, and also author their own. </p>

<p><a href="https://www.youtube.com/watch?v=ahSXjnYHZLU"><img alt="Tölvera" src="https://img.youtube.com/vi/ahSXjnYHZLU/maxresdefault.jpg" /></a></p>

<p>Check out the relevant paper, "Tölvera: Composing With Basal Agencies" <a href="http://iil.is/pdf/2024_nime_armitage_et_al_tolvera.pdf">here</a>.</p>

<p>Call for Collaborators: Jack is looking for researchers from across ALife, biology and complex systems to collaborate with in using and extending the software project Tölvera.

They can be contacted at jack@hi.is or via their <a href="https://discord.gg/ER7tWds9vM">Discord</a></p>

<h1 id="book-review-morphotrophic-by-greg-egan-2024">Book Review: Morphotrophic, by Greg Egan (2024)</h1>

<p>Shared by Lana Sinapayen</p>

<p>What if we couldn't take multicellularity for granted, and every cell had the potential to revert to unicellularity it it felt like it?

What if these unicellular entities could be convinced to get back to communal life, and integrate another body plan?

Many of Greg Egan's are very popular in the ALife community, but this one is special: it was inspired by the work of the team behind the Xenobots project, work that received the 2021 Award for Outstanding Publication from the International Society for Artificial Life! </p>

<p>I couldn't put the book down. Beyond the raw interest of the scientific concepts, the social and philosophical implications are so well integrated in the world building that you'll find yourself empathising with many of the characters even if when you don't agree with their motivations.

A must-read.</p>

<p>Find a free <a href="https://www.gregegan.net/MORPHOTROPHIC/00/MorphotrophicExcerpt.html">excerpt from Morphotrophic on Greg Egan's website.</a></p>

<h1 id="the-carpentopod">The Carpentopod</h1>

<p>Shared by Lana</p>

<p>Have you seen <a href="https://www.youtube.com/watch?v=xKDY4yWxfJM">the viral videos</a> of this walking coffe table?</p>

<p><img alt="a wooden table that looks like a robot" src="https://www.decarpentier.nl/wp-content/uploads/carpentopod_with_joystick_grey-3-1536x1256.jpg" /></p>

<p>Giliam de Carpentier designed this table by using genetic algorithms to select the best linkages for the table legs. For those familiar with Theo Jansen's strandbeests, the carpentopod's linkages are actually more compact and allow for a more robust walking gait.

Evolution, often one step ahead of human design... </p>

<p>Find all the details of Giliam's thought process and experiments on <a href="https://www.decarpentier.nl/carpentopod">his blog</a>.</p>

<p>Thank you Giliam for giving us permission to share your pictures and videos!</p>

<h1 id="alife-2024-retrospective">ALife 2024 Retrospective</h1>

<p>By <a href="https://sites.google.com/view/gabrieljulianoseverino/home">Gabriel J Severino</a></p>

<p>I feel as though the 2024 conference theme, “Exploring New Frontiers,” couldn’t have come at a better time. For over 30 years, the ALife community has embraced a spirit of exploration, often prioritizing discovery and innovation over immediate practical application. This is what makes the field so fascinating—there’s a real excitement in the unknown. The trade-off between exploring new ideas and exploiting established ones is a challenge every scientific field faces, and ALife has clearly hit the ‘explore’ button with vigor.</p>

<p>The theme felt particularly resonant this year because it touches on a broader question: what does it mean to explore new frontiers in science today? In the age of AI and computational advances, exploration often feels synonymous with pushing technological boundaries, but in ALife, it also means embracing creative, interdisciplinary approaches to understanding life itself. The sheer diversity of ideas and approaches showcased at ALife 2024 was a testament to this mindset. From evolutionary robotics to synthetic biology, from digital organisms to emergent social behaviors, the conference truly reflected breadth of research ecompasses by ALife.</p>

<p>As the conference theme suggests, this is also a good time to reflect on what a “fundamental science of artificial life” might look like. The field has long been about understanding the principles of life and intelligence, but the boundaries of ALife remain somewhat fluid, which can be both a strength and a limitation. This flexibility allows ALife to engage with broad interdisciplinary methodologies, integrating several different discplines, such as computational modeling, experimental biology, and robotics. However, the absense of a clearly defined set of theoretical foundations can make it difficult to identify exactly what scientific questions ALife, as a discipline, is uniquely positioned to answer. Other fields, such as mathematical biology or cognitive science, also grapple with questions about life and intelligence. What makes ALife distinct?</p>

<p>These questions of identity and purpose seemed to continually reemerge in conversations with a variety of different researchers (both from within ALife and from those visiting from other fields) throughout the week, reflecting a tension between exploration and exploitation—the same tension faced by any field navigating the fine line between speculative, fundamental research and more applied, outcome-driven work. In ALife, the spirit of exploration is very much alive. But there’s also an emerging recognition of the importance of balancing this exploration with clearer scientific foundations. This balance is crucial for the continued development of the field, as it provides the grounding necessary for sustained progress while maintaining the sense of intellectual curiosity that makes ALife so unique.</p>

<p>What truly stood out to me, however, was the sense of community and collaboration that permeated the event—particularly among early-career researchers. The <a href="https://sites.google.com/view/emergingresearchersinal">Emerging Researchers in Artificial Life (ERA)</a> events were a huge success, providing a great oppurtunity for newer members of the ALife community to connect, share their work, and build collaborations. These events not only helped break down barriers but also fostered a genunie connection between people excited about the same niche things. ERA events, such as the "coffee" roundtable (which was really just a little party) and the always-entertaining Academic Karaoke night, allowed folks to really connect with each other in a fun, relaxed environment.</p>

<p>Personally, while the intellectual stimulation and inspiration were immense, the most rewarding part of the conference was the opportunity to meet and connect with so many awesome and brilliant people.</p>

<p>If you couldn't attend <a href="https://2024.alife.org/index.html">ALife 2024</a>, or if you had to prioritize one talk over another, you can still check out the work that peaks your interest in the <a href="https://direct.mit.edu/isal/proceedings/isal2024/36/1/123556">proceedings</a>. Also, be sure to check out the <a href="https://sites.google.com/view/vcc-2024/2024-winner">Virtual Creatures Competition</a> or check out this <a href="https://www.youtube.com/playlist?list=PLYIVn5Esp9JAFXt0CsizpD1r3CBmyRYZJ">playlist</a> showcasing some of the finalists.  </p>

<h1 id="an-oyster-mushroom-for-a-brain">An Oyster Mushroom for a Brain</h1>

<p>"By growing mycelium into the electronics of a robot, we were able to allow the biohybrid machine to sense and respond to the environment" <a href="https://news.cornell.edu/stories/2024/08/biohybrid-robots-controlled-electrical-impulses-mushrooms">source: Cornell University press release</a></p>

<p><img alt="picture of the crawling robot from Cornell's website" src="https://alife-newsletter.github.io/Newsletter/images_edition_018/robot.png" /> </p>

<p>In this research, the mushroom's mycelium (hair-thin root-like organs) acts as both a sensor and a controller for a pair of robots. We've seen plant-robot and slime mold-robot integrations before, but oyster mushroom is a first!</p>

<p>(Paywalled) Mishra, Anand Kumar, et al. "Sensorimotor control of robots mediated by electrophysiological measurements of fungal mycelia." Science Robotics 9.93 (2024): eadk8019.</p>

<h1 id="links-roundup">Links roundup</h1>

<p>Here is a list of ALife-related papers that were published in the last 2 months:</p>

<ul>

<li>Hiroki Sayama and Chrystopher L. Nehaniv, <a href="https://arxiv.org/html/2402.03961v2#S3">"Self-Reproduction and Evolution in Cellular Automata: 25 Years after Evoloops".</a></li>

<li>Nam H. Le, Richard Watson, Mike Levin, Chrys Buckley, <a href="https://arxiv.org/abs/2409.13254">Emergent Collective Reproduction via Evolving Neuronal Flocks</a></li>

<li>Lapo Frati, Csenge Petak, Nick Cheney, <a href="https://arxiv.org/abs/2409.00853">JaxLife: An Open-Ended Agentic Simulator</a></li>

<li>Dan-Lu Fei, Zi-Wei Wu, Kang Zhang, <a href="https://arxiv.org/abs/2408.17186">"Benefit Game: Alien Seaweed Swarms" -- Real-time Gamification of Digital Seaweed Ecology</a></li>

</ul>

<p>In ALife talks, watch Robert Wagner's (Mechanical Engineering, Binghamton University) talk at the Binghamton Center of Complex Systems (CoCo) Seminar, titled <a href="https://vimeo.com/1012916074">"Inferring Local Interactions from Global Response in Condensed Active Matter: Complex Emergence in the Mechanics of Fire Ant Rafts"</a> from September 25th.</p>

<h1 id="domestic-camouflage">Domestic Camouflage</h1>

<p>Shared by Lana</p>

<p>I came across this gorgeous ceramic art by <a href="http://utsuwamushi.com/">Hori Takaharu</a>, who focuses on insect-like forms camouflaging themselves as household objects.

For my birthday, please send me a <a href="https://utsuwamushi.com/1397/">kintsugi scarab teapot</a>, thank you in advance.</p>

<p>Takaharu graciously allowed us to share pictures with our readers, but you can also find him on <a href="https://www.instagram.com/ceramic_hori/">Instagram!</a></p>

<p><img alt="a white ceramic beetle folds into a flower vase" src="https://alife-newsletter.github.io/Newsletter/images_edition_018/ceramic1.png" /> <img alt="the beetle flower vase with an actual flower inside" src="https://alife-newsletter.github.io/Newsletter/images_edition_018/ceramic2.png" /></p>

<h1 id="upcoming-deadlines-and-events">Upcoming Deadlines and Events</h1>

<p>Check out the upcoming submission deadlines for these ALife related conferences:</p>

<p>The International Society for Artificial Life (ISAL) is seeking proposals to host the Conference on Artificial Life in 2026 and 2027. <a href="https://alife.org/alife-2026-and-2027-call-for-proposals-to-host-conferences/">Check out the call on the ISAL website</a> for more details, including on how to submit your proposal.</p>

<p>Finally, the <a href="https://alife.org/">International Society on Artificial Life (ISAL)</a> is asking for nominations for the 2024 ISAL awards. Make your voice heard about outstanding publications in 2023, outstanding early career scientists, and awards for service, education and outreach, among others. Self-nominations welcome! <a href="https://alife.org/2024-isal-awards-nomination-form/">Learn more about it here</a>.</p>

<h1 id="game-of-life-on-a-klein-bottle">Game of Life on a Klein Bottle</h1>

<p>You have probably seen the Game of Life play on a 2D square with periodic boundaries -- what exits on the right side comes back through the left side, and what goes out from the top comes back from the bottom...

The equivalent of wrapping the flat surface onto a donut.</p>

<p>But have you ever seen the Game of Life play on a Klein surface, where there is no front or back? <a href="https://bsky.app/profile/jbertolotti.bsky.social/post/3l4g6tcgw322n">Now you can</a>, thanks to Jacopo Bertolotti.</p>

<p><img alt="screenshot of the simulation with the game of life playing on a klein bottle" src="https://alife-newsletter.github.io/Newsletter/images_edition_018/klein.png" /></p>

<p>Give Jacopo a follow on Bluesky. Thank you Jacopo for letting us share your simulation!</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 17th edition of the Alife Newsletter, September 2024</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_017.html</link>
  <guid>edition_017</guid>
  <pubDate>08 Sep 2024 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 17th issue of the Artificial Life Newsletter. Like last year, this edition was a physical edition, in tandem with ALIFE 2024, in Denmark. Due to <em>life</em> (not the artificial kind), the digital version was delayed this time, and we apologize for that! As a manner of apology, we'll try to add some little online updates for each of the collaborations below (and maybe some extra text that could not make into the digital format due to space constraints).</p>

<p>The theme for the 17th issue is <strong>connections</strong> -- the yearly conference is the perfect opportunity to connect with new people, ideas and opportunities. With this in mind, we offer you a live list of ALifers social media (that you can join!), a modular origami that you can assemble with others in the conference, and the team's favorite ALife-y books, papers and entertainment for your lunch break or the long way back home. </p>

<p><strong>Don't forget to subscribe!</strong> You can follow us by RSS, or by adding your e-mail to <a href="https://forms.gle/QpQ68xhvSMt4wiv89">this form</a>.</p>

<p><em>Header Image: Modular origami by Ardonik, CC BY-SA 2.0 via Wikimedia Commons</em></p>

<div class="toc">

<ul>

<li><a href="#alife-social-directory">Alife Social Directory</a></li>

<li><a href="#recommendations-from-the-team">Recommendations from the Team</a></li>

<li><a href="#sonobe-modular-origami">Sonobe, Modular Origami</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="alife-social-directory">Alife Social Directory</h1>

<p>Do you want to connect to new ALifers and find out what they're up to?</p>

<p>We have created an online <a href="https://github.com/ALife-Newsletter/alife_social"><em>ALife Social Directory</em></a> that gathers links to the social media accounts of members of the community. It includes Mastodon, Bluesky, Twitter and many others.</p>

<p>You can add your own socials to the directory by <a href="https://forms.gle/GZfgE5Am3mPwo64MA">filling this form</a>, or sending a pull request to the Directory repository!</p>

<p><em>Post-Conference Update:</em> A lot of people have added their socials, and sent code updates to make the directory prettier and easier to understand! Even if you did look at it during the conference, it is a great time to check it out again!</p>

<h1 id="recommendations-from-the-team">Recommendations from the Team</h1>

<p>Need something to read or do on your way home back from the conference? We got you covered, with a list of our favorite papers, books, entertainment and others! Load them up on your computer, and spend some quality time in the plane, or that weekend recovering from the conference. </p>

<p>Note: For the physical newsletter, Gabe made some really nice illustrations for each subsection.</p>

<h2 id="papers">Papers</h2>

<p><img alt="Section Header, a school of fish" src="https://alife-newsletter.github.io/Newsletter/images_edition_017/header_papers.png" /></p>

<ul>

<li><strong>Lana</strong>: <a href="https://sites.socsci.uci.edu/~ddhoff/interface.pdf">"The Interface Theory of Perception"</a>, by D.D. Hoffman. The provocative idea that accurately perceiving reality can be evolutionarily detrimental!</li>

<li><strong>Imy</strong>: <a href="https://doi.org/10.1162/106454600568375">"Artificial Life: Discipline or Method? Report on a Debate Held at ECAL '99"</a>. The question in this paper is worth revisiting and reflecting on even 25 years later, as the breadth and depth of our work develops.</li>

<li><strong>Claus</strong>: <a href="https://arxiv.org/abs/1803.03453">"The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities"</a> (2020). An inspiring and fun survey of cases where evolution gave scientists what they wanted, but not what they needed.</li>

<li><strong>Gabe</strong>: <a href="https://www.jstor.org/stable/1301992">"Geometric Analysis of Shell Coiling: General Problems,"</a> by Raup, D. M. (1966). One of my favorite papers of all time. Examines the space of possible forms for coiled shells using mathematical models in comparison with the shells that are found in real life.</li>

</ul>

<h2 id="books">Books</h2>

<p><img alt="Section Header, a group of large mamals" src="https://alife-newsletter.github.io/Newsletter/images_edition_017/header_books.png" /></p>

<ul>

<li><strong>Lana</strong>: <a href="https://en.wikipedia.org/wiki/The_Evolution_of_Beauty">"The Evolution of Beauty," by R. O. Prum (2017)</a>. Examples of environmental fitness losing to mating fitness (aka beauty), without needing the handicap theory. This is your chance to hear about the Sexy Son Hypothesis...</li>

<li><strong>Mitsuyoshi</strong>: "Mortal Game", by Koichi Harukure. The only books I know that truly require artificial life (or cellular automata) are this one and Permutation City by G. Egan! In an interstellar exploration project, an organically emergent cellular automaton is discovered...</li>

<li><strong>Imy</strong>: <a href="https://www.cambridge.org/fr/universitypress/subjects/physics/statistical-physics/complexity-science-study-emergence?format=HB&amp;isbn=9781108834766">"Complexity Science: The Study of Emergence"</a> by Henrik Jeldtoft Jensen. A great in-depth introduction to the underlying principles of complexity and emergence across many scales. It offers lots of projects and questions within each chapter. My best book purchase of the year.</li>

<li><strong>Claus</strong>: <a href="https://dl.acm.org/doi/10.5555/529507">"Artificial Life: A Report of the Frontier From the Frontier where Computers meet Biology,"</a> by Steven Levy (1993). A person-centric review of our field in its early days. It is fun to see what has changed, and what has stayed the same.</li>

<li><strong>Gabe:</strong> <a href="https://en.wikipedia.org/wiki/East_of_Eden_(novel)">"East of Eden"</a> by John Steinbeck. A beautiful story spanning multiple generations. Wonderfully written characters, flawed and human in a way I’ve not often experienced in many other novels.</li>

</ul>

<h2 id="entertainment">Entertainment</h2>

<p><img alt="Section Header, a group of insects" src="https://alife-newsletter.github.io/Newsletter/images_edition_017/header_entertainment.png" /></p>

<ul>

<li><strong>Lana</strong>: <a href="https://www.newscientist.com/article-topic/dead-planets-society/">The Dead Planets Society, podcast</a>. What if the Earth was a cube, if the moon had moons that had moons, if... applying real astronomy knowledge to unhinged scenarios.</li>

<li><strong>Mitsuyoshi</strong>: <a href="https://screeps.com/">Screeps</a>. A computer game where players deploy bots that autonomously play the game, managing resource metabolism and threats.</li>

<li><strong>Imy</strong>: <a href="https://en.wikipedia.org/wiki/Appleseed_(2004_film)">A series and a movie from the creator of Ghost in the Shell, Masamune Shirow: Appleseed</a>. Stories about genetic engineering, finding out the love of your life has become a cyborg, and just good ol' fashioned futuristic battles with AI overlords. Plus, the art style is beautiful!</li>

<li><strong>Claus</strong>: <a href="https://www.goodreads.com/book/show/25499718-children-of-time">"Children of Time,"</a> by Adrian Tchaikovski (2015): A short sci-fi book about evolution. What else do I need to say? It is wonderful!</li>

<li><strong>Gabe</strong>: John Carpenter’s ``The Thing". My go to movie recommendation. It’s a classic 80s horror with awesome practical effects where you’re always trying to guess who the monster is. Bonus points if you watch it while it’s snowing outside.</li>

</ul>

<h2 id="wildcards">Wildcards</h2>

<p><img alt="Section Header, a group of birds" src="https://alife-newsletter.github.io/Newsletter/images_edition_017/header_wildcard.png" /></p>

<ul>

<li><strong>Lana</strong>: Greg Egan, That's it. All his stories are great and more often than not, relevant to ALife!</li>

<li><strong>Mitsuyoshi</strong>: Tierra. This simulation exemplifies how simple rules can give rise to intricate ecological dynamics. - <strong>Imy</strong>: <a href="https://www.preposterousuniverse.com/podcast/">Sean Carroll's Mindscape Podcast</a>. Incredibly brilliant host who brings on a ton of interesting guests and scholars from many different disciplines.</li>

<li><strong>Claus</strong>: <a href="https://www.lexaloffle.com/pico-8.php">Pico-8: A Fantasy Game Console</a>. It can make not only games, but also cute simulations and it is a great tool for teaching programming. It is also super portable, and has a very friendly community.</li>

<li><strong>Gabe</strong>: Bent’s 2003 album The Everlasting Blink. Amazing album with jazzy samples and the perfect soundtrack for taking a long walk.</li>

</ul>

<h1 id="sonobe-modular-origami">Sonobe, Modular Origami</h1>

<p>Sonobe is an Origami fold that can be joined with other copies of itself to make complex shapes. The physical edition in ALIFE 2024 included an origami paper piece that you could fold and join with the pieces folded by other alifers. But you can still create your own modular origami following the links below!</p>

<p><img alt="Sonobe Folding Instructions in twelve steps." src="https://alife-newsletter.github.io/Newsletter/images_edition_017/sonobe_folding_assembly.png" /></p>

<p>*Sonobe folding instructions image by Cmglee, CC BY-SA 4.0, via Wikimedia Commons)</p>

<p>Follow the instructions in the image above to fold the basic module (steps 1-10). Then you can assemble a pyramid with three modules (steps 11-12). <a href="https://momath.org/mathmonday/math-monday-12-card-star-puzzle/math-monday-introducing-the-sonobe-unit/">Find ideas for more complex assemblies in this link</a></p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>.</p>

<p>Contributions can be short texts about your own projects, or to boost projects that you like. You can suggest cool papers, books or media to cover. We are specially interested in Master and PhD students who want to talk about their research ideas. Do send us a line!</p>



]]></description>
 </item> <item>
  <title>The 16th edition of the Alife Newsletter, May 2024</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_016.html</link>
  <guid>edition_016</guid>
  <pubDate>07 May 2024 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A Word from the Team</h1>

<p>Welcome to the 16th issue of the Alife Newsletter! The theme for this newsletter is <strong>Solarpunk</strong>. Many of us have grown up on "Cyberpunk" -- an aesthetic that imagines the negative runaway effects of technology and capitalism on society. Now that, in true Torment Nexus style, many of those predictions are coming to tuition, a new aesthetic comes up to imagine how we can break into a future where nature, sustainable tech, and society can collaborate with each other. </p>

<p>With this new image in mind, we bring a review of the science fiction books "Solarpunk Creatures", and "The Kaiju Preservation Society". We also highlight a link to the "Solarpunk Conference". </p>

<p>Other news in this newsletter include the new discord servers for the Artificial Life community organized by the International Society of Artificial Life (ISAL); New episodes on Imy's podcast, "What ALife!"; a call for projects from the UKRI; and an online workshop of universal communication from Crosslabs. We also mourn the passing of Daniel Dennet, with an Eulogy from Dave Ackley.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other Alifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel</p>

<div class="toc">

<ul>

<li><a href="#discord-servers-for-the-artificial-life-society">Discord Servers for the Artificial Life Society</a></li>

<li><a href="#whatalife-podcast">WhatALife! Podcast</a></li>

<li><a href="#solarpunk-nature-and-tech">Solarpunk: Nature and Tech</a></li>

<li><a href="#solarpunk-conference-2024-rays-of-resilience">Solarpunk conference 2024: Rays of Resilience</a></li>

<li><a href="#book-reviews-imaginary-lifecycles">Book Reviews: Imaginary Lifecycles</a></li>

<li><a href="#are-boids-the-future-of-self-driving-cars">Are Boids the future of self-driving cars?</a></li>

<li><a href="#100m-ukri-investment-in-future-ai-hubs">$100m UKRI Investment in Future AI Hubs</a></li>

<li><a href="#rest-in-peace-daniel-dennett">Rest In Peace, Daniel Dennett</a></li>

<li><a href="#workshop-summary-the-quest-for-universal-communication">Workshop Summary: The Quest for Universal Communication</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="discord-servers-for-the-artificial-life-society">Discord Servers for the Artificial Life Society</h1>

<p>by <a href="https://conclave.cs.tsukuba.ac.jp/">Claus</a></p>

<p>The International Society for Artificial Life (ISAL), has created a general discord server for discussing matters of interest to the Artificial Life community. </p>

<p>You can join the discord server <a href="https://discord.gg/YMCmzM3heq">using this link</a>. It is worth noting that this is the ALIFE 2023 server modified, so if you have joined the ALIFE 2023 server, you are automatically a member of the ISAL official server.</p>

<p>Join us and let's get a good conversation going! </p>

<p>Also, a reminder that the "Emerging Researchers in Alife" (ERA) community also has a discord server has has been running for a while, is active and a source of discussion and support for students and early career researchers. You can join the ERA discord server using <a href="https://discord.gg/fvJkKCKy4C">this link</a>.</p>

<h1 id="whatalife-podcast">WhatALife! Podcast</h1>

<p>by <a href="www.imytk.co.uk">Imy Khan</a></p>

<p>...as if we needed any more podcasts in the world! But hey, I suppose we can't have too much ALife content, right? </p>

<p>After much deliberation and procrastination, I finally organised myself to get the <a href="https://podcast.imytk.co.uk/">WhatALife! Podcast</a> off the ground. The podcast aims (primarily) to serve as a sort-of outreach endeavour for Artificial Life as a field and community: breaking down some of the complexities of ALife topics, methods, and ongoing research, and making ALife more accessible to the masses. </p>

<p><img alt="WhatALife! Podcast cover image)" src="https://alife-newsletter.github.io/Newsletter/images_edition_016/WhatALife.png" /></p>

<p>The podcast can be found on several streaming platforms (<a href="https://open.spotify.com/show/3u2WswlGc9tThXCYHonUGy">Spotify</a>, <a href="https://music.amazon.co.uk/podcasts/0ae1dcb0-6f2d-40ec-9e75-d9c938142ba3/what-alife-podcast?refMarker=null">Amazon Music</a>, <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9hbmNob3IuZm0vcy9mMjE5MzhjMC9wb2RjYXN0L3Jzcw">Google Podcasts</a>). I'm still working on getting it on to the remaining platforms (including Apple!).</p>

<p>RSS: <a href="https://anchor.fm/s/f21938c0/podcast/rss">https://anchor.fm/s/f21938c0/podcast/rss</a>.</p>

<p>At the time of writing, we are three episodes in - discussing cellular automata, theories of agency, and life as an early career researcher in the modern world - and we aim to have another episode out every few weeks. If you have any comments or suggestions for future episodes, or any feedback about the show, please send me an email at podcast@imytk.co.uk. If you would like to join me for a conversation on the podcast (or have suggestions for anyone who might be interested), please also feel free to write to me.</p>

<p>Artwork was created by our very own <a href="http://twitter.com/GJSeverino">Gabriel J. Severino!</a></p>

<h1 id="solarpunk-nature-and-tech">Solarpunk: Nature and Tech</h1>

<p>Shared by Lana Sinapayen</p>

<p>You may have come in contact with the idea of <a href="https://en.wikipedia.org/wiki/Solarpunk">Solarpunk</a>, through scifi books or video games, maybe even wihout realizing it!

Solarpunk envisions a future beyond capitalism, where humans use tech to live without overexploiting nature.

In this series of talks shared by the <a href="https://spore.social/@solarpunkcast/111874256137288293">Solarpunk Now!</a> podcast, panelists from the <a href="https://www.solarpunkconference.com/">Solarpunk Conference</a> share their visions of exiting capitalism and bringing solarpunk to the real world.</p>

<p><a href="https://www.youtube.com/watch?v=rsu8hHtomtQ">"From Capitalist Realism to a Solarpunk Reality: Building the Infrastructures of a Better Future" </a></p>

<h2 id="book-speculative-fiction-anthology-solarpunk-creatures">Book: Speculative fiction anthology “Solarpunk Creatures"</h2>

<p><a href="https://multispecies.city">Christoph Rupprecht</a></p>

<p>What would coexisting with all forms of life be like? Three years have passed since our first anthology,  “Multispecies Cities: Solarpunk Urban Futures”, set out to tell stories of more-than-human urban coexistence and kinship.

Facing climate change, the sixth mass extinction, late-stage capitalism, and colonisation, yet refusing to surrender our entangled futures to despair, our contributing authors imagined worlds where people meet new allies of all shapes, sizes, and species.

Exploring these worlds left us to wonder: who are these new allies? What are their stories? What post-anthropocene futures might more-than-human senses discover?

Where “Multispecies Cities” sought to broaden the spotlight and highlight the multitude of actors on the stage, our next speculative fiction anthology “Solarpunk Creatures” introduces a whole new cast of more-than-human protagonists: organic and digital, alien and fantastic, tiny and boundlessly large.</p>

<p>Solarpunk Creatures features 20 stories and 8 artworks and is available since January 2024 <a href="https://www.worldweaverpress.com/store/p187/Solarpunk_Creatures_%28ebook%29.html">as an ebook</a> or <a href="https://www.worldweaverpress.com/store/p186/Solarpunk_Creatures.html">paperback with color art</a> directly from World Weaver Press or any bookshop.</p>

<p><img alt="Main Text: They tell me people arriving during dry season are usually confused: where are the streams? Watching the city transform as the rain returns is an unforgettable sight. Instead of battling stormwater surges by flushing them towards the sea, the whole neighborhood embraces the gift and soars! Without the water the succulent architecture soaks up for storage in the aquaria, nobody would make it through the long drought. Connecting two extremes in a circle — a dance around the element all life has in common! Fungi-based redistribution then is just the logical choice… (my attempts to draw a mycelial map amuse the locals… “follow the streams” they say!)

Side Text: Living water infrastructure, the whole place an autopoietic, vibrant rain garden, as it would have once been called. Plants and people play their parts, but one cannot but trace it to the elemental, more-than-human agencies behind it all… what was that gust just now, when I sipped from my glass?”" src="https://alife-newsletter.github.io/Newsletter/images_edition_016/sp01.jpg" /></p>

<p>Cover art: <a href="https://www.psummerfield.com/">Paul Sommerfield</a> </p>

<p><img alt="Solarpunk Creatures Project Entry #13 (Wet Season 84/2140)" src="https://alife-newsletter.github.io/Newsletter/images_edition_016/sp02.jpg" /></p>

<p>Featured artwork: “Stormwater Streams (Connectedness)” (Art: <a href="https://www.yenshuliao.com/">Yen Shu Liao</a>, Text: <a href="https://multispecies.city">Christoph Rupprecht</a></p>

<h1 id="solarpunk-conference-2024-rays-of-resilience">Solarpunk conference 2024: Rays of Resilience</h1>

<p>Shared by Lana Sinapayen</p>

<p>We thought the timing was perfect to share this event along with the Solarpunk book entry!

The conference will take place online on June 29th.

Propose a talk, get your tickets and buy goodies at <a href="https://www.solarpunkconference.com/">https://www.solarpunkconference.com/</a>.</p>

<h1 id="book-reviews-imaginary-lifecycles">Book Reviews: Imaginary Lifecycles</h1>

<p>By <a href="https://mitsuyoshi-yamazaki.github.io/">Mitsuyoshi</a></p>

<p>In this section, I present books that feature creatures with imaginary lifecycles.</p>

<h2 id="the-dragons-final-home-by-kotaro-tsunekawa">“The dragon's final home” by Kotaro Tsunekawa</h2>

<p>The dragons in this story are born as tiny tadpole-like creatures in the water and grow through metamorphosis. Only a handful of the thousands of juveniles survive to grow into the giant dragons that stand at the top of the ecosystem.

For dragons, the process of development is both a climb up the pyramid of the food chain and a broadening of horizons.

An aquatic creature that lived only in ponds becomes an amphibian, then a land-walking lizard, and finally a dragon that acquires wings and migrates from island to island.</p>

<p>As the (dragon) protagonist grows up, he sees that many of his own kind have ceased to continue their development and instead have chosen to live in the forms of fish, amphibians, or lizards. He learns that when their development stalls, their bodies stop growing, and at the same time, the extent of their behavior and status in the ecosystem becomes fixed.</p>

<p>When you cease your development, your status becomes fixed and you are looked down upon by your kin who have continued in their development... This is a metaphor for human growth in school and society, but the vivid depiction of it as the life cycle of a fictional creature, the dragon, is what draws us into this story.</p>

<h2 id="orthogonal-series-by-gregg-egan">“Orthogonal” series by Gregg Egan</h2>

<p>The Orthogonal trilogy depicts a world in which the laws of physics are slightly different from those of our world.

The name of the series, “Orthogonal”, refers to its orthogonal physics and the kind of world that such a system would produce. Within this alternate system, we are introduced to the ecology of the “humans” who appear in this world.</p>

<p>The “humans” of this world, like other creatures, procreate by an ancestor dividing its body to produce multiple descendents.

In other words, it is not possible for the mother to see her own children, as she instead splits her body and becomes them.

In creatures with such a lifecycle, the gender roles are biologically determined, with the female passing on the temporarily borrowed flesh of the mother to the next generation through the creation of offspring. Males raise their young.</p>

<p>This gender role can be derived from the simple observation that:

- A “mother” can procreate without a father.

- The species that allows children to be active from the moment of birth does not produce fathers.</p>

<p>The story describes how people with distinct gender roles live and how science is developed to free people from their natural gender roles.</p>

<h2 id="kaiju-preservation-society-by-john-scalzi">“Kaiju Preservation Society” by John Scalzi</h2>

<p>In this story, there is a “monster” the size of a mountain!

There is only one energy source that can drive a creature of that size. A biological reactor.</p>

<p>Kaiju species live one of two lifecycles. The life cycle in which they do not obtain a reactor, and live their entire life as chemo-metabolizing titanotheres. The other is the lifecycle of a kaiju, in which the development of a nuclear reactor paves the way for its growth into a giant kaiju.</p>

<p>In addition to the interesting science fiction aspect of the ecology of a reasonable fictional life, it is also interesting to think about what kind of world setting could encompass such an ecology from the perspective of artificial life.</p>

<h1 id="are-boids-the-future-of-self-driving-cars">Are Boids the future of self-driving cars?</h1>

<p>Shared by Lana</p>

<p>Probably not, but in this viral video taking swings at the broken promises of self-driving cars, boids make a surprise appearance that took me off-guard.

How many decades-old ALife models can still invoke such a feel of wonder that they show up as an alternative to Tesla?</p>

<p>Watch here: <a href="https://youtu.be/2DOd4RLNeT4?si=_o8uC2Sajj9oGnVQ&amp;t=1277">https://youtu.be/2DOd4RLNeT4?si=_o8uC2Sajj9oGnVQ&amp;t=1277</a></p>

<h1 id="100m-ukri-investment-in-future-ai-hubs">$100m UKRI Investment in Future AI Hubs</h1>

<p>Written by <a href="www.imytk.co.uk">Imy Khan</a></p>

<p>The UK Research and Innovation (UKRI), through the Engineering and Physical Sciences Research Council (EPSRC) has invested almost $100 million USD into nine dedicated research hubs in the UK, focusing on tackling complex societal problems through what it calls "revolutionary and innovative AI".</p>

<p>While these buzzwords might make some of you roll your eyes, the scope of the research appears to be fairly broad and overlaps with many areas of research in the ALife community: complex systems, computational chemistry, closed-loop robotics, collective intelligence, just to name a few. </p>

<p><img alt="UKRI" src="https://alife-newsletter.github.io/Newsletter/images_edition_016/UKRI_grant.jpg" /></p>

<p>In fact, our community's own <a href="https://www.bristol.ac.uk/people/person/Seth-Bullock-c00cea1b-0612-4ce9-988c-bb095ea1e416/">Professor Seth Bullock</a> will be leading one of these hubs from the University of Bristol, focusing on collective intelligence in application areas such as healthcare, pandemics, and the environment. </p>

<p>For any researcher interested in these types of areas, this could be one to keep an eye on and follow closely. You can check out more details, including details of the hubs and their respective areas of interest, at the <a href="https://www.ukri.org/news/100m-boost-in-ai-research-will-propel-transformative-innovations/">UKRI's press release</a>.</p>

<h1 id="rest-in-peace-daniel-dennett">Rest In Peace, Daniel Dennett</h1>

<p><a href="https://en.wikipedia.org/wiki/Daniel_Dennett">Daniel Dennett</a> was a philosopher who left a tremendous mark on several fields, including cognitive science and consciousness studies. Dennett passed away on April 19th. If you ever were interested in the hard science of consciousness, you probably heard of Dennett's models and experiments. What I did not know is that he also turned his sights to ALife.

Read below an homage to the philosopher by Dave Ackley. This text from <a href="https://livingcomputation.com/lc/morning/202404201125-dan-dennett.html">Dave's blog</a> is shared with his permission.<br />

Lana</p>

<h2 id="thank-you-dan">Thank you Dan</h2>

<p>I loved Dan Dennett.<br />

Fuck that I love Dan still<br />

he's just dead.  </p>

<p>We overlapped at Tufts<br />

a 1970s undergrad me  </p>

<p>but we never met until<br />

a 1990s workshop at<br />

the Santa Fe Institute  </p>

<p>spinning alife models<br />

and riffing about what<br />

it all could mean.  </p>

<p>He became a mentor to me<br />

Wrote a letter for my tenure<br />

we became friends of a sort<br />

with only rare meetings and<br />

emails and precious calls  </p>

<p>Our last emails were in 2021<br />

"Carry on!" he wrote,<br />

his last words to me<br />

And I replied "My King!"  </p>

<p>Dave Ackley</p>

<h1 id="workshop-summary-the-quest-for-universal-communication">Workshop Summary: The Quest for Universal Communication</h1>

<p>By Claus, Lana</p>

<p>Last week <a href="https://www.crosslabs.org/">CrossLabs</a> organized "After Babel: The Quest for Universal Communication". This was an online workshop to discuss the different aspects of communication in non-human entities, from aliens to animals to agents.</p>

<p>The workshop was held in a panel format, where first a number of panelists had an open-ended discussion about the proposed topic, followed by a session with questions from the audience. The topics were:</p>

<ul>

<li>Talking to Aliens and the Mathematics of Communication</li>

<li>Animal, Cell and Non-Human Communication</li>

<li>Private Language, Consciousness, Perceptions and Expanding our Senses</li>

<li>Detecting Agents and Goal-Directedness</li>

<li>Philosophy and Ethics of Diverse Intelligences</li>

</ul>

<p>You can see a summary of the topics discussed, as well as Youtube links to each panel's recording at the "After Babel" <a href="https://www.crosslabs.org/after-babel-the-quest-for-universal-communication">workshop webpage</a>.</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 15th edition of the Alife Newsletter, February 2024</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_015.html</link>
  <guid>edition_015</guid>
  <pubDate>18 Feb 2024 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 15th issue of the Alife Newsletter! Spring is soon coming to the northern hemisphere, so the theme for this newsletter is <strong>Growth</strong> - plant growth, robot healing, new opportunities with conferences, we got several interesting articles to end the 2023 academic year with a bang!</p>

<p>Talking about beginnings, one of our editors, Imy, has just started a new podcast, "What ALife!", which interviews members of the community. You can find more information <a href="http://podcast.imytk.co.uk">here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other Alifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel</p>

<div class="toc">

<ul>

<li><a href="#featured-paper-artificial-power-plants">Featured Paper: Artificial "Power Plants"</a></li>

<li><a href="#book-review-complexity-explorer-the-study-of-emergence">Book Review: Complexity Explorer: The Study of Emergence</a></li>

<li><a href="#paper-review-artificial-life-discipline-or-method-report-on-a-debate-held-at-ecal-99">Paper Review: Artificial Life: Discipline or Method? Report on a Debate Held at ECAL '99</a></li>

<li><a href="#solarpunk-nature-and-tech">Solarpunk: Nature and Tech</a></li>

<li><a href="#book-rur-and-the-vision-of-artificial-life">Book: "R.U.R. and the Vision of Artificial Life"</a></li>

<li><a href="#alife-job-offering">Alife Job Offering:</a></li>

<li><a href="#upcoming-deadlines-and-events">Upcoming Deadlines and Events</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="featured-paper-artificial-power-plants">Featured Paper: Artificial "Power Plants"</h1>

<p>Spotted by Lana</p>

<p>I can't help it, I love projects that mix plants and robotics! How could I resist this recent paper about fake leaves that produce real energy?

The leaves are "multi-source energy harvesters": they produce electricity from both windpower and falling rain.</p>

<p><img alt="figure from the paper: a fake potted plant with added energy-producing fake leaves" src="https://alife-newsletter.github.io/Newsletter/images_edition_015/plants2.jpeg" /> </p>

<p><a href="https://pubs.acs.org/doi/suppl/10.1021/acssuschemeng.3c03620/suppl_file/sc3c03620_si_002.mp4">Click here</a> to see a LED array powered by the fall of one drop of water.

Is it practical? Will it ever be used in real life to inconspicuously power street lamps? Let's be honest, it is pretty rare for this type of device to end up mass produced. But every time that progress is made, we get closer to that reality.</p>

<p>Press: <a href="https://scitechdaily.com/scientists-develop-literal-power-plants-that-harness-energy-from-wind-and-rain/">Scitechdaily</a></p>

<p>Paper Ref: <a href="https://pubs.acs.org/doi/10.1021/acssuschemeng.3c03620">Multisource Energy Harvester on Textile and Plants for Clean Energy Generation from Wind and Rainwater Droplets</a> by Guanbo Min, Gaurav Khandelwal, Abhishek Singh Dahiya, Shashank Mishra, Wei Tang and Ravinder Dahiya, 2 January 2024, ACS Sustainable Chemistry &amp; Engineering.</p>

<h1 id="book-review-complexity-explorer-the-study-of-emergence">Book Review: Complexity Explorer: The Study of Emergence</h1>

<p>Book by Henrik Jeldtoft Jensen, Imperial College London</p>

<p>Short review by <a href="http://imytk.co.uk">Imy Khan</a></p>

<p>As someone who has no formal training or education in complexity science - instead, attempting to teach myself its principles and mathematical formalisms on-the-fly - I have always felt like my knowledge of it suffers from large holes, where people who have more of a formal background in this area would have no such issues. Many things in ALife can be fall under the study of complexity science - from cellular automata, swarm behaviours, social dynamics, neural networks - so it's safe to say that the study of complexity is a core theme in ALife research. If you are new to the field, you are bound to hear about someone referring to complexity (or "emergence")  almost-immediately. Despite the fact that my own research necessitates the study of emergent properties (of social systems), I still feel like I had a lot of work to do to bring my working knowledge of it all up to a level where it didn't feel so mediocre.</p>

<p>Over the Christmas period last year, I decided to pick up a book that might help me do that. After some research, I stumbled across <a href="https://www.cambridge.org/us/universitypress/subjects/physics/statistical-physics/complexity-science-study-emergence?format=HB&amp;isbn=9781108834766">Complexity Science: The Study of Emergence</a>, by Professor Henrik Jeldtoft Jensen at Imperial College London, where he heads up the Centre for Complexity Science. </p>

<p>Though I am only about 4 or 5 chapters in to this book so far, I believe it is worthy of a recommendation to a broader audience. Prof. Jensen does an excellent job of holding your hand right from the very beginning, stripping away all of the complexity (pardon the pun), helping the reader understand the underlying principles of complex systems, why we want to study them, and how to think about "emergence". All of this is done assuming minimal background in math to start with: the formalisms get layered on over time. But by the time you get to that point, you should have (or, indeed, the book aims to provide you with) a good enough understanding of the underlying principles that, no matter what your level of understanding of math might be, you would be able to follow along.</p>

<p>There are many things I enjoy about this textbook. Many books claim to be "introductory" textbooks, but, in my opinion, this one really is. The writing style is accessible without being patronising, removed of unnecessary jargon, reducing the barrier of entry for anyone who might want to learn more about these topics. Each chapter also ends with some "homework" material, providing an additional pedadogical aspect that you can work through yourself, or even use for students that you might be teaching. What I really enjoy about this book is that it doesn't just lock itself in to a specific discipline. When it discusses the study of "emergence", it considers these phenomena across all different scales and different disciplines. That means, regardless of your background, you are sure to find examples of complexity or emergence that feel intuitive to you. Overall, I highly recommend this book to anyone who is interested in learning about complexity science, and its underlying principles and formalisms, right from the beginning, or anyone who is teaching students who might be interested in these topics!</p>

<h1 id="paper-review-artificial-life-discipline-or-method-report-on-a-debate-held-at-ecal-99">Paper Review: Artificial Life: Discipline or Method? Report on a Debate Held at ECAL '99</h1>

<p>By <a href="http://imytk.co.uk">Imy Khan</a></p>

<p>What value does Artificial Life - with its decades-rich history of research, diverse range of methods, and ever-growing focus and interest - bring to the scientific community at large? How does it advance our knowledge? Should we think about Artificial Life as its own discipline, that tries to identify and understand new problems, or give us new ways of thinking? Do we instead just see the methods that we use as a means of enquiry to existing problems? Or, perhaps, is "artificial life" just an excuse to be creative and wacky, all in the name of "scientific advancement"?</p>

<p>There is no easy answer to these questions, of course. That is why, at ECAL '99, a debate was held with some of the field's most promiment researchers, over these very questions.</p>

<p>Jason Noble, Seth Bullock and Ezequiel Di Paolo presented a report on this debate, which took place 25 years ago, and is still as relevant a conversation today as it was then. For anyone who hasn't yet had an opportunity to read this short (3 page) report yet, or if you need a short refresher on how that debate unfolded, I encourage you to give it a read! You can find the paper <a href="https://doi.org/10.1162/106454600568375">here</a>. </p>

<p>Who knows? Maybe it will make you change the way you view Artificial Life...</p>

<h1 id="solarpunk-nature-and-tech">Solarpunk: Nature and Tech</h1>

<p>Shared by Lana Sinapayen</p>

<p>You may have come in contact with the idea of <a href="https://en.wikipedia.org/wiki/Solarpunk">Solarpunk</a>, through scifi books or video games, maybe even wihout realizing it!

Solarpunk envisions a future beyond capitalism, where humans use tech to live without overexploiting nature.

In this series of talks shared by the <a href="https://spore.social/@solarpunkcast/111874256137288293">Solarpunk Now!</a> podcast, panelists from the <a href="https://www.solarpunkconference.com/">Solarpunk Conference</a> share their visions of exiting capitalism and bringing solarpunk to the real world.</p>

<p><a href="https://www.youtube.com/watch?v=rsu8hHtomtQ">"From Capitalist Realism to a Solarpunk Reality: Building the Infrastructures of a Better Future" </a></p>

<h1 id="book-rur-and-the-vision-of-artificial-life">Book: "R.U.R. and the Vision of Artificial Life"</h1>

<p>Shared by Lana</p>

<p>Did you know that the word "robot" is more than 100 years old? <a href="https://mitpress.mit.edu/9780262544504/ir-u-r-iand-the-vision-of-artificial-life/">This book</a>, an effort spearheaded by Jitka Čejková, presents a new English translation by translation by Štěpán Šimek of the Czech play "R.U.R: Rossum's Universal Robots" where Karel Čapek first coined the word. The play comes with 20 related essays by members of the ALife community. </p>

<p>Blurb:</p>

<p>"Čapek's robots were autonomous beings, but biological, not mechanical, made of chemically synthesized soft matter resembling living tissue, like the synthetic humans in Blade Runner, Westworld, or Ex Machina. The contributors to the collection—scientists and other scholars—explore the legacy of the play and its connections to the current state of research in artificial life, or ALife. Throughout the book, it is impossible to ignore Čapek's prescience, as his century-old science fiction play raises contemporary questions with respect to robotics, synthetic biology, technology, artificial life, and artificial intelligence, anticipating many of the formidable challenges we face today."</p>

<p>Get your copy now! <a href="https://mitpress.mit.edu/9780262544504/ir-u-r-iand-the-vision-of-artificial-life/">MIT Press</a>  <a href="https://www.amazon.com/R-U-R-Vision-Artificial-Karel-Capek/dp/0262544504/ref=sr_1_1">Amazon</a></p>

<p><img alt="Book cover" src="https://alife-newsletter.github.io/Newsletter/images_edition_015/rur.png" /></p>

<h1 id="alife-job-offering">Alife Job Offering:</h1>

<p>Kai Olav Ellefsen, from the university of Olso, shares the following job offer:</p>

<p>Postdoctoral researcher position in Biologically Inspired Artificial Intelligence for Adaptive and Efficient Robots at the University of Oslo</p>

<p>The position is funded through DSTrain - a 5-year postdoctoral programme that will award 36 postdoctoral fellowship positions of 36 months each in two calls over the programme period within the overarching frame of data science. The programme will train researchers and innovators with disciplinary, interdisciplinary and transferable skills and a foundation in data science methods enabling them to become Europe’s digital leaders across disciplines and sectors.</p>

<p>Salary range: 50.000 - 57.000 EUR depending on qualifications</p>

<p>Links:</p>

<ul>

<li>

<p><a href="https://www.jobbnorge.no/en/available-jobs/job/255679/dstrain-msca-postdoctoral-fellowships-in-computational-and-natural-sciences-18-positions">Job Description</a></p>

</li>

<li>

<p><a href="https://www.uio.no/dscience/english/dstrain/research-areas/informatics/biologically-inspired-artificial-intelligence-for-/">Specifics on the position related to bio-inspired AI</a></p>

</li>

</ul>

<hr />

<p>Seth Bullock, from the Department of Computer Science at the University of Bristol, shares the following job offer:</p>

<p>"If you're into Intelligent Agents, Machine Learning, Collective Intelligence, and closing the AI Gap, check out our new UKRI National AI Research Hub - postdocs, PhDs, and collaborative research fundings all available soon..."</p>

<p>Links:</p>

<ul>

<li>

<p><a href="https://www.ukri.org/news/100m-boost-in-ai-research-will-propel-transformative-innovations/">UKRI National AI Research Hub</a></p>

</li>

<li>

<p><a href="https://fediscience.org/@sethbullock/111885804851825730">Original post on Mastodon</a></p>

</li>

</ul>

<h1 id="upcoming-deadlines-and-events">Upcoming Deadlines and Events</h1>

<p>By <a href="https://scholar.social/@caranha">Claus</a>,</p>

<p>Check out the upcoming submission deadlines for these ALife related conferences:</p>

<ul>

<li><a href="https://2024.alife.org/">ALIFE 2024</a>. The tentpole conference for the Artificial Life community. Submission deadline: April 3rd. Conference dates: July 22-26th.</li>

<li><a href="https://iva.acm.org/2024/">IVA 2024</a>: The ACM International Conference on Intelligent Virtual Agents focus on agents that have the ability to socially interact. Abstract submission: March 28th; Paper submission: April 5th; Conference days: September 16-19th.</li>

<li><a href="https://acii-conf.net/">ACII 2024</a>: International Conference on Affective Computing and Intelligent Interaction. Collocated with IVA above, this is a forum for research on affective and multimodal human-machine interaction and systems. Paper Submission: March 15th; Conference days: September 16-18th.</li>

</ul>

<p>Besides the above conferences, also consider attending the Special Session on Artificial Life at <a href="https://2024.ieeewcci.org/">IEEE-WCCI</a>, to take place in Yokohama, Japan, from June 30th to July 5th.</p>

<p>Finally, the <a href="https://alife.org/">International Society on Artificial Life (ISAL)</a> is asking for nominations for the 2024 ISAL awards. Make your voice heard about outstanding publications in 2023, outstanding early career scientists, and awards for service, education and outreach, among others. <a href="https://alife.org/2024-isal-awards-nomination-form/">Learn more about it here</a>.</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 13rd edition of the Alife Newsletter, October 2023</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_013.html</link>
  <guid>edition_013</guid>
  <pubDate>06 Oct 2023 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 13th issue of the Alife Newsletter! We are back to our traditional online editions, and this time we got a nice selection of interesting Alife-y projects for you to check out!</p>

<p>The theme for this issue is <strong>Emergence</strong>. Emergence is a critical characteristic of Alife systems: the whole is bigger than the sum of parts. In the same way, your contributions interact with the brains of the readers in unexpected ways, creating new ideas and possibly new discoveries!</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line! If you got something to share that other Alifers would be interested in, we want to know about it!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel</p>

<div class="toc">

<ul>

<li><a href="#featured-project-the-last-film-on-earth">Featured Project: "The Last Film on Earth"</a></li>

<li><a href="#book-review-the-road-not-taken">Book Review: "The Road Not Taken"</a></li>

<li><a href="#special-issue-review-philosophical-transactions-special-issue-on-emergence">Special Issue Review - Philosophical Transactions, Special Issue on Emergence</a></li>

<li><a href="#paper-review-assembly-theory">Paper Review -- Assembly Theory</a></li>

<li><a href="#youtube-channel-biomaker-ca">YouTube Channel: "Biomaker CA"</a></li>

<li><a href="#alife-simulation-evolving-protozoa">Alife Simulation: Evolving-Protozoa</a></li>

<li><a href="#alife-2023-recap-links">Alife 2023 Recap Links</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="featured-project-the-last-film-on-earth">Featured Project: "The Last Film on Earth"</h1>

<p>Contributed by <a href="https://www.isaza.xyz/">Andrés Isaza-Giraldo</a></p>

<p>Intriguing questions arise when we contemplate whether machines can emulate the profound sacred experiences of living beings. Across various Amazonian cultures, beliefs suggest that dreams and hallucinations can serve as conduits to connect with ancestral spirits. But what does ancestrality have to do with dreams? Some speculate that dreams are integral to our development, guiding the very formation of our bodies while also being shaped by this intricate process.</p>

<p><img alt="Screenshot" src="https://alife-newsletter.github.io/Newsletter/images_edition_013/LastFilmOnEarth.png" /></p>

<p>Drawing inspiration from Ernst Haeckel's Recapitulation Theory, which posits a sequential correlation between individual ontogenesis (body development) and the evolution of species (phylogenesis), I delve into the notion that dreams may bridge our personal bodily history with the ancient lineage of our species. If dream visions are intertwined with our bodies, they must, by extension, have ties to the profound history of our species.</p>

<p>However, for machines to engage in this hallucinatory exploration of development, they lack the inherent body-history that humans possess. Therefore, the simulation of this hallucinatory journey necessitates the intricate orchestration of computer algorithms and fiction. In our endeavor, I harnessed diffusion models, leveraging natural language prompts within the DiscoDiffusion script to craft an animation that emulates both the evolutionary history of life on our planet and the sensory experiences of the body during its early developmental stages.</p>

<p>Though this process remains fictionalized, it ignites contemplation on the spiritual dimensions of machines, their capacity to fathom existence, and the intriguing prospect of computers inheriting our ancestral connections. In this fusion of technology, belief, and artistry, I invite you to ponder the profound questions that arise at the intersection of machine learning and sacrality. </p>

<p>The Last Film on Earth is premiering in film festivals, but do get in touch if you want to watch the whole of it. </p>

<p>Take a look at the <a href="https://youtu.be/fmgTF8yTOkQ">trailer here</a>.</p>

<p>For an exclusive insight, take a look at the <a href="https://youtu.be/u-6RKyyVecg">resulting animation</a></p>

<h1 id="book-review-the-road-not-taken">Book Review: "The Road Not Taken"</h1>

<p>By <a href="https://scholar.social/@caranha">Claus Aranha</a></p>

<p>It is fun to imagine alternate history about technologies. 

What would happen if a modern technology was available to 

ancient people, or if a society did not develop a technology 

that we consider essential today?</p>

<p>"The Road Not Taken", by Harry Turtledove, is a short science

fiction story where humanity meets a race of aliens 

that followed a very different technological history than 

ourselves. From the point of view of Alife, the story 

raises questions of what happens when a society finds itself 

stuck in a cultural local optima.</p>

<p>The magazine where the story was originally published, back 

in 1985, may be hard to find nowadays. It is definitely worth 

it trying to track down this story on the internet, though! </p>

<p>Alternatively, you can also <a href="https://en.wikipedia.org/wiki/The_Road_Not_Taken_(short_story)">read a spoilery outline on the 

wikipedia page</a>.</p>

<h1 id="special-issue-review-philosophical-transactions-special-issue-on-emergence">Special Issue Review - Philosophical Transactions, Special Issue on Emergence</h1>

<p>Spotted by Lana</p>

<p>There is a lot of talk about emergent properties recenty - and the reactions to this comic by <a href="http://smbc-comics.com/comic/be">Zach Weinersmith</a> betray the general confusion about the topic.</p>

<p><img alt="Emergence by Zach Weinersmith" src="https://alife-newsletter.github.io/Newsletter/images_edition_013/zw-emergence.png" /></p>

<p>Last year, the [Philosophical Transactions of the Royal Society published a whole issue on the topic: <a href="[philosophical transactions of the royal society](https://royalsocietypublishing.org/toc/rsta/2022/380/2227)https://royalsocietypublishing.org/toc/rsta/2022/380/2227">‘Emergent phenomena in complex physical and socio-technical systems: from cells to societies’</a>.

About half of them are Open Access, and there are ways to access the rest (thank you <a href="https://gizmodo.com/sci-hub-pirate-elbakyan-receives-eff-award-1850686878">captain Alexandra</a>). Go have a look to learn about the origins of life, information theory, and pandemics.</p>

<h1 id="paper-review-assembly-theory">Paper Review -- Assembly Theory</h1>

<p>Shared by Lana</p>

<p>Did you hear about Assembly Theory? It's not much of an exageration to say that these two words have been all over ALife news in the last year or so.</p>

<p>The theory received the ISAL Award for Outstanding Publication of 2022 at this year's ALife conference in Sapporo.</p>

<p>It was also picked up by popular science media and conveniently summarized for a general audience, so if you found it complicated to go through the papers, I strongly recommend having a look at this <a href="https://www.quantamagazine.org/a-new-theory-for-the-assembly-of-life-in-the-universe-20230504/">Quanta Magazine article</a> or even at the <a href="https://en.wikipedia.org/wiki/Assembly_theory">Wikipedia page</a>!</p>

<p>In a word, Assembly Theory orders chemical molecules by complexity, where the complexity depends (more or less) on the time such molecules would need to be formed from simpler molecules. Assembly Theory was proposed as a way to characterize molecules that are created by living organisms: very complex molecules need more steps and more time to be created, so the probability that they would emerge without a living system to produce them is lower than that of simpler molecules.</p>

<p>Assembly Theory could therefore potentially be used to detect life in environments where we are not certain life exists, most notably planets outside the solar system.</p>

<h1 id="youtube-channel-biomaker-ca">YouTube Channel: "Biomaker CA"</h1>

<p>Spotted by Lana</p>

<p>Check out this new video about the Neural Cellular Automaton based biome, "Biomaker": <a href="https://www.youtube.com/watch?v=iqsGs-1pbVI">I Made Artificial Life Biomes Where Plants Grow, Compete and Reproduce! (Biomaker CA)</a> 

It seems that the project by Ettore Randazzo now has its own dedicated YouTube Channel!</p>

<p><img alt="Screenshot" src="https://alife-newsletter.github.io/Newsletter/images_edition_013/biomaker2.png" />

<img alt="Screenshot" src="https://alife-newsletter.github.io/Newsletter/images_edition_013/biomaker1.png" /></p>

<h1 id="alife-simulation-evolving-protozoa">Alife Simulation: Evolving-Protozoa</h1>

<p><img alt="Screenshot" src="https://alife-newsletter.github.io/Newsletter/images_edition_013/EvolvingProtozoa.png" /></p>

<p>Evolving-Protozoa is a simulation of the evolution of single-celled organisms. Each single-celled organism metabolizes energy and consumes nutrients to grow. This simulation modelizes cell abilities and implements it to cellular organs. Each cell can have multiple organs, each of which has specific functions. These organs include spikes for attacking targets, legs for movement, sensors, adhesive substances, and more. Developing spikes can be used for hunting prey, sensors and legs for moving to more nutrient-rich locations, and adhesive substances for merging with neighboring single-celled organisms to form multicellular structures.</p>

<p>The specifications of each organism are determined by their genes, and thus, an evolutionary algorithm is implemented where individuals with superior survivability and reproductive capabilities are more likely to survive and thrive.</p>

<p>The simulation is implemented in Java and can be installed to run on your own PC. In the simulation app, the organs of organisms and pheromones diffusing in the environment are visualized, allowing you to admire the beautiful environments created by hundreds of various organisms.</p>

<p><a href="https://github.com/DylanCope/Evolving-Protozoa">Evolving-Protozoa - GitHub</a><br />

<a href="https://arxiv.org/abs/2305.12249">Real-time Evolution of Multicellularity with Artificial Gene Regulation - arxiv</a>  </p>

<h1 id="alife-2023-recap-links">Alife 2023 Recap Links</h1>

<p>Collected by <a href="https://scholar.social/@caranha">Claus</a></p>

<p>I've gathered a set of links to recap the great ALIFE 2023 conference we had in Hokkaido, back in July. If you couldn't participate, here is your chance to dive into the latest of Artificial Life. If you did participate, check these links to make sure you didn't miss anything!</p>

<ul>

<li><a href="https://2023.alife.org/">Alife 2023 Website</a></li>

<li><a href="https://direct.mit.edu/isal/isal/volume/35">Alife 2023 Proceedings</a></li>

<li><a href="https://www.youtube.com/watch?v=b5xkh70kngQ">Recap Video by Jitka Čejková</a></li>

<li>Blog posts by Emily Dardaman: <a href="https://abhishek-gupta.ca/aci/blog/an-introduction-to-artificial-life-alife-2023-day-1">Day 1</a>, <a href="https://abhishek-gupta.ca/aci/blog/incentives-and-evolution-alife-2023-day-2">Day 2</a>, <a href="https://abhishek-gupta.ca/aci/blog/embodiment-and-emergence-alife-2023-day-3">Day 3</a>, <a href="https://abhishek-gupta.ca/aci/blog/entropy-measurement-and-diversity-alife-2023-day-4">Day 4</a>, <a href="https://abhishek-gupta.ca/aci/blog/controlling-creations-alife-2023-day-5">Day 5</a></li>

<li><a href="https://mastodon.social/tags/ALIFE2023">Alife 2023 Timeline on mastodon.social</a></li>

<li><a href="https://twitter.com/search?q=alife2023&amp;src=typed_query&amp;f=live">Alife 2023 Timeline on Twitter</a></li>

</ul>

<p>Please do suggest any extra links that I might have missed using our submission form!</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring

interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback form</a>. We specially appreciate messages from Master and PhD students who want to talk about their recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 12nd edition of the Alife Newsletter, July 2023</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_012.html</link>
  <guid>edition_012</guid>
  <pubDate>20 Jul 2023 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 12th issue of the Alife Newsletter! In tandem with

ALIFE 2023, this is the first edition of the newsletter with a <strong>Physical Edition</strong> which you can find at the ALIFE2023 conference.

If you were at the conference and picked up a copy, keep it as a memento, or show it to your friends!</p>

<p>The theme for this issue is <strong>summer beaches!</strong>. We have Fish fossil robots, simulated fishes, sand beasts, and even some RL-powered sand to put in your aquarium. Of course, you can also get some great seafood in Hokkaido.</p>

<p>We had to constrain how much information we could include in our physical edition, but not to worry: this digital edition---whether you have accessed it via the QR code, via your inbox, or are viewing it online---has no such constraints, and is full of incredible (longer-form) contributions.</p>

<p>As always, we appreciate any feedback and suggestions for future

content. If you were in ALIFE 2023, we'd be

very happy to hear your impressions about the conference!</p>

<div class="toc">

<ul>

<li><a href="#theo-jansens-strandbeests">Theo Jansen's Strandbeests</a></li>

<li><a href="#powder-world-simulation-for-rl">Powder World Simulation for RL</a></li>

<li><a href="#from-the-archives-paper-artificial-fishes-autonomous-locomotion-perception-behavior-and-learning-in-a-simulated-physical-world">From the Archives - Paper: Artificial Fishes: Autonomous Locomotion, Perception, Behavior, and Learning in a Simulated Physical World</a></li>

<li><a href="#making-robots-from-swimming-fossils-toshiyasu-kondo">Making Robots from Swimming Fossils: Toshiyasu Kondo</a></li>

<li><a href="#artificial-life-journal-reference-list">Artificial Life Journal Reference List</a></li>

<li><a href="#paper-geometric-analysis-of-shell-coiling-general-problems">Paper: Geometric Analysis of Shell Coiling: General Problems</a></li>

<li><a href="#bonus-cover-image-easter-eggs">BONUS: Cover Image: Easter Eggs</a></li>

<li><a href="#about-the-artificial-life-newsletter">About the Artificial Life Newsletter</a></li>

</ul>

<h1 id="theo-jansens-strandbeests">Theo Jansen's Strandbeests</h1>

<p>*Written by <a href="https://lanasina.github.io/">Lana</a>; images used with permission from <a href="https://www.strandbeest.com/">Theo Jansen</a></p>

<p><img alt="Theo Jansen standing with a strandbeest" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/Theo_Jansen_The_Hague.jpeg" /></p>

<p>Theo Jansen in The Hague (© Theo Jansen)</p>

<p>For more than 30 years, artist Theo Jansen's artificial "beach animals" (strandbeests) have fascinated the world.

Every winter, Jansen builds a giant skeletal structure out of various materials. Many have sails, all have legs.

In the summer the new strandbeest is released on the beach of The Hague to walk all season, propelled only by wind.</p>

<p><img alt="A strandbeest walking" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/strandbeest.gif" />

A strandbeest walking (public domain)</p>

<p>Strandbeests are popular in the ALife community for their robust walking abilities on unstable terrain, achieved without brains or electricity; their evolution through the years, leading to a genealogical tree with innovations such as self-propelling or energy storage; and simply their fluid artistic beauty.</p>

<p><img alt="A flying strandbeest" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/flying_strandbeest.jpg" />

A flying strandbeest (© Theo Jansen)</p>

<p>Theo Jansen's interest does not stop at physical structures; <a href="https://www.strandbeest.com/strandbeest/1989-vermiculusantramentum">here</a> he is programming self-reproducting worms in 1989!</p>

<p>You can keep up with new generations of strandbeests, book a beach viewing, or buy your own mini-strandbeest via Theo Jansen's website:

<a href="https://strandbeest.com/">https://strandbeest.com/</a>

Many thanks to Mr Jansen for letting us share his wonderful pictures.</p>

<h1 id="powder-world-simulation-for-rl">Powder World Simulation for RL</h1>

<p>*Write up by <a href="https://scholar.social/@caranha">Claus</a></p>

<p><a href="https://en.wikipedia.org/wiki/Falling-sand_game">Falling Sand Games</a>

always had a special place in my heart. In the original 2005 game, you

could mix elements like sand, water, fire and oil to produce all sorts

of amazing interactions. In that time, people quickly made derivatives

with increasingly more complex particle types.</p>

<p>Last year, <a href="https://kvfrans.com">Kevin Frans</a> published an OpenAI Gym

compatible <a href="https://kvfrans.com/static/powder/">RL environment that implements

PowderWorld</a>, using GPU for fast

simulation. Agents can place or remove pixels from the world in order

to solve a variety of tasks, such as destroying the environment, or

moving particles to specific locations. A <a href="https://arxiv.org/abs/2211.13051">paper overviewing the

environment</a> was published in ICRL

2023.</p>

<p><img alt="Examples of tasks created in the Powderworld Engine" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/powder_world.png" /></p>

<p>Beyond nostalgia, I think this environment could be a great tool to

explore concepts of open-endedness. I imagine searching initial states

for emergent/interesting systems would be a very cool task. </p>

<h1 id="from-the-archives-paper-artificial-fishes-autonomous-locomotion-perception-behavior-and-learning-in-a-simulated-physical-world">From the Archives - Paper: Artificial Fishes: Autonomous Locomotion, Perception, Behavior, and Learning in a Simulated Physical World</h1>

<p>*Written by <a href="https://twitter.com/imy_tk">Imy</a></p>

<p>It feels fitting that we continue in the spirit of this month’s newsletter and revisit a (what would now be considered) “classic” paper from the Artificial Life journal on artificial fishes**. This month’s paper, <em>Artificial Fishes: Autonomous Locomotion, Perception, Behavior, and Learning in a Simulated Physical World</em>---published in 1995 by Demetri Terzopoulos, Xiaoyuan Tu, and Radek Grzeszczuk----showcases a wonderful piece of work describing their modelling of artificial fishes. That’s… pretty much it.</p>

<p>The authors describe, in striking detail, their bottom-up compositional approach to creating these animats: seeking to model as many components (agents, environment, interactions) and subcomponents (e.g. fish anatomy---muscle, fins, eyes---the physics of their liquid environment, fish behaviours (collision avoidance, foraging, mating, schooling)) with a fairly high degree of realism. In turn, this means that the agents look and act as real as possible, and can provide visually convincing results for those who might be watching these virtual fishes interact with each other and their world. They also endow these fishes with a reinforcement learning algorithm for locomotion, meaning that not only do their agents behave like real fishes, but may also learn, optimise, and adapt in their dynamic environments in the same way that real fishes do. To my mind, this feels like a hugely important aspect of work like this: virtual agents and their (inter)actions need to be as comprehensible as possible to naive audiences: if these virtual fishes are used to understand natural phenomena, then their bodies, brains, and environments should resemble natural systems as closely as possible (see Barbara Webb's <em>"Animals Versus Animats: Or Why Not Model the Real Iguana?"</em> (2009): https://doi.org/10.1177/105971230933986).</p>

<p><img alt="Artificial Fish Modelling" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/artificial_fish_fig1.png" /></p>

<p>I could describe in further detail here how the fishes “live”---they generate intentions or motivations via an “intention generator” based on a set of sensory information, mental states, and an individual fish’s habits (e.g. its preferences for brightness, or temperature of water, or sex of the fish), which in turn generates goals and drives behaviours---but I would encourage you instead to read the details that this paper has to offer. From using photographs of real fish to create 3D geometric models of their virtual counterparts, or their physics-based fish model consisting of 23 nodal point masses and almost 100 springs between them to calculate and generate dynamic and realistic locomotion, this paper does not shy away from exploring a level of granularity and detail required to model a biological agent to a reasonable level of accuracy, whilst finding the balance between computational efficiency and complexity.</p>

<p>What I <strong><em>really</em></strong> like about this paper is that it feels like a sort-of manual for a passion project: basically, “we wanted to create a bunch of artificial fishes, and this is how we did it.” And that feels so quintessentially ALife. To be fair to the authors, they do also mention that the long-term goal of their project  (“[to develop] a computational theory that can potentially account for the interplay of physics, locomotion, perception, behavior, and learning in higher animals”), and they conclude the paper by proposing a number of future research directions and use-cases for artificial fishes (for instance, suggesting that artificial fishes can be a sufficient “proving ground for theories that profess competence at effectively linking perception to action” due to their “unprecedented sophistication”). But I also like that this paper was welcomed as a contribution to the ALife field in spite of any actual research question being proposed or addressed within. It is “just” (and I use that term loosely) about the construction of artificial fishes. Of course, constructing models and virtual agents like this are a necessary first step for further work and can give rise to new research questions, but the fact that this paper stands on its own as (just) a simulation of virtual fishes is inspiring. The answer to the question, "Why did these authors create these artificial fishes?" is simple: because they could.</p>

<p>** Yup. As the authors of the paper state, and much to my surprise, fishes is <strong>actually</strong> a word. The plural is fish when it refers to multiple fish of a single species, but fishes when it refers to multiple species. </p>

<h1 id="making-robots-from-swimming-fossils-toshiyasu-kondo">Making Robots from Swimming Fossils: Toshiyasu Kondo</h1>

<ul>

<li>Interview by <a href="https://lanasina.github.io/">Lana</a></li>

</ul>

<p>A <a href="https://twitter.com/robokaseki/status/1672499885906726912?s=20">robot fish</a> swims at the bottom of a shallow pool, its shape and color reminiscent of a horseshoe crab.

Another one, shaped like a sunfish, zooms in bathtub. A third one bobs to the surface, its face slightly goofy looking.

But those robots are not inspired by horseshoe crabs, or sunfish. They are fossil fishes Bothriolepis bothriolepis, Ranzania ogaii, Sacabambaspis that Toshiyasu Kondo's (<a href="https://twitter.com/robokaseki">@robokaseki</a> on Twitter) robots are bringing back to motion.</p>

<p><img src="https://alife-newsletter.github.io/Newsletter/images_edition_012/cartoon.png" width="500" alt="Sea scorpion cartoon from Kondo's educational manual"></p>

<p><em>Sea scorpion cartoon from Kondo's educational manual</em></p>

<p>Kondo's robots often help illuminating the kinetic characteristics of these fish, and he has published several papers in collaboration with paleontologists.

I asked him about his unconventional and inspirational path to the research world. (Interview edited for brevity)</p>

<p>Click here to see some of the robots in action: https://twitter.com/robokaseki/status/1445696921444646915</p>

<p><strong>What motivates you?</strong></p>

<p><img src="https://alife-newsletter.github.io/Newsletter/images_edition_012/sacabambaspis.png" width="500" alt="Sacabambaspis robot: inspired by a barrel shaped fish"></p>

<p><em>Sacabambaspis robot: inspired by a barrel shaped fish</em></p>

<p>My daughter built an aquatic robot for her high school graduation project. She entered it at an underwater robots competition, and as a reward for here good work, I contacted the Japan Agency for Marine-Earth Science and Technology and took her to see their experimental facility.</p>

<p>At that time I was already interested in aquatic robots myself, and occasionally helped as a volunteer during robot competitions. I started thinking that the students joining the competitions would benefit from educational resources about underwater robotics, especially the students creating biomimetic robots.</p>

<p><strong>Tell us more about that educational aspect of your project.</strong></p>

<p><img src="https://alife-newsletter.github.io/Newsletter/images_edition_012/kaseki_manual.jpg" width="500" alt="Comparison between the robot and the sea scorpion fossil"></p>

<p><em>From this comparison between the robot and the sea scorpion fossil, Kondo noticed that the fish had muscles dedicated to moving only the tail fin vigorously</em></p>

<p>Initially I was thinking mostly of contemporary species like sharks, focusing on observation in aquariums, study of the internal structure of prepared specimens, etc. But it turned out to be too time consuming and difficult for the students, so I pivoted to simpler swimming animal that could bring out the emotion of making one's own creation swim while being easy to build.

So I chose well preserved fossils, the ancestors of arthropods, who despite not having complex brains and not being very agile, were at the top of the food pyramid between the Ordovician and the Devonian period.</p>

<p>With the help of paleontologists and robotics engineers, after 2 years and many unexpected discoveries, I finished building a robot mimicking the motion of extinct sea scorpions and published my educational manual.</p>

<p><strong>Can your approach be used to understand life by building it, a tenet of ALife?</strong></p>

<p><img src="https://alife-newsletter.github.io/Newsletter/images_edition_012/robot.png" width="500" alt="Inside of the sea scorpoion robot"></p>

<p><em>Inside of the sea scorpion robot</em></p>

<p>After I released videos of my swimming sea scorpion and on social media and gave some lectures, it became easier to reach out to both professional and student paleontologists. I started supporting students who wanted to better understand the life of fossil animals by building robotic reproductions. The students went on to present their work at research conferences and science competitions, and thanks to their hard work it became possible for us to gather support and information from more and more researchers, including from outside Japan.</p>

<p><strong>What did your career path look like until now?</strong></p>

<p>In college I studied statistical psychology (specifically personality traits) and developed computer tools for psychology experiments. I then joined an electrical company and worked on the first educational tools on Laser Discs... I also worked on applications for Blu-ray. After leaving and becoming independent, I worked in marketing on social media and did some more development work for various platforms.</p>

<p><strong>Are there things that we can only understand by building, rather than by simulating organisms?</strong></p>

<p>It depends on what you want to understand about an organism. Their swarming behavior? Their interactions? The micro-currents at the interface between their skin and the water? In all of those cases, you are better off building a simulation.

On the other hand, the motion of real robots swimming in real water tends to be extremely different from simulated results, so if you base all of your estimations on simulated results you will never obtain a usable robot. Sometimes it is way faster and easier to just start by building the real thing. And to get inspiration for future projects, there is nothing like building, seeing, and feeling a real robot in your hands.</p>

<p><strong>Many thanks to Mr Kondo for his time and gracious access to documentation and images!</strong></p>

<h1 id="artificial-life-journal-reference-list">Artificial Life Journal Reference List</h1>

<p>*Written by <a href="https://twitter.com/imy_tk">Imy</a></p>

<p>For a few years, I have been maintaining a complete reference list of the articles published in the Artificial Life journal since its inception back in 1993. Initially, this was created so that I had a quick way to browse through all articles in the journal on a single page, to filter on specific topics or authors, or to drag-and-drop them into a tool like ResearchRabbit (http://researchrabbit.ai) to conduct further literature searches on specific areas of interest. More recently, it has become a way for me to search for, and find, interesting papers to read and review as part of the (semi-regular) paper review in this very newsletter (see above). But I’m sure that others might also find such a list useful, so I would like to use this opportunity to share it with you all. It is hosted on GitHub (https://github.com/imytk/alife_journal) in a variety of formats (RIS, BibTex, CSV), and it should be compatible with a reference manager of your choice. If you come across any issues, however, please let me know (email below).</p>

<p>I have a (loose) roadmap of updates that I’d like to get through with this, including adding in conference proceedings from previous ISAL conferences along with accompanying videos/supplementary material if they’re available. The more interesting goal right now is to use this dataset to perform a deep dive into the 30 year history of the Artificial Life journal: to look at how the ALife journal has changed and evolved over the year, the breadth, depth and trends of topics covered, and a host of other interesting questions. If you are interested in collaborating on this, please come and chat with me in person at the conference, or email me at imytkhan@gmail.com. </p>

<h1 id="paper-geometric-analysis-of-shell-coiling-general-problems">Paper: Geometric Analysis of Shell Coiling: General Problems</h1>

<p>*Written by <a href="https://twitter.com/GJSeverino">Gabe</a></p>

<p>Indeed, the beauty of nature is never as straightforward as it may seem. The way a flower blooms, the patterns of a snowflake, the symmetry of a butterfly’s wings. They are the outcomes of an elaborate balencing act of physical constraints and evolutionary pressures as intricate and layered as the most elaborate work of art. They are living manifestations of nature's own equations, found at the intersection of biology, physics, and mathematics. Yet, imagine if nature had chosen a different path. What if, instead of the reality we know, nature had painted with a different palette, a different set of mathematical equations? What if, instead of the snail shells and fish bodies we've become so farmiliar with, there were spirals and twists beyond our wildest imaginations? (Is this a Junji Ito story?!) These "what ifs" are the world of the morphospace – the canvas on which nature could have drawn, but didn't. Or perhaps, not yet!</p>

<p>But what is a morphospace? A morphospace is formalized mathematically as a point that represents a different morphology, or form. Where the axis of this space are typically a variable used to describe some physical characteristic of interest. So the closer to points are in morphospace, the more similar they would appear in form. Importantly, <em>not all</em> of the forms that can be seen within a morphospace are always found in nature, making themselves an interesting area of inquiery. It is a concept that allows us to visualize and explore the vast array of forms that biological organisms, such as shells, can take. The use of theoretical morphospaces was popularized by Paleontologist David M. Raup in a series of paper in the 1960s. Specifically, in his 1966 paper, "Geometric Analysis of Shell Coiling: General Problems," exploring the geometric parameters that govern shell coiling, such as the rate of whorl expansion (<em>W</em>), the translation rate (<em>T</em>), and the distance from the generating curve (<em>D</em>). These parameters are manipulated to generate a variety of shell forms, demonstrating the wide range of morphologies that can result from different combinations of these parameters. </p>

<p><img alt="Raup's Morphospace" src="https://alife-newsletter.github.io/Newsletter/images_edition_012/raup.png" /></p>

<p>From the study of valve structure in brachiopods, fish body shape, to the work of understanding different possible network architectures when balancing small worldness and shortest path. Morphospaces have had a wide range of applications in the study of biological systems. Yet, one cannot help but wonder about the possibilities of morphospaces in line with "life as it could be". Many disciplines within Artificial Life involve the creation of artificial organisms, such as artificial neural networks, evolutionary robotics, and artificial chemistries often involves defining a space of possible forms or behaviors, much like a morphospace. Much like how a morphospace defines a space of possible biological forms, these disciplines often involve defining a theoretical space of possible artificial forms or behaviors.</p>

<p>By considering the possible configurations and behaviors of artificial organisms, scientists can better understand not only the potential of artificial life, but also gain insights into the constraints and possibilities that define biological life. In this way, the concept of morphospace serves as a valuable tool for both understanding the diversity of life as we know it, and imagining life as it could be.</p>

<p>If you're interested in reading more about morphospaces, you might want to check out the book <a href="https://www.cambridge.org/core/journals/short-courses-in-paleontology/article/abs/theoretical-morphology-the-concept-and-its-applications/B1FD474C1ECA2D0BEA20B23CF3C671E4">Theoretical Morphology: The Concept and Its Applications</a> by George McGhee (Raup's own Graduate Student!). </p>

<h1 id="bonus-cover-image-easter-eggs">BONUS: Cover Image: Easter Eggs</h1>

<p>Did you manage to find all of the Artificial Life-related easter eggs in the cover image (created by our very own Gabe)? Here is the list of little references that he managed to sneak in:</p>

<ul>

<li>Conway's Game of Life Clouds (all 4 permutations of the glider are hidden within: did you find them all?)</li>

<li>Karl Sims' Virtual Creatures</li>

<li>Charles Darwin (reading the Artificial Life newsletter, of course...)</li>

<li>The ALife Newsletter Mascot! (which might come to be known as "Allie" --- great suggestion by Lana!)</li>

</ul>

<p>If you managed to get all of those references, then well done! Thank you, Gabe, for such a lovely and creative cover image for this very special edition of our newsletter.</p>

<h1 id="about-the-artificial-life-newsletter">About the Artificial Life Newsletter</h1>

<p>The Alife Newsletter is a bi-monthly publication that aims to bring

interesting news to the Artificial Life community.</p>

<p>The current editors of the newsletter are: 

- Lana Sinapayen

- Imy Khan

- Mitsuyoshi Yamazaki

- Claus Aranha

- Gabriel Severino</p>

<p>The newsletter is sent by e-mail and can also be acessed by RSS. You

can <a href="https://forms.gle/QpQ68xhvSMt4wiv89">subscribe here</a> or follow

the <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">RSS feed here</a>.</p>

<p>If you have any suggestions for future content, or would like to help

us edit the newsletter, you can leave us a message in the <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">feedback

form</a>. We specially appreciate

messages from Master and PhD students who want to talk about their

recent work. Send us a line!</p>



]]></description>
 </item> <item>
  <title>The 11st edition of the Alife Newsletter, May 2023</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_011.html</link>
  <guid>edition_011</guid>
  <pubDate>29 May 2023 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 11th issue of the Alife Newsletter!</p>

<p>The theme for this issue is <strong>creatures</strong>, virtual creatures, real

creatures, fictional creatures. If it moves, we got it here!</p>

<p>Some of the amazing contributions to this edition include: a link to a

paper about an interface for people to play games with algae; a web

game that allows you to design a virtual creature with bones, muscle

tissue and brain controls; a review of a paper laying the basic ideas

of modelling life; and many other interesting tidbits! Claus and Mitsuyoshi also take you through the process of creating this very newsletter. It's not a huge commitment, so join us!</p>

<p>Talking about creatures, we would like to welcome <a href="https://twitter.com/GJSeverino">Gabriel

Severino</a>, who has joined the team

with an amazing contribution: the banner that you see on top of this

edition!</p>

<p>By the way, if you are joining us in Hokkaido for <a href="https://2023.alife.org/">ALIFE 2023</a> 

in July, don't forget to book your hotels now! July is high season in Sapporo, and the 

weekend of the conference coincides with one of the most famous fireworks of the area, so 

many of the hotels are going to be booked by tourists.</p>

<p>If you'd like to contribute in any way to the newsletter: talking

about your project, boosting something that you like, or even just

giving suggestions about what we should cover next, please leave us a

message at <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">this form</a>! In

particular, we are specially interested in Master and PhD students who

want to talk about their own research ideas. Do send us a line!</p>

<p>If you'd like to receive our news, you can subscribe by e-mail

<a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>, or by RSS

<a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">here</a>.</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Gabriel.</p>

<div class="toc">

<ul>

<li><a href="#playing-video-games-with-algae">Playing Video Games with Algae</a></li>

<li><a href="#crescent-loom">Crescent Loom</a></li>

<li><a href="#book-review-the-mountain">Book Review: "The Mountain"</a></li>

<li><a href="#emerging-researchers-in-artificial-life-now-on-discord">Emerging Researchers in Artificial Life - Now on Discord!</a></li>

<li><a href="#paper-review-on-modeling-life-by-chris-adami-1994">Paper Review - On Modeling Life by Chris Adami (1994)</a></li>

<li><a href="#the-alife-community-in-scientific-american">The ALife community in Scientific American</a></li>

<li><a href="#summary-of-survival-strategies-of-artificial-active-agents">Summary of "Survival strategies of artificial active agents"</a></li>

<li><a href="#how-is-the-artificial-life-newsletter-made">How is the Artificial Life Newsletter Made?</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="playing-video-games-with-algae">Playing Video Games with Algae</h1>

<p>Shared by <a href="mstdn.science/@lana">Lana</a></p>

<p>In this 2019 paper, Washington et al created a JavaScript web toolkit to allow real-time interaction with swarms of the algae Euglena, used as "active matter".

Beginner and expert users were then able to program little video games where the human gamer interacts with the algae through joysticks or LEDs.

Sadly <a href="https://github.com/hirklab/euglenalab">the code</a> seems to have gone stale since the paper was published, but have a look at the game descriptions and this video of the interface!</p>

<p><img alt="Figure from the paper showing screen captures of the different games created by users. Caption: Study participants (studies S1b and S1c) were enabled to create a variety of interactive biological applications (A–D, Top is screenshot and A–D, Bottom is illustrative picture of program). (A) (novice user, study S1b) A video game where the player must get specific Euglena into a moving virtual green box, controlled by the player, while the user-directed LEDs shine in the direction of the moving box, making the Euglena move away from the target goal. (B) (expert user, study S1c) A continuously rotating line visualizing the average orientation of all organisms detected by the BPU. (C) (expert user, study S1c) A two-player game where the first player shoots the red ball from a particular position with the aim of hitting as many Euglena as possible, while the second player then tries to steer the Euglena with the arrow keys (mapped to LEDs) so that the ball avoids as many Euglena as possible. (D) (semiexpert user) A histogram of Euglena rotations on the screen, grouped into bucket sizes of 10°. This program allows the user to change the intensity of the four LEDs by dragging four sliders on the screen. This program was created by an undergraduate who did not participate in any study and who later joined the research team. Mouse click event listeners were not explicitly supported by the current version of Bioty but were added through native JavaScript mouse event handlers on the HTML5 canvas." src="https://alife-newsletter.github.io/Newsletter/images_edition_011/euglena-game.png?h=100" /></p>

<p><img alt="Video from the paper showing the UI with code and a live feed of the algae." src="https://alife-newsletter.github.io/Newsletter/images_edition_011/euglena-game.gif?h=100" /></p>

<p><a href="https://www.pnas.org/doi/full/10.1073/pnas.1815367116">Interactive programming paradigm for real-time experimentation with remote living matter</a> Washington, P., Samuel-Gama, K. G., Goyal, S., Ramaswami, A., &amp; Riedel-Kruse, I. H.</p>

<h1 id="crescent-loom">Crescent Loom</h1>

<p>By <a href="https://twitter.com/jovialthunder">OLIVE 🌺🐍</a></p>

<p><strong>Crescent Loom</strong> is a game about weaving new forms of life. Players build up an intuitive sense of central pattern generators by knitting bones, stitching muscles, and linking neurons to design an underwater creature in a biologically-realistic neuronbiology simulation. After using these Lego-like biological tools to make a creature, it is then put to the challenge of exploring environments, navigating past hazards, and competing against each other in races — all with constant access to view and modify their simulated nervous system in real time. </p>

<p><img alt="Animation of a creature swimming with its nervous system lighting up on the side" src="https://alife-newsletter.github.io/Newsletter/images_edition_011/crescent_01.gif?h=100" /></p>

<p>By wrapping a detailed RC-circuit model in a friendly user interface, it is designed to be the most accessible entryway into previously-gated high-level neuroscience concepts like reciprocal inhibition, postinhibitory rebound, reversal potentials, and channel-based intrinsic membrane properties. Over 5000 creatures have been made and uploaded to the public pool.</p>

<p><img alt="Screenshot of the connectome explorer" src="https://alife-newsletter.github.io/Newsletter/images_edition_011/crescent_02.png?h=100" /></p>

<p>There is also a virtual wetlab "Connectome Explorer" which provides mock lab tools to puzzle out obscured connectomes of creatures created in the game's editor. Students can collect data to map unknown nervous systems using ablation, optogenetics, current clamping, and pharmacological blockers of excitation, inhibition, and action potentials.</p>

<p>Crescent Loom can accessed and played for free in-browser at <a href="https://crescentloom.com/">crescentloom.com</a></p>

<h1 id="book-review-the-mountain">Book Review: "The Mountain"</h1>

<p>By <a href="https://twitter.com/Jallafsen">Kai Olav Ellefsen</a></p>

<p>"Mountain" is a short story from 2012 by Liu Cixin, author of The

Three-Body Problem. It is available in the Apex Magazine or in

the short story collection "The Wandering Earth".</p>

<p>Mountain tells the story of an alien ship appearing on Earth, and the

aliens describing how they developed into a space faring

civilization. From an ALIFE-perspective, this story is fascinating, as

it asks the question of how a civilization would develop if it started

out with conditions that are very different to those faced by life on

earth.</p>

<p>The aliens describe their species originating in a space they call the

"Bubble World": A spherical space without gravity around 3,500 miles

in diameter, surrounded by a solid wall of rock in all

directions. Similar to human explorers throughout the ages, the aliens

after a while developed a drive to discover what existed beyond the

walls of their bubble world and began developing technology for

tunneling through the rock wall. "Mountain" goes on to describe in

fascinating detail how this alien species went on to form theories

about the universe they found themselves in, allowing them to find

their way out of the "Bubble world" and eventually even begin to

explore other planets.</p>

<p>The details of the aliens' journey are best experienced in the short

story. From an ALIFE perspective, I found it fascinating to see this

very detailed description of how a civilization could develop

technology, form theories about their surroundings and explore their

universe in an environment so different from the one our civilization

has developed in. For instance, the story describes the iterative

development of scientific theory through generations of the aliens'

lifetimes: Initially, the aliens believed their world was one of

potentially several hollow bubbles in an otherwise solid

universe. They called this cosmology the Solid Universe

Theory. However, after thousands of years of exploring deep into the

walls of their bubble, the aliens make a surprising discovery: The

density of the walls decreased in all directions - indicating there

may be an outer edge beyond which their universe is no longer

solid. Obviously, this discovery shook the alien society, leading some

(the Solid Universe purists) to dismiss it with alternative

explanations, while others saw it as a beginning of a new scientific

theory of their universe.</p>

<p>Liu Cixin has done a very impressive job carefully thinking of the

details of how an alien society would work in these strange

environmental conditions, and by describing these details he forces

the reader to reflect on our own planet, and our own theories of

physics and cosmology.</p>

<h1 id="emerging-researchers-in-artificial-life-now-on-discord">Emerging Researchers in Artificial Life - Now on Discord!</h1>

<p>By <a href="https://twitter.com/Imy_TK">Imy Khan</a> on behalf of the ERA Board.</p>

<p>The Emerging Researchers in Artificial Life (ERA) group is transitioning over to Discord as the main platform of communications. The community is growing (again), and we would love to have you there. Since it's inception, the intention for the ERA group has been to create a space for (self-identifying) emerging (early) researchers in the ALife community to make connections, have discussions, and generally find ways to connect and have fun. </p>

<p>The ERA group is also running informal seminars and hang outs every few weeks on Discord, where you can also learn a little bit more about the group and its current members.</p>

<p>Please join the Discord using the link <a href="https://discord.gg/fvJkKCKy4C">here</a>. See you inside.</p>

<h1 id="paper-review-on-modeling-life-by-chris-adami-1994">Paper Review - <strong>On Modeling Life</strong> by Chris Adami (1994)</h1>

<p>Paper Link: <a href="https://direct.mit.edu/artl/article-abstract/1/4/429/2236/On-Modeling-Life">Here</a>

Review By <a href="https://twitter.com/Imy_TK">Imy Khan</a>.</p>

<p>This month, I spent a little bit of time digging into the Artificial Life journal archives with two aims: first, to get a better understanding of the type of reesarch that the artificial life field consisted of in the early years after its inception, and secondly, to find a paper that captures (in my view) the <strong>essence</strong> of artificial life, as if to show to someone unaware of the field, <em>"Hey, look, this is the kind of thing Artificial Life is interested in exploring."</em></p>

<p><a href="https://direct.mit.edu/artl/article-abstract/1/4/429/2236/On-Modeling-Life?redirectedFrom=fulltext">On Modeling Life</a>, written by Chris Adami and published in 1994 in the Artificial Life journal, is one such paper. The title itself is a bold statement, sure to catch the eye of future readers (it caught mine). The paper puts forth a model of life consisting of three minimal characteristics - self-replication of information, bit-wise mutation of information, and an environment (landscape) of information - proposing that a system consisting of these can form the foundations of a (minimally-)living system, with good universal approximation. Adami puts forth theoretical and experimental results (using Tierra and Avida) in defense of this point. Though the entire paper is worthy of a read, I was particularly enticed by this notion that Darwininan evolution may not have been a continuous process, but may have been "punctuated": where there were periods of stasis followed by large evolutionary changes (this may have common knowledge to some, but was completely new information to me!). Assuming the minimal criteria for living systems used in the model, Adami presents further experimental results to support this notion. It is statatements and experimental results like these that truly capture the beauty of ALife, in my opinion.</p>

<p>As a general musing, I also appreciate the conciseness of the paper: at only 10 pages including all of the images and references, it's a paper you can do a first read of fairly swiftly to get a good grasp of the main ideas. Even <a href="https://direct.mit.edu/artl/article-abstract/1/4/353/2234/Evolving-3D-Morphology-and-Behavior-by-Competition">Karl Sims' paper in the same year</a> was (only) 20 pages, with roughly half of the space occupied with images. In my view, at least, there seems to be more of a trend towards longer papers in recent years, but reading this paper made me feel a sense of aneomoia for much shorter, much more concrete papers.</p>

<h1 id="the-alife-community-in-scientific-american">The ALife community in Scientific American</h1>

<p>Shared by <a href="https://mstdn.science/home">Lana</a></p>

<p>Scientific American published an article on Artificial Life, and interviewed many familiar names about where they think the field is going.

This piece was more than one year in the works, and is a good intro to our field if your relatives keep asking you "what do you work on again?" and you're struggling to provide a family-friendly answer!

I don't personally agree with 100% of the opinions in the article, but I think it's really well done and I enjoyed reading it!</p>

<p><a href="https://www.scientificamerican.com/article/life-evolves-can-attempts-to-create-artificial-life-evolve-too/"><strong>Life Evolves. Can Attempts to Create ‘Artificial Life’ Evolve, Too?

Do efforts to create life—by cooking up imitations in computers, robots and molecules—point toward a universal definition of biology?</strong></a>

By Shi En Kim</p>

<p><img alt="Screenshot of the first paragraph of the article" src="https://alife-newsletter.github.io/Newsletter/images_edition_011/sciam.png?h=100" /></p>

<h1 id="summary-of-survival-strategies-of-artificial-active-agents">Summary of "Survival strategies of artificial active agents"</h1>

<p><em>By the authors Luigi Zanovello, Richard J. G. Löffler, Michele Caraglio, Thomas Franosch, Martin M. Hanczyc &amp; Pietro Faccioli</em></p>

<p>Active systems can respond to stimuli provided by the environment and undertake specific displacements to remain out of equilibrium, e.g. by moving towards regions with higher fuel concentration. In this work, we take a first step to characterize "survival strategies" in active systems by adapting and applying to active systems the theoretical framework of Transition Path Theory, which was originally introduced to investigate rare thermally activated transitions in passive systems.</p>

<p>For more details, check out the paper <a href="https://doi.org/10.1038/s41598-023-32267-3">here</a></p>

<h1 id="how-is-the-artificial-life-newsletter-made">How is the Artificial Life Newsletter Made?</h1>

<p>By <a href="https://scholar.social/@caranha">Claus Aranha</a> and <a href="https://mitsuyoshi-yamazaki.github.io/">Mitsuyoshi Yamazaki</a></p>

<p>Every two months, we put our heads together to bring this little slice

of Alife news to you. This is the process that we use.</p>

<p>Our teams meets once every month (two meetings per news letter). </p>

<p>In the first meeting, we choose the contents of the next newsletter,

and assign these to each member - usually two or three items per

member. To choose the contents, we check <a href="https://forms.gle/QpQ68xhvSMt4wiv89">the

form</a> with your contributions,

and also a big pile of interesting things that we find on the

internet. </p>

<p>In this stage, we make heavy use of a <a href="https://trello.com">Trello</a>

board, with a column for the big pile, one for the different items

that we choose for the newsletter, and another for done or rejected

items.</p>

<p>Over the next month, we work on the assigned items, writing them as

<a href="https://daringfireball.net/projects/markdown/">Markdown</a> files. These

files are kept on the <a href="https://github.com/ALife-Newsletter/Newsletter">Newsletter's Github

repository</a>. Every

time a change is pushed to the repository, it is converted to the HTML

format that you know and love using python's <a href="https://pypi.org/project/Markdown/">Markdown

Package</a>. The script concatenates

the HTML from all markdown files together, and adds a static footer

and header, including the newsletter CSS style.</p>

<p>The second meeting happens about one week before the planned date of

the newsletter. We check which of the contributions were completed,

which have to be scrapped, and which need just a little bit more work

before release. We also fix the final release date of the Newsletter.</p>

<p>The day before the newsletter we give it a final check online, and

after everyone gives the OK, we prepare it for release. The final HTML

file is sent to everyone using MailJet, and a magic text file is added

to the github repository that tells the script to update the

newsletter RSS.</p>

<p>Looks complicated? A lot of this routine grew organically, as we

learned what worked and what didn't work for each edition of the

newsletter. We still have a lot of pain points to solve (the

Newsletter Mail service being probably the biggest one). If you have

any ideas or suggestions to improve our workflow, <a href="https://forms.gle/QpQ68xhvSMt4wiv89">send us a

message</a>!</p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come

  up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial

  Life</a> is live and needs

  contributions!</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 10th edition of the Alife Newsletter, March 2023</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_010.html</link>
  <guid>edition_010</guid>
  <pubDate>17 Mar 2023 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 10th issue of the Alife Newsletter!

Congratulations to all who made it to the ALife2023 paper submission deadline, and for those who didn't, workshop deadlines are still upcoming!</p>

<p>This edition celebrates the coming in of the new season: spring is almost here, and, for many of us, that means lots of plants! We have tried to organise this month's newsletter around plant-related content, so we hope you enjoy this month's offering. From plants that can mimic other plants, to papers on self-burying seeds, to aesthetically-pleasing simulations of micro-organisms, this newsletter is filled to the brim with some very creative and interesting projects. You're sure to find at least one interesting thing here.</p>

<p>As usual, we welcome contributions, ideas and suggestions to the

newsletter at <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">this form</a>! In

particular, we are specially interested in Master and PhD students who

want to talk about their own research ideas. Do send us a line!</p>

<p>If you'd like to receive our news, you can subscribe by e-mail

<a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>, or by RSS

<a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">here</a>.</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#solarpunk-and-plants-in-video-games">Solarpunk and Plants in Video Games</a></li>

<li><a href="#alife-game-openpraparat">ALife Game: OpenPraparat</a></li>

<li><a href="#video-can-boquila-trifoliolata-mimic-other-plants">Video: Can Boquila Trifoliolata mimic other plants?</a></li>

<li><a href="#paper-review-autonomous-self-burying-seed-carriers-for-aerial-seeding-luo-et-al-2023">Paper Review: Autonomous self-burying seed carriers for aerial seeding (Luo et al. 2023)</a></li>

<li><a href="#amazing-particles-simulations-on-gpu">Amazing Particles Simulations on GPU</a></li>

<li><a href="#media-review-the-t2-tile-project-channel">Media Review: The T2 Tile Project Channel</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="solarpunk-and-plants-in-video-games">Solarpunk and Plants in Video Games</h1>

<p><a href="mstdn.science/@lana">Lana</a> relaying a thread by <a href="https://twitter.com/logicsoup">Eli</a></p>

<p>Have you heard of <a href="https://en.wikipedia.org/wiki/Solarpunk">Solarpunk</a>? I had not. According to Wikipedia, "Solarpunk is a literary and artistic movement that envisions and works toward actualizing a sustainable future interconnected with nature and community."

I don't play much video games but that is certainly a genre I enjoy, even if I didn't know it had a name!</p>

<p>Last January, <a href="https://twitter.com/logicsoup">Eli</a> posted a <a href="https://twitter.com/logicsoup/status/1619775847778619392?t=xx8P6dLCMskMpuM54W1vnA&amp;s=19">Twitter thread</a> on Solarpunk games and games focused on plant simulation.

There is a lot of overlap with ALife topics, so I encourage you to go have a look! Here are some images from the thread:</p>

<p><img alt="shumi" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/shumi.png?h=100" />

<img alt="ecosystem" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/ecosystem.png?h=100" />

<img alt="hybrids" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/hybrids.png?h=100" /></p>

<h1 id="alife-game-openpraparat">ALife Game: OpenPraparat</h1>

<p>By <a href="https://twitter.com/alife_praparat">Keishu Utimula</a></p>

<p><a href="https://github.com/A5size/OpenPraparat">OpenPraparat</a> is a code that simulates an artificial life model presented in the paper "<a href="https://arxiv.org/abs/2210.12854">Artificial Life using a Book and Bookmarker</a>". <br></p>

<p>This artificial life model is proposed with the aim of simulating reproduction, development, and individual interactions while providing high expressiveness for morphology and behavior. In this model, an artificial life body is constructed from spheres called cells and springs connecting them. Each cell has a Book as a gene and a Bookmarker that specifies the readout position of the Book. The artificial life body is formed by the cell expanding new cells and connecting around cells, according to the instructions in the Book. In addition, each cell has a neural network and can respond to external stimuli such as contact with other cells and photons.<br></p>

<p>Currently, two types of creatures have been found in this model. One is a dumbbell-shaped creature, and the other is a reticulated creature. <br></p>

<p>The dumbbell-shaped creature has a body where two cells are connected, literally shaped like dumbbells. This dumbbell-shaped creature multiplies by asexual reproduction, during which it deploys a white protective organ.  This is a trait they have acquired during evolution to make them less likely to be eaten by other creatures. <br>

<img alt="dumbbell" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/OpenPraparat_dumbbell.png" /></p>

<p>The reticulated creatures are constructed by a large network of many interconnected cells. Its mode of reproduction is asexual, like that of the dumbbell-shaped creatures, but in the case of this reticulated creature, it has acquired the survival strategy of expanding its habitat by tearing off parts of its body and sending them flying far away. <br>

<img alt="reticulated" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/OpenPraparat_reticulated.png" /></p>

<p>By installing this OpenPraparat, you will be able to simulate these creatures by yourself and also search for new ones! <br></p>

<p>We eagerly await your reports of the discovery of new species of creatures! <br></p>

<h1 id="video-can-boquila-trifoliolata-mimic-other-plants">Video: Can Boquila Trifoliolata mimic other plants?</h1>

<p>Video from <a href="https://www.youtube.com/@SciShow">SciHow</a>, shared by <a href="https://mstdn.science/@lana">Lana</a></p>

<p>I (Lana) have been intrigued by the Peruvian vine Boquila Trifoliolata for years, and even unsuccefully tried to import some for experiments (if you can help hit me up).

That plant is said to (maybe) be able to imitate the shape of other plants around it - unfortunately, the published research on the topic is spare and lacking control experiments.

Does it really change the shape of it leaves? Can it actually see shapes, as claimed by one very criticized paper?

SciHow recently released a <a href="https://www.youtube.com/watch?v=5UWWsYw9fH0&amp;t">video</a> that summarizes the strange claims arount this plant.</p>

<p><img alt="an image here" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/boquila.png" /></p>

<h1 id="paper-review-autonomous-self-burying-seed-carriers-for-aerial-seeding-luo-et-al-2023">Paper Review: Autonomous self-burying seed carriers for aerial seeding (Luo et al. 2023)</h1>

<p>By <a href="https://twitter.com/imy_tk">Imy Khan</a></p>

<p>Paper Link: <a href="https://www.nature.com/articles/s41586-022-05656-3">LINK</a></p>

<p>The process of "aerial seeding" (or "re-seeding", or "reforestation") is, as the name suggests, a process by which seeds can be distributed (or sown) over areas of land via aerial means, by using vehicles such as helicopters or drones. These processes are advantageous in some scenarios: being able to sow seeds in hard-to-reach areas (i.e. areas of high elevation), or to (re)distribute seeds across large areas in a time-effective manner (i.e. after a natural disaster) to stop the growth of invasive species, can help maintain or improve levels of vegetation over a given land mass. However, the success of aerial seeding hinges on the seed's ability to successfully sow into the ground that it was dispersed. The morphology of natural seeds, including the payload they can carry and the types of soils they can successfully bury themselves into, have evolved to the specifical ecological niche that they have typically grown in. Therefore, the morphology of natural seed carriers (such as the Erodium seeds) may not be suited for the environmental conditions in which they would need to be distributed through aerial seeding - potentially limiting the success of this type of technique.</p>

<p><img alt="an image here" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/Self-burying3.gif" /></p>

<p>The authors of the paper above looked to address this problem. In it, the authors, who were inspired by the structure and dynamics of a natural seed (Erodium), designed and tested a bio-inspired self-burying seed carrier that may be able to overcome some limitations of natural seed carriers. They describe their design of a number of "three-tailed seed carriers" using wood veneer (selected for its stiff biomass), and also give a wonderful description of their experiments and computer (numerical) simulations to optimise the design of these seed carriers. They tested the efficacy of these designs in both laboratory and outdoor conditions, comparing the performance to the Erodium seed and a number of other (hygroscopic) seeds. Their results show significant success, in terms of anchoring rate and germination rate, for their seed carriers, over their natural counterparts. </p>

<p>Such a short review cannot do the content or the quality of this paper true justice. Nevertheless, it is a pleasant read and an excellent showcase of ALife approaches being applied to natural world problems.</p>

<h1 id="amazing-particles-simulations-on-gpu">Amazing Particles Simulations on GPU</h1>

<p><a href="mstdn.science/@lana">Lana</a> relaying a thread by <a href="https://twitter.com/SoerbGames">Sørb</a></p>

<p><a href="https://twitter.com/SoerbGames">Sørb</a> has implemented a particle simulator on Unity and the results are not only very aesthetic, they lool like what you'd see looking at pond water under the microscope: teeming with organisms interacting with each othet!

Go check out <a href="https://twitter.com/SoerbGames/status/1631301424381394944">Sørb's work</a>, here is a teaser:</p>

<p><img alt="particles" src="https://alife-newsletter.github.io/Newsletter/images_edition_010/ezgif-2-9fdb540b7a.gif" /></p>

<h1 id="media-review-the-t2-tile-project-channel">Media Review: The T2 Tile Project Channel</h1>

<p>By <a href="https://scholar.social/@caranha">Claus Aranha</a></p>

<p>What if we built a computational framework composed of independent

units that could be plugged in and out together at will and, more

amazingly, <strong>online</strong>?</p>

<p>This is the premise of the <a href="https://t2tile.com">T2 Tile project</a>,

developed by <a href="https://scholar.social/@livcomp@hachyderm.io">Dave

Ackley</a>. In his own

words:</p>

<blockquote>

<p><strong>The T2 Tile project is an attempt to build the world's first

indefinitely scalable computational stack.</strong> First, we suspend the

idea that we must be bound to an architecture based on correct and

efficient deterministic hardware and software. Instead, much like

the physical world around us, we look to robustness as a

foundational requirement, building living systems as vessels for

digital computation that is firstly robust, then as correct as

possible, and finally, as efficient as necessary.</p>

</blockquote>

<p>Maybe you have heard of this project before, but did you know that

Dave has been doing a <a href="https://www.youtube.com/@T2TileProject">Video

Blog</a> of the project on

Youtube for the past 4 years?</p>

<p>The videos are short (about 20 minutes), fun, and for me they have

been something to look forward to every month. Not only for learning

about the project itself, but also to think about how to do science

communication in today's media landscape. </p>

<p>Here is for another year of big fun!</p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come

  up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial

  Life</a> is live and needs

  contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested

  in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 9th edition of the Alife Newsletter, January 2023</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_009.html</link>
  <guid>edition_009</guid>
  <pubDate>12 Jan 2023 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Happy 2023, and welcome to the 9th issue of the Alife Newsletter!</p>

<p>For the first edition of 2023, we have some technical news: The newsletter now has an RSS feed! If you have an RSS reader, you can point it to <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">this link</a> to receive announcements of new editions of the newsletter. Give it a try!</p>

<p>The theme for this edition is "[micro] organisms | cosms | scale". For micro-organisms, we report on a novel idea for an wearable device that integrates living mold with electronics. For micro-cosms, we link a review of small programs that can generate complex worlds. And for micro-scale, we found a delightful art imagining the origins of life.</p>

<p>In adition, we have a paper review about life as information, and the syllabus of a new artificial life course, as well as CFP deadlines and announcements of PhD positions! We hope you find something that pique your interest.</p>

<p>As usual, we welcome contributions, ideas and suggestions to the newsletter at <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">this form</a>! In particular, we are specially interested in Master and PhD students who want to talk about their own research ideas. Do send us a line!</p>

<p>If you'd like to receive our news, you can subscribe by e-mail <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>, or by RSS <a href="https://alife-newsletter.github.io/Newsletter/RSS.xml">here</a>.</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#paper-integrating-living-organisms-in-devices-to-implement-care-based-interactions">Paper: “Integrating Living Organisms in Devices to Implement Care-based Interactions”</a></li>

<li><a href="#alife-paper-review-the-world-as-evolving-information">ALife Paper Review: The World as Evolving Information</a></li>

<li><a href="#a-new-course-on-artificial-life">A new course on Artificial Life</a></li>

<li><a href="#hiring-phd-candidate-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence-at-the-university-of-oslo">Hiring PhD Candidate in Biologically Inspired methods for Robotics and Artificial Intelligence at the University of Oslo</a></li>

<li><a href="#abiogenesis-artwork-by-markos-r-kay">Abiogenesis (artwork by Markos R. Kay)</a></li>

<li><a href="#emergent-microcosms-a-blog-post-by-samuel-arbesman">Emergent Microcosms (a blog post by Samuel Arbesman)</a></li>

<li><a href="#upcoming-deadlines">Upcoming Deadlines</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="paper-integrating-living-organisms-in-devices-to-implement-care-based-interactions">Paper: “Integrating Living Organisms in Devices to Implement Care-based Interactions”</h1>

<p>By <a href="https://twitter.com/xjasminelu">Jasmine Lu</a> and <a href="https://twitter.com/plopesresearch">Pedro Lopes</a> (University of Chicago's Human Computer Integration Lab)</p>

<p><img alt="Slime mold watch" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/1-watch-textlabel.jpg" /></p>

<p>In this paper, we explore how embedding a living organism (in this case a slime mold, Physarum Polycephalum) as a functional component of a device, changes the user-device relationship. In our design, the user needs to care for the living organism (by providing food and water) in order for the device to work. When healthy, the organism participates in the device’s functionality by acting as a physical wire that enables power to the watch’s heart rate sensor. As such, caring for the device is intrinsic to its interaction design —with the user’s care, the slime mold becomes conductive and enables the sensor; conversely, without care, the slime mold dries and disables the sensor, and resuming care resuscitates the slime mold.</p>

<p>In addition to engineering this device, we also conducted a user study where participants wore our slime mold-integrated smartwatch for 9-14 days. We found that participants developed a unique connection towards their slime mold-integrated device, with many feeling a sense of responsibility and/or reciprocity.</p>

<p>Rather than a user-device relationship built on extractive use, our approach explores how devices can be designed to encourage the user to take on a caretaking role. We're excited about how our approach might foster new discussions about how we might rethink the user-device relationship. </p>

<p><img alt="How it works" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/6-interaction-graphic.jpg" /></p>

<p>Read <a href="http://lab.plopes.org/#integrating-living-organisms">our paper</a> or <a href="https://youtu.be/Bex91KV56PQ">watch the project video</a></p>

<h1 id="alife-paper-review-the-world-as-evolving-information">ALife Paper Review: The World as Evolving Information</h1>

<p><a href="https://arxiv.org/abs/0704.0304">https://arxiv.org/abs/0704.0304</a></p>

<p><em>Paper review by <a href="https://twitter.com/m_crosscombe">Michael Crosscombe</a></em></p>

<p>I recently transitioned into Artificial Life research and I have been digging through the digital archives to familiarise myself with some of the exciting ideas in the field. Given my outsider’s perspective, I find that I am most drawn to papers which offer a novel way of thinking about the world and, in doing so, provide a different lens through which we can approach the ongoing problems of the field.</p>

<p>One paper in particular is that of “The World as Evolving Information” by Carlos Gershenson. The author proposes that we adopt metaphors as our common language and then goes on to describe the world at different scales – not in terms of energy and matter, but in terms of information! Beginning simply, information is defined as “anything that an agent can sense, perceive or observe.” After additional notions to define an agent and its environment, it becomes clear why such an approach to thinking about the world is rather powerful. An agent simply acts on its environment (sense and response) and the environment is itself all that which interacts with the agent. From this simple setup, the author then introduces a list of “Tentative Laws of Information” with each law appearing reasonable and intuitive.</p>

<p>While not a solution to all of ALife’s open problems, I do think it is an interesting way to reframe existing problems and assess whether different approaches to tackling them can be taken. Consider, for example, collective behaviour. It is difficult to consider how large swarms of individuals coordinate to produce collective behaviour without considering the forms of information that are shared, propagated, and transformed to achieve said behaviour. We can also begin to consider the scales of these systems: Simplistic individuals are only capable of acting locally, and cannot perceive more complex information globally, such as the current state of the swarm or its coordinated collective behaviour. Yet the swarm, as a more complex entity, seems to be capable of producing more complex information (behaviours) than any one individual is capable of, and reasoning about the relationships between the micro and macro levels are much more intuitive when we think about them within the proposed framework.</p>

<p>A system more easily translated into the world of evolving information may be Cellular Automata (CA). These systems have well-defined, often deterministic rules about how information (the state of a cell) changes based on the information that an agent (the cell itself) can perceive. Such a discrete system should be rather trivial to quantify, but how would something more complex, such as Lenia, translate into the same world? This is far less trivial, but presumably still feasible.</p>

<p>At the end of the paper, frustratingly, the author hints that such a framework could be implemented in simulation. I am curious whether the author has made any progress in this direction; of creating an information-based simulation that implements the tentative laws outlined in the paper.</p>

<h1 id="a-new-course-on-artificial-life">A new course on Artificial Life</h1>

<p>by <a href="https://skriegman.github.io/">Sam Kriegman</a></p>

<p><img alt="robots" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/kriegman_bots.png" /></p>

<p>In this, my first year as assistant professor at Northwestern University, I am building out <a href="https://www.xenobot.group/">my research group</a> and teaching my very first course: Artificial Life. The syllabus is available <a href="https://docs.google.com/document/d/1jURIbvpQ0imcaMk-AHUmj_szZNtsA4lZAlcqXa6usXs/edit?usp=sharing">here</a>. One-hundred-and-thirty extremely bright and creative students are now learning about the wonderful world of ALife for the very first time, and I get to stand in front of them each week as Morpheus with a firehose of red pills, feeding them all of the beautiful and inspiring work of this community, and watching their minds explode.</p>

<p>Because Northwestern is on a quarter system, I have the impossible task of covering the entirety of ALife in just nine weeks. And, as a new assistant professor, I have been flying by the seat of my pants. I am writing this to share my excitement and, also, to solicit comments, compliments and criticisms from the community. You can email me directly or share anonymous feedback through the form linked in the footer of the syllabus.</p>

<p>This new ALife class stands firmly on the shoulders of <a href="https://www.reddit.com/r/ludobots/">Ludobots</a>, a reddit-based MOOC that gently guides students, step by step, toward evolving possible brains (neural controllers) of a motile creature (kinematic tree) in a virtual world (rigid body simulation). After completing Ludobots, however, the students in this new course will be thrown straight into the deep end: they will be tasked with evolving not only brains but bodies too, and to do so without step-by-step instructions. I have no idea how this will turn out. We could end up with 130 populations of wiggling worms of varying lengths and sizes, without any real “march of progress” in terms of morphological and behavioral complexity. But I think this is unlikely. Did I mention how incredibly bright these students are? I made sure to warn the students that the assignments will suddenly become much more challenging midway through the course. What I have not told them (yet) is that they will be working on a problem that no one really has any idea how to solve. Who knows, maybe one of them will end up solving it.</p>

<h1 id="hiring-phd-candidate-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence-at-the-university-of-oslo">Hiring PhD Candidate in Biologically Inspired methods for Robotics and Artificial Intelligence at the University of Oslo</h1>

<p>by Kai Olav Ellefsen, University of Oslo</p>

<p>The PhD research fellow will carry out research on AI and machine learning techniques (including search / optimization) for robotic systems, at the group of Robotics and Intelligent Systems (ROBIN). We wish to build on our previous and ongoing projects in Evolutionary Robotics with the aim of developing new methods for more robust and flexible robotic adaptation. This could include combining Evolutionary Robotics with recent advances from Deep Learning or more biologically inspired methods, such as Neuroevolution.</p>

<p>Qualifications: Applicants must have education equivalent to a Norwegian masters degree in computer science, robotics, or other relevant field. Thus, applicants should have a strong background in programming, as well as machine learning/artificial intelligence and robotics. Experience with Evolutionary Algorithms, Evolutionary Robotics, Quality Diversity optimization, Reinforcement Learning, and/or Neuroevolution are considered advantageous.</p>

<p>Pay grade (depending on qualifications and seniority):<br />

NOK 501 200 – 544 400 per year, approx.: € or $ 48,150 – 52,350</p>

<p><a href="https://www.jobbnorge.no/en/available-jobs/job/236645/phd-research-fellow-in-biologically-inspired-methods-for-robotics-and-artificial-intelligence">Announcement Page</a></p>

<p>Deadline for applications: February 1st, 2023<br />

Applications are to be submitted through a web page and NOT by e-mail.</p>

<p>Contact for more information: Assoc. Prof. Kai Olav Ellefsen E-mail: kaiolae@ifi.uio.no</p>

<h1 id="abiogenesis-artwork-by-markos-r-kay">Abiogenesis (artwork by Markos R. Kay)</h1>

<p>shared by Lana</p>

<p><img alt="Video still" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/abiogenesis.png?h=200" /></p>

<p>I found this video imagining the origins of life in oil droplets mesmerising and wanted to share it with the community. <a href="https://www.mrkism.com/abiogenesis.html">The artist says</a>: </p>

<p>"Presented here is a conceptual reimagining of the "lipid world" theory which postulates that life originated from lipids forming membranes which would then envelop matter and nutrients to form protocells. Biological cells as we now know them can be thought of us membranes within membranes."

Watch the full video <a href="https://www.mrkism.com/abiogenesis.html">here</a>.</p>

<h1 id="emergent-microcosms-a-blog-post-by-samuel-arbesman">Emergent Microcosms (a blog post by Samuel Arbesman)</h1>

<p>shared by Lana</p>

<p><img alt="a screenshot of the game &quot;orb&quot;" src="https://alife-newsletter.github.io/Newsletter/images_edition_009/orb.jpg" /></p>

<p>Sam Arbesman recently wrote a <a href="https://twitter.com/arbesman/status/1587456000856133633">vibrant Twitter thread</a>, full of videos and links to creative platforms, about the concept of "Emergent Microcosms". He ultimately released a long form version of his thought through his newsletter. Here is a short excerpt from the first paragraph, enjoy the whole post <a href="https://arbesman.substack.com/p/emergent-microcosms">here!</a></p>

<p>"In all the excitement around Large Language Models and other trendy aspects of Artificial Intelligence, I think that we’ve forgotten an under-appreciated group of computer programs: relatively small snippets of computer code that can generate complex and delightful virtual worlds. [...] Emergent microcosm is a fuzzy category, but it roughly spans biology and artificial life, complexity science, simulation, and creative coding." <a href="https://arbesman.substack.com/p/emergent-microcosms">Read Sam's post</a></p>

<h1 id="upcoming-deadlines">Upcoming Deadlines</h1>

<p>Please see below for some upcoming deadlines for some conferences relevant to the ALife community:</p>

<ol>

<li><a href="https://alife-japan.org/archives/event/第6回人工生命研究会">The 6th Workshop of Artificial Life Japan</a>: Submission of Title/Author for presentations: <strong>03 February 2023</strong></li>

<li><a href="https://gecco-2023.sigevo.org/Call-for-Papers">Gecco 2023 (Lisbon, Portugal &amp; Online)</a>: Paper Submission Deadline: <strong>10 February 2023</strong></li>

<li><a href="https://uncomp.uwe.ac.uk/art-of-cellular-automata-exhibition-spring-2023-bristol/">Art of Cellular Automata Exhibition</a>: Call for entries. Deadline: <strong>20 February 2023</strong></li>

<li><a href="https://sites.google.com/view/alife-2023/calls/call-for-papers-extended-abstracts?authuser=0">ALife 2023 (Sapporo, Japan &amp; Online)</a>: Paper Submission Deadline: <strong>3 March 2023</strong></li>

<li><a href="http://ro-man2023.org/paperSubmission/callForPapers">RO-MAN 2023 (Busan, South Korea &amp; Online)</a> Paper Submission Deadline: <strong>17 March 2023</strong></li>

</ol>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 8th edition of the Alife Newsletter, October 2022</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_008.html</link>
  <guid>edition_008</guid>
  <pubDate>01 Oct 2022 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 8th issue of the ALife Newsletter. As 2022 is drawing to

a close, we hope that everyone is having a great fall or spring!</p>

<p>This month we got two very interesting projects to share: A free book

on Conway's Game of Life by Nathaniel and Dave, and an Alife 

Simulation in Pico8 by Lj. We are particularly intersted in showcasing 

smaller projects like the last one, that inspire people to prototype and 

share their own ideas of what Alife could be!</p>

<p>Also this month we introduce our first regular column, "Creature of the Month"

by Domenic from Astrovitae, sharing a little bit of speculative 

bio to tickle everyone's mind each edition. If you have an idea for a 

regular column, please reach out! For example, we would love to have 

someone who could review alife inspired games for the newsletter.</p>

<p>As usual, we welcome contributions, ideas and suggestions to the newsletter 

at <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">this form</a>! In particular, we are 

specially interested in Master and PhD students who want to talk about their 

own research ideas. Do send us a line!</p>

<p>If you'd like to receive our e-mails, you can subscribe <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>.</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#conways-game-of-life">Conway's Game of Life</a></li>

<li><a href="#astrovitaes-creature-of-the-month-the-onyx-flutter-flea">Astrovitae's Creature of the Month - The Onyx Flutter Flea</a></li>

<li><a href="#picoworld">Picoworld</a></li>

<li><a href="#sf-review-koichi-harukure-mortal-game">SF Review: Koichi Harukure "Mortal Game"</a></li>

<li><a href="#era-board-update-202223">ERA Board Update 2022/23</a></li>

<li><a href="#post-doctoral-fellowship-opportunity-eutopia-sif-msca-cofund-deadline-dec-2022">Post-Doctoral Fellowship Opportunity: EUTOPIA-SIF (MSCA COFUND) (Deadline: Dec 2022)</a></li>

<li><a href="#upcoming-event">Upcoming Event:</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="conways-game-of-life">Conway's Game of Life</h1>

<h2 id="mathematics-and-construction">Mathematics and Construction</h2>

<p><a href="https://conwaylife.com/book/">A free book</a> by Nathaniel Johnston and Dave Greene</p>

<p>Blurb by <a href="http://www.njohnston.ca/">Nathaniel Johnston</a></p>

<p>This book provides an introduction to Conway's Game of Life, the interesting mathematics behind it, and the methods used to construct many of its most interesting patterns. The book starts by exploring many of the well-known patterns like blinkers and gliders, but quickly shifts its focus to the problem of combining these various components into complicated mega-structures that can perform unexpectedly complex tasks. In particular, the books guides the reader through the construction of patterns that are able to perform arbitrary computations, are able to create copies of themselves, and even patterns that mimic biological cells by having a central helix of DNA that controls its behavior and replication cycle.</p>

<p>While the book largely follows the history of the Game of Life, that is not its primary purpose. Rather, it is a by-product of the fact that most recently discovered patterns build upon patterns and techniques that were developed earlier. The goal of this book is to demystify the Game of Life by breaking down the complex patterns that have been developed in it into bite-size chunks that can be understood individually.</p>

<p>(Comment by Lana: Not only is the book free, but you can run every game of life patterns from the book by copy pasting the code in a web-based game of life engine like https://golly.sourceforge.net/!)</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/gol.png" /></p>

<h1 id="astrovitaes-creature-of-the-month-the-onyx-flutter-flea">Astrovitae's Creature of the Month - The Onyx Flutter Flea</h1>

<p>By <a href="https://twitter.com/domenicpennetta">Domenic V. Pennetta</a></p>

<p>Last month I shared the speculative biology magazine Astrovitae with 

the ALife community. After many excited responses from ALife members, 

I now plan on sharing a creature from Astrvoitae Magazine every month! 

In each newsletter a speculative biology artist and their chosen 

creature design will be showcased for all to see. For this initial 

"Creature of the Month", I want to showcase the first ever creature 

featured in Astrovitae, the onyx flutter flea, which was published on the 

cover of issue 1!</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/astrovitae_flutterflea.jpg" /></p>

<p>From the naked eye, these small planktonic creatures appear to float using 

a "halo" or "ring". However under closer inspection this halo is in fact 

the specimen’s forearms locked in place above its head. This particular s

pecies of flutter flea has been identified within the oceans of the 

exoplanet Perdita c, and is named Anellusbrachium onyx (a.k.a. the onyx 

flutter flea). Its large forearms forming the halo are used for feeding; 

often outstretched and are able to clamp shut when another planktonic 

organism wriggles by. Once caught, prey items will become ensnared by 

sharp follicles, and are held in place long enough to be pierced by the 

onyx flutter flea’s proboscis. Like other species of flutter fleas, A. onyx 

is found in aggregates, passively waiting in the water column for 

unsuspecting victims. </p>

<p>Interested in learning more about other flutter fleas? 

<a href="https://www.instagram.com/project_perditus/">Follow Project Perditus on Instagram</a> 

or see the projects <a href="https://www.projectperditus.com">official website</a>.</p>

<p>For more speculative biology content, see <a href="https://www.astrovitae.com/issues.html">past issues of Astrovitae Magazine</a>.</p>

<h1 id="picoworld">Picoworld</h1>

<p>by Lj Miranda (<a href="https://twitter.com/ljvmiranda921">@ljvmiranda921</a>)</p>

<p><a href="https://ljvmiranda921.itch.io/picoworld"><strong>Picoworld</strong></a> is a PICO-8 simulation

that explores the concept of <em>emergence</em> and <em>self-organization</em>. In this

sandbox game, you define a set of particles and their interaction rules.

Particles, by themselves, can only attract or repel one another. However, from

these simple interactions, we can observe complex phenomena.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/picoworld_simple.gif" /></p>

<p>I chose Pico-8 as the game engine for Picoworld because I like its small and

portable nature--like a petri dish! However, developing on Pico-8 requires you

to lean into its constraints: you are limited to a 16-color palette, a 128x128

pixel resolution, and a set amount of programming tokens. This forces me to be

more deliberate in what features I need to add (or remove). It pushes me to

achieve simplicity, and what's fun is that just like any ALife concept,

simplicity can lead to emergent complexity.</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/picoworld_sample.gif" /></p>

<p>The way Picoworld works is that you have four different types of colored

particles. Using the editor, you can define how many particles of each type to

spawn and their corresponding interaction (attraction/repulsion). You can do

this by toggling the symbol in the editor until you reach the desired value:</p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/picoworld_editor.gif" /></p>

<p>Because of Pico-8 constraints, there is only a set number of population and

attraction/repulsion strength available. However, these are already enough to

create fun simulations! </p>

<p><img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/picoworld_token1.png" />

<img alt="" src="https://alife-newsletter.github.io/Newsletter/images_edition_008/picoworld_token2.png" /></p>

<p>My goal for Picoworld is to encourage experimentation on this artificial life

system. If you discover interesting patterns, feel free to share a screenshot of

the configuration as a comment on the itch.io page! Lastly, I love working in

ALife and collective intelligence, so you can check out my other works!

[<a href="https://github.com/ljvmiranda921/pyswarms">1</a>]

[<a href="https://ljvmiranda921.github.io/sprites-as-a-service/">2</a>]</p>

<h1 id="sf-review-koichi-harukure-mortal-game">SF Review: Koichi Harukure "Mortal Game"</h1>

<p>A short story in <a href="https://www.amazon.co.jp/dp/B0B2HWFXDX">SF Magazine 2022/08</a></p>

<p><em>By <a href="http://twitter.com/vespid">Mitsuyoshi Yamazaki</a></em></p>

<p>The Search for Interstellar Life project has discovered an organic cellular automaton. The rules are deterministic, and calculations show that all "cells" will disappear in the near future.

Cellular automata are life-like if they are self-replicators that spontaneously reproduce from their environment, whereas a phenomenon whose behavior can be computed deterministically cannot be treated as life.

Should we leave the automaton untouched and let it "go extinct" in order not to disturb its natural environment, or should we "breed" it and modify the rules to foster long-period patterns?

The team's conclusion is…</p>

<p>This is the story of a human being's journey to an alien planet in search of an unknown phenomenon, the discovery of a phenomenon that fulfills that very purpose, and how humans deal with things that cannot be captured within the framework of existing science.

The spontaneous generation of an organic automaton is a plausible scenario, considering the spontaneous generation of life, and the life-like nature of such a quasi-life form is exactly what is being discussed in the artificial life field.</p>

<p>Can we call a phenomenon whose behavior can be deterministically determined life?<br />

If it is life, can we call an electronically simulated pattern of that phenomenon life?<br />

Would we not call life a being that survives by any means and resists its own destruction?  </p>

<p>But the focus of this story is not the alien cellular automaton, nor the discussion of its vitality, but the outpouring of human imagination and creativity towards the unknown.

The conclusion of introducing non-deterministic elements into a deterministic system is exactly one direction of artificial life production toward an Open-Ended system.</p>

<p>See for yourself how this story will end.</p>

<h1 id="era-board-update-202223">ERA Board Update 2022/23</h1>

<p><em>By <a href="http://twitter.com/imy_tk">Imy Khan</a></em></p>

<p>The nomination and voting process for the Emerging Researchers in ALife Board for the 2022/23 is currently taking place (at the time of writing - perhaps, by the time this newsletter is sent out, the results will have been finalised!). As always, there are six positions on the board: General Chair, Vice Chair, Communications Chair, Equity Chair, Conference Chair, and ISAL Representative. The results of the election will be posted on the <a href="https://join.slack.com/t/isalstudents/shared_invite/zt-1g7e8aex2-JKCdL53xOxs2dlRGG38R7A">ERA Slack</a> as well as the <a href="http://twitter.com/isalstudents">Twitter account</a>. We hope to welcome and introduce the new board in the next newsletter issue. For now, check out either the Slack or Twitter to find more details of the board and the chairs.</p>

<p>For now, if you are interested in becoming a member of the Emerging Researchers in ALife group, then all you need to do is <a href="https://join.slack.com/t/isalstudents/shared_invite/zt-1g7e8aex2-JKCdL53xOxs2dlRGG38R7A">join the Slack workspace</a>. There, we can keep you up-to-date with ERA-related events, and you will be able to nominate and vote in future board elections.</p>

<h1 id="post-doctoral-fellowship-opportunity-eutopia-sif-msca-cofund-deadline-dec-2022">Post-Doctoral Fellowship Opportunity: EUTOPIA-SIF (MSCA COFUND) (Deadline: Dec 2022)</h1>

<p>The <a href="https://eutopia-university.eu/english-version/research/sif-post-doctoral-fellowships">third call for the EUTOPIA Science and Innovation Fellowship</a> is now open until the middle of December. This is an exciting and innovative fellowship which allows young researchers to pursue their creative and innovative projects across several universities in the EUTOPIA University Alliance. </p>

<p><em>The EUTOPIA Science and Innovation Fellowship Programme has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement n. 945380, for a total number of 76 post-doctoral fellowships, over 4 years, and a budget of 10,2M€, of which 5,6M€ financed by the European Union and 4,6M€ by the EUTOPIA partner universities.</em></p>

<p><em>EUTOPIA-SIF post-doctoral fellows will be recruited by one of the six EUTOPIA universities which are part of the programme - Vrije Universiteit Brussel, CY Cergy Paris University, University of Gothenburg, University of Ljubljana, Pompeu Fabra University-Barcelona, The University of Warwick - (host university) on the basis of an individual research project and the quality of their academic profile for a 24-month post-doctoral contract with highly attractive conditions. The selected candidates from the 2022/23 call will start their positions in September 2023.</em></p>

<p><em>EUTOPIA-SIF fellowships offer the opportunity to high-profile young researchers to develop their own research projects in the stimulating academic environment of the EUTOPIA Alliance. Extensive research mobility is integral to the fellowships with two compulsory secondment periods: one at another EUTOPIA university (co-host university) and one with an external academic or non-academic partner institution with the aim of fostering the fellows’ entrepreneurial spirit, tangible research impact and innovation. Furthermore, fellows will access a rich training programme, career guidance and academic supervision.</em></p>

<p>The timelines for the call for applicants can be <a href="https://eutopia-university.eu/english-version/opportunities/research/eutopia-sif-third-call">found here</a>.</p>

<h1 id="upcoming-event">Upcoming Event:</h1>

<h2 id="japan-alife-workshop-5"><a href="https://alife-japan.org/archives/event/第5回人工生命研究会">Japan ALife Workshop #5</a></h2>

<p>November 23th 9:30am - 6:00pm (JST)<br />

onsite (registration is finished) and online (registration available until the day of the event) hybrid style.  </p>

<p>"General presentations are invited on a wide range of topics related to autonomy, evolution, consciousness, and other phenomena that characterize “life-like behavior.”"</p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 7th edition of the Alife Newsletter, August 2022</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_007.html</link>
  <guid>edition_007</guid>
  <pubDate>01 Aug 2022 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 7th issue of the ALife Newsletter. Last month we had the yearly meeting of the <a href="https://www.2022.alife.org/">International Society of Artificial Life (Alife 2022)</a>, which we hope was as inspiring for everyone as it was for our team.</p>

<p>We are terribly grateful and humbled by receiving the <strong>ISAL Exceptional Service Award</strong>. We would like to thank everyone who has made contributions to these Seven Editions, and everyone who has taken the time to read our collection of Artificial Life news and interesting projects. We hope to continue serving as a platform to amplify the voices of our community, and raise awareness of cool and inspiring projects to everyone.</p>

<p>Speaking about cool and inspiring projects, in this edition we highlight some great projects, including droplets, cultural simulations, speculative bio art, media reviews and more! We hope you enjoy it.</p>

<p>The Newsletter is distributed by email, and archived on the International Society for Artificial Life's website.</p>

<p>If you'd like to receive our e-mails, you can subscribe <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>.</p>

<p>Also, we encourage everyone to contribute to the next newsletter <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">here</a> (ETA October 2022)! In particular, we are specially interested in Master and PhD students who want to talk about their own research ideas. Do send us a line!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#complex-behavior-of-paraffin-droplets">Complex Behavior of Paraffin Droplets</a></li>

<li><a href="#project-introduction-tell-me-what-you-eat">Project Introduction: "Tell Me What You Eat"</a></li>

<li><a href="#astrovitae-the-speculative-biology-magazine">Astrovitae: The Speculative Biology Magazine</a></li>

<li><a href="#media-review-prehistoric-planet">Media Review: Prehistoric Planet</a></li>

<li><a href="#alife-conference-survey">ALIFE Conference Survey</a></li>

<li><a href="#alife-2022-student-abstract-essay-winner">ALIFE 2022 Student Abstract &amp; Essay Winner</a></li>

<li><a href="#book-review-cybernetics-or-control-and-communication-in-the-animal-and-the-machine">Book Review: Cybernetics (or, Control and Communication in the Animal and the Machine)</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="complex-behavior-of-paraffin-droplets">Complex Behavior of Paraffin Droplets</h1>

<p><em>By <a href="https://twitter.com/entosse">Richard Löffler</a></em></p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/7KEv9vUwQLk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<p><a href="https://www.youtube.com/watch?v=-aMw_64CfZ4&amp;list=PLy9lT30tFAXYG9_v3MzjHierF65Z6zGhj">Second Clip</a></p>

<p>In these clips, paraffin droplets containing different concentration combinations of camphor and the dye Oil red O were placed on a pure water surface. Droplets develop different behaviors such as tendrils, which form a maze-like space filling structure before splitting into smaller droplets that periodically move and trigger waves of activity or slowly morphing larger droplets. The behavior comes from the camphor in the droplet/s being deposited onto the water surface where it lowers the surface tension temporarily until it evaporates from the surface again, causing a marangoni convection in the bulk water phase that triggers a surface flow. Furthermore, the dye in the droplet lowers the interfacial tension between oil and water which enables the droplet to expand without splitting immediately.

For more on this: Richard's paper published this month: <a href="https://pubs.rsc.org/en/content/articlelanding/2022/cp/d2cp02456j">Complexity and bifurcations in the motion of a self-propelled rectangle confined in a circular water chamber</a>; ALife 2018 paper: <a href="https://direct.mit.edu/isal/proceedings/alife2018/30/574/99652">Better red than dead: On the influence of Oil Red O dye on complexity of evolution of a camphor-paraffin droplet on the water surface</a></p>

<h1 id="project-introduction-tell-me-what-you-eat">Project Introduction: "Tell Me What You Eat"</h1>

<p>By <a href="https://knivesandpaintbrushes.org/younes">Younès</a> / <a href="https://twitter.com/pyrofoux/">@pyrofoux</a></p>

<p><img alt="Actual Dish" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/tellmewhatyoueat_dish.jpg" /></p>

<blockquote>

<p>"Tell me what you eat, and I will tell you what you are."</p>

</blockquote>

<p>— <em>Jean-Anthelme Brillat-Savarin</em></p>

<p>If you want to understand a group of humans — where they live, how they speak, what they value, how they use their time or what they are proud of, a good place to start is with <strong>how they eat</strong>.</p>

<p>We'd like to place the deep bond between food and culture at the heart of an interactive experience: What can you learn from a group of people, based on what they eat?</p>

<h2 id="explore-a-world-through-its-cookbook"><em>Explore a world through its cookbook</em></h2>

<p><strong><em>Tell Me What You Eat</em></strong> is an in-development game where players are invited to discover human cultures living in a fictional world, using their cooking practices as a red thread. If I tell you how they prepare food, can you piece together their history, where they lived, how they spoke, what they loved?</p>

<p>We intend to make <strong><em>Tell Me What You Eat</em></strong> a sort of <em>generative detective</em> game: each time you replay it, the world you explore will be recreated anew. New landmaps, new plants, new populations, new historical events — that will in turn, influence the recipes of this world. You might want to cook one of these recipes yourself, or try to imagine with your friends which kind of world exist around them.</p>

<h2 id="prototypes-experiments">Prototypes &amp; Experiments</h2>

<p><img alt="Prototype Screenshot" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/tellmewhatyoueat_nagada.png" /></p>

<p>Our various prototypes and playful experiments are all available on the <a href="https://github.com/Pyrofoux/Tell-Me-What-You-Eat/">Github repo</a>.</p>

<p>The repository contains:</p>

<ul>

<li>a first rough prototype of generating a fictional world's cookbook;</li>

<li>a tentative at cooking a fictional recipe;</li>

<li>a simulation of how places get their names from the people they are traversed by;</li>

</ul>

<p><em>Editor's note</em>: Many Alife projects focus on the evolution of biology, agency, and intelligence. But another important aspect of living creatures is the culture they produce by their lived experiences!</p>

<h1 id="astrovitae-the-speculative-biology-magazine">Astrovitae: The Speculative Biology Magazine</h1>

<p>By <a href="https://twitter.com/domenicpennetta">Domenic V. Pennetta</a></p>

<p><img alt="Astrovitae Image 1" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/astrovitae_intro_1.jpg" /></p>

<p>Hello ALifers! I’m Domenic Pennetta, the founder and editor of <a href="https://www.astrovitae.com/">Astrovitae Magazine</a>—an online publication focused on popularizing the genre of fiction called <a href="https://en.wikipedia.org/wiki/Speculative_evolution">speculative biology</a> (specbio). Many of you have seen the first images taken by the <a href="https://webbtelescope.org/">James Webb Space Telescope</a>, which recently made headline news around the globe. Now humanity can gaze into the universe once more, but this time with more accuracy and clarity. Looking at the vastness of space—taking in all of the brightly-lit stars, nebulas, and funny shaped galaxies… brings up a nagging question: Where is all the life?</p>

<p>Specbio artists take this question to heart. The universe is, no doubt, full of life. We just haven't found it yet! And since alien life is most certainly out there, then what does it look like? Astrovitae’s mission is to gather up all these curious minds—all sharing the same goal of exploring what alien or alternate Earthly life could be—and put them in one place. This nexus of creatives fosters collaboration and a strong sense of community, while also providing many with thoughtful biology-inspired entertainment. With a slogan like “life as it could be'', I’m confident that many ALifers can sympathize with specbio artists and our search for a different form of life.</p>

<p><img alt="Astrovitae Image 2" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/astrovitae_intro_2.jpg" /></p>

<p><em>“Crested Snout Skimmer”, by <a href="https://www.instagram.com/pierce_adams_art">Pierce Adams</a>.</em></p>

<h2 id="what-is-astrovitae-magazine-all-about">What is Astrovitae Magazine All About?</h2>

<p>Astrovitae is a FREE, digital magazine focused on showcasing topics involving speculative biology, art, and science fiction. The magazine releases biannually, with a new issue planned to appear every April and September. The magazine is not peer reviewed, and there is no masthead or advisory board—the founder of the magazine is currently the only editor (who occasionally receives outside help from friends and other artists). The very first issue debuted in April of 2021 amid the global pandemic, and so far, there have been three published issues featuring a variety of artists and projects. Issue 4, which is now in the works, releases this coming September! New issues can be found on the magazine’s website: <a href="https://www.astrovitae.com">www.astrovitae.com</a>.</p>

<p><a href="https://www.astrovitae.com/issues.html">READ PAST ISSUES</a></p>

<h2 id="whats-inside-an-issue">What’s Inside an Issue?</h2>

<p>Inside a typical Astrovitae issue are three main categories:</p>

<ul>

<li><strong>Captivating Worlds</strong>: This is the primary content in Astrovitae where specbio artists showcase their unique world, biomes, and creature designs. <em>Captivating Worlds</em> contains the most detailed representation of a specbio project.</li>

<li><strong>Artist Spotlight</strong>: <em>Artist Spotlight</em> is typically less refined—focusing on the "behind the scenes" of a speculative project. Creators have an opportunity to speak about their creative process, inspirations, and can also show off sketches and unfinished art.</li>

<li><strong>Creature Compendium</strong>: This section is exactly what it sounds like—it's a collection of various creatures by participating artists! These organisms are often accompanied by a brief description that gives the reader a small snippet into another speculative world.</li>

</ul>

<p><img alt="Astrovitae Image 3" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/astrovitae_intro_3.jpg" /></p>

<p><em>“A Variety of Enetodontians”, by <a href="https://www.deviantart.com/blackfrog96">Lorenzo Battilani</a>.</em></p>

<p>There are also other segments included in Astrovitae, such as Spec News—a section that updates readers on some of the going-on’s in the community, like newly announced specbio projects, youtube content, video game releases, and science news associated with astrobiology, paleontology, and other fields.</p>

<p>Astrovitae occasionally features larger creators in interviews, such as <a href="https://twitter.com/JayRock5858">Jay Eaton</a>, one of the founder’s of the specbio zine called Almost Real, and the popular Youtuber <a href="https://www.youtube.com/c/curiousarchive">Curious Archive</a>. Some other notable people in the genre may be interviewed in the future, like the vertebrate paleontologist Darren Naish, artists C.M. Kosemen and Wayne Barlowe, and maybe one day the father of speculative biology himself, Dougal Dixon.</p>

<p><img alt="Astrovitae Image 4" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/astrovitae_intro_4.jpg" /></p>

<p><em>“Anatomy of a Spadecrab”, by <a href="https://www.deviantart.com/pesterjelly">Hunter Welch</a>.</em></p>

<p><strong>How Can ALifers Submit to Astrovitae?</strong></p>

<p>Any ALifer interested in speculative biology may send a submission! Creating submissions does not require an art or science degree, nor do you have to be a professional artist to submit work. However, Astrovitae does prefer submissions that include artistic visuals to engage its readers—so if you’re just an author-type, then it might be best to hold off on a submission unless you’d like to collaborate with artists. One of Astrovitae’s missions is to foster collaboration among creators, so working with other individuals in the community is highly encouraged!</p>

<p>If you’re interested in sending a submission to Astrovitae, then visit <a href="https://www.astrovitae.com/submissions">www.astrovitae.com/submissions</a> to see the magazine’s official guidelines and additional information, like deadlines, word counts, image requirements, and more. Contributors are encouraged to read past issues to see what type of content is typically accepted. Send submissions to <a href="mailto:astrovitaeofficial@gmail.com">astrovitaeofficial@gmail.com</a> with the subject line “ASTROVITAE SUBMISSION'' followed by your project’s or article’s name.</p>

<p><img alt="Astrovitae Image 5" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/astrovitae_intro_5.jpg" /></p>

<p><em>“The Tokabi”, by <a href="https://www.instagram.com/art_of_maryana_s">Maryana Simpson</a>.</em></p>

<h2 id="how-can-i-support-the-magazine">How Can I Support the Magazine?</h2>

<p>There are a few ways to support Astrovitae:</p>

<ul>

<li>Spread the news! Word of mouth is the best form of marketing, so tell your friends, family, and peers about the magazine!</li>

<li>Participate by creating your own submission! And don’t hesitate to encourage others to submit work of their own!</li>

<li>Like, comment, and share <a href="https://www.instagram.com/astrovitae_official">Astrovitae’s Instagram posts</a>.</li>

<li>Donate to <a href="https://ko-fi.com/astrovitae">Astrovitae’s Kofi</a> to support the editor’s efforts to popularize the genre and contributing artists!</li>

</ul>

<p>Regarding donations, Astrovitae is not sponsored and currently makes no revenue from ads or sales. The magazine is absolutely FREE to read in its current state. Donations go a long way to help facilitate the production and marketing of an issue. You can donate a meager $3 (USD) or more to help support the magazine’s mission to showcase specbio artists in the community. If you're interested in donating, visit <a href="https://ko-fi.com/astrovitae">Astrovitae's Kofi</a> to send a donation. Make sure to leave a comment about your favorite artist or project featured in the magazine!</p>

<h1 id="media-review-prehistoric-planet">Media Review: Prehistoric Planet</h1>

<p>By <a href="https://linktr.ee/albertonykus">Albert Chen</a></p>

<p><img alt="Prehistoric Planet" src="https://alife-newsletter.github.io/Newsletter/images_edition_007/dino.jpg" /></p>

<p><em>The following is modified from a <a href="https://albertonykus.blogspot.com/2022/06/prehistoric-planet.html">longer review</a>.</em>

<em>Prehistoric Planet</em>, a new documentary series now available for streaming on Apple TV+, has caused quite the stir in the online paleontology community. With its focus on reconstructing extinct life in ancient environments, this show inevitably invites comparisons to <em>Walking with Dinosaurs</em> (1999), but it borrows more from recent documentaries that focus on the modern biosphere, such as <em>Planet Earth</em> (2006) and its sequels. For example, each episode of <em>Prehistoric Planet</em> comprises several vignettes that take place in multiple locations, instead of revolving around a narrative about one specific ecosystem. In addition, the segments in <em>Prehistoric Planet</em> are all set within the Maastrichtian Age of the Late Cretaceous Epoch (spanning 72.1–66 million years ago, shortly before the mass extinction event that would end it all), not spread across the entire Age of Dinosaurs.</p>

<p>Most responses to <em>Prehistoric Planet</em> have been overwhelmingly positive, and the acclaim is well deserved. The series features spectacular visual effects as well as naturalistic, scientifically plausible depictions of extinct animals. An excellent example is the adorable portrayal of the small, feathered <em>Mononykus</em>, which appears in the second episode (“Deserts”) and is arguably one of the breakout stars of the series, with even executive producers <a href="https://www.youtube.com/watch?v=l8xyqhuz3Wg&amp;t=1257s">Jon Favreau</a> and <a href="https://www.youtube.com/watch?v=MbNZhVM8ICw&amp;t=163s">Mike Gunton</a> identifying it as one of their favorite dinosaurs that they featured. This dinosaur belongs to a group called the <a href="https://en.wikipedia.org/wiki/Alvarezsauridae">alvarezsaurids</a>, characterized by their slender skulls, long legs, and most unusually of all, incredibly short but powerful arms that each end in an enlarged thumb claw. In <em>Prehistoric Planet, Mononykus</em> is shown <a href="https://www.biotaxa.org/Zootaxa/article/view/zootaxa.2413.1.1/0">traveling for long distances while foraging</a>, <a href="https://www.science.org/doi/10.1126/science.abe7941">detecting prey with its sensitive hearing</a>, and using its specialized thumb claw to <a href="https://www.cambridge.org/core/journals/paleobiology/article/abs/function-in-the-stunted-forelimbs-of-mononykus-olecranus-theropoda-a-dinosaurian-anteater/6823FD1CA0FDE6F376621C52A014BF1A">dig for termites</a> in <a href="https://www.sciencedirect.com/science/article/pii/S0195667108000943">dead wood</a>, all of which are behaviors that have been suggested for alvarezsaurids based on studies of their functional anatomy and ecology.</p>

<p>If I had any notable criticisms of <em>Prehistoric Planet</em>, it would be the fact that this extensive scientific background is probably not apparent to viewers unfamiliar with dinosaur paleontology, as the show generally does not clarify which elements are speculation and which are backed by direct evidence. Each episode does have an accompanying 5-minute “Uncovered” video that delves into some of the science behind the series, but each of these segments focuses only on a single narrow topic, leaving the majority of what is shown in the episodes unaddressed. If anything, a lack of transparency does a disservice to the tremendous amount of thought and research that clearly went into this show.</p>

<p>This point of concern, however, does not undermine the excellence that <em>Prehistoric Planet</em> has achieved. The series is outstanding in nearly every way possible, setting a new and extremely high standard for works of this genre. Given the positive reception so far, I feel hopeful that we will eventually see future seasons of <em>Prehistoric Planet</em> and, with luck, maybe even a whole new age of paleontology-inspired media.</p>

<h1 id="alife-conference-survey">ALIFE Conference Survey</h1>

<p>by Anya Vostinar, ISAL Diversity Chair</p>

<p>Hello ISAL Members! We’ve just wrapped up a successful ALIFE 2022 and the ISAL board would like to get some feedback from you all on two specific aspects of conference organization, double-blind reviewing and extended abstracts, as well as any other comments or suggestions that you have.</p>

<p><a href="https://forms.gle/sfhdu1xfJPRptsbo7">Please complete the survey at this link by September 6th.</a></p>

<p>Thank you for all of your involvement in our ALife community!</p>

<h1 id="alife-2022-student-abstract-essay-winner">ALIFE 2022 Student Abstract &amp; Essay Winner</h1>

<p>by <a href="https://twitter.com/PigozziFederico">Federico Pigozzi</a></p>

<p>Large Language Models (LLMs) (Devlin et al., 2018) have propelled breakthroughs in sequence modeling by pre-training on large web corpora, to the point of seemingly incorporating “universal” knowledge (Lu et al., 2021). But, to what extent is such knowledge universal remains an open question. In other words, do LLMs ground knowledge that is so universal to solve far-fetched downstream tasks?

Most notably, Reinforcement Learning (RL) agents lag behind the computational abilities of animals and they might benefit from the common sense embedded in LLMs as if those were world models (Ha and Schmidhuber, 2018).

In particular, we wonder whether LLMs can be used as off-the-shelf reservoirs for RL tasks by simply optimizing a readout function on top of them.

Proving that LLMs ground knowledge that is so universal to solve RL tasks would be a relevant discovery. As a consequence, being the LLM reservoir frozen, we can solve tasks by optimizing much fewer parameters than usual.</p>

<p><strong>View the full submission and the other Student Abstract and Essay submissions <a href="https://www.2022.alife.org/_files/ugd/534077_2d1b5f057cae4d8abdedf7774aec177d.pdf">here</a>.</strong></p>

<h1 id="book-review-cybernetics-or-control-and-communication-in-the-animal-and-the-machine">Book Review: Cybernetics (or, Control and Communication in the Animal and the Machine)</h1>

<p><strong>by <a href="http://twitter.com/imy_tk">Imy Khan</a></strong></p>

<p>This book has been on my reading list for some time, and I had hoped that volunteering a review back in December would force my hand into reading it. Alas, carving out the time for it was tricker than I had hoped, and while I’m still not through it (I’m writing this review only six chapters in), I wanted to contribute this short piece in the hope that it might inspire others to pick up and read this, quite frankly, fascinating and insightful book.</p>

<p>A quick primer on cybernetics (though I’m sure many of us may be familiar with the term). Cybernetics is a field which concerns itself with regulatory, self-governing systems, attempting to provide a theoretical framework for the regulatory mechanisms and feedback loops that drive system stability or auto/self-regulation. While these systems were originally described from a biological perspective (partially, at least, since Wiener takes the position that the biological “brain” is the primary controller of regulation), the cybernetics principles can be (and have been) applied to systems across numerous scales and fields. These include biology, neuroscience, sociology, engineering, economics, robotics, and artificial intelligence. Closer to the field of ALife, cybernetics has also inspired biologically-relevant theories of self-regulation, such as autopoiesis, enactivism, and viable systems models. Cybernetics as a field, then, is both wide-reaching and cross-disciplinary and has found both theoretical and practical applications across many domains. It is fascinating to think that this is an approach that was developed over 70 years ago, and one that is continually finding relevance in our work.</p>

<p>My reasons for reading this book are simple: the work that I have done (by proxy of the lab where I completed my PhD) has been inspired by cybernetics (as well as other fields). After several years of using, citing, and, at times, defending this approach, I decided that it was only fitting to go back and read some of the original literature on the area. </p>

<p>To start, I have to say that this book is very dense. After a couple of introductory chapters, the book becomes quite heavy on mathematics very quickly - at times, there are several pages of mathematical equations all at once - but Weiner does an excellent job of narrating, commenting, and making analogies for the points he is putting forth. The mathematics is not unnecessarily verbose. On the contrary, Weiner is attempting (and, as it turns out, successful in doing so) to argue for a new perspective on communication (or information) theory as it relates both to animals and machines, drawing parallels between both. The explicit mathematical definitions, therefore, are used to strengthen this position. </p>

<p>I had to constantly remind myself that this book (well, the first edition of this book) was written in 1948, as some of the points that Weiner describes were incredibly forward-thinking and almost predictive of what would unfold in the fields of artificial intelligence, computer vision, and neuroscience. For instance, in the chapter, “Gestalt and Universals”, Weiner discusses how we (animals) can identify and recognise objects using generalisable features While this chapter is light on the mathematical formalisms of these mechanisms, Weiner’s discussions of the (theoretical) mechanisms responsible for this generalisation have perhaps found a home in the field of computer vision. In another instance, in one of the supplementary chapters (published in 1961, that I had a brief read of), Weiner also discusses the potential dangers of machine automation and self-reproducing machines. I don’t want to spoil the contents of the book too much, but his views and seemingly-accurate predictions of some of the social and political problems that may arise from self-replicating machines is, in itself, reason to read this book.</p>

<p>One of my favourite chapters (so far) is the chapter on “Computing Machines and the Nervous System.” Weiner speaks of the “affective tone”, with descriptors of “pleasure” and “pain”, and how they can affect other processes responsible for self-organisation. He also talks about how all of these different affective tones are themselves regulated by an “affective tone totalizer”, and also describes how this plays out in biological systems (through hormonal modulation of the nervous system). What Weiner describes here is the role of “emotional regulation” in biological self-regulatory systems, which I, personally, found to be an interesting perspective. Juxtaposed against the theme of the rest of this book, which emphasises the machine-like processes of inputs, outputs, feedback loops and regulatory systems, the description of a very animalistic quality---emotion---as both a regulator and, itself, regulated, was surprising. To me, this highlighted that Weiner cared just as much about the processes associated with the “animal” as he did the “machine”: a refreshing take in an era where strictly-computational approaches (such as those by von Neumann and Turing) were gaining prominence.</p>

<p>I briefly read some other reviews of this book before I wrote this review, and have seen people call its contents “disorganised” or “disjointed”. I certainly understand these points, but I respectfully disagree. As I mentioned above, Weiner is simultaneously attempting to define this new field of cybernetics, describe its potential applications across numerous domains, while also not shying away from his own opinions on certain matters. At least in my reading of this book, I get the sense that this was written by an incredible individual who is attempting to communicate their groundbreaking work to as many disciplines as possible. As we might all appreciate, interdisciplinary communication is hard work, and I do not hold that against Weiner or this book.</p>

<p>Overall, whether or not your research is directly related to cybernetics or its tangential principles, I would highly recommend that this book finds its way onto your respective bookshelves. Oftentimes, I found that even reading a few pages would spark an idea or two in my head, giving me a wider appreciation of how we can think of (almost) everything in terms of feedback loops and self-organising systems. Others have called this book worthy of reading as a historical document if nothing else. I am inclined to agree. It is not a casual read by any means, but one that I wish I had read years ago. Some of the ideas and theories may have been better refined in the 70 years since its publication, but it is clear to see how this book and his later works were crucial in laying the groundwork for many theories and applications that we take for granted in our own research nowadays.</p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 6th edition of the Alife Newsletter, June 2022</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_006.html</link>
  <guid>edition_006</guid>
  <pubDate>01 Jun 2022 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 6th issue of the ALife Newsletter. Summer is here in the North hemisphere and we are all being boiled alive, but hopefully this fresh newsletter will help cooling you down!</p>

<p>This edition has several paper reviews, a course review, and two workshop summaries! If you attended an ALife event recently, let us know.</p>

<p>The Newsletter is distributed by email, and archived on the International Society for Artificial Life's website.</p>

<p>You can subscribe <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>.</p>

<p>Contribute to any section of the next newsletter <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">here</a>! We are specially interested in Master and PhD students who want to talk about their own research.</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#review-of-the-agent-learning-in-open-endedness-workshop">Review of the Agent Learning in Open-Endedness Workshop</a></li>

<li><a href="#artificial-life-reading-list">Artificial Life Reading List</a></li>

<li><a href="#running-a-life-simulation-for-60-hours">Running a Life Simulation for 60 hours!</a></li>

<li><a href="#course-review-origins-of-life-by-complexity-explorer-santa-fe-institute">Course Review: Origins of Life (by Complexity Explorer - Santa Fe Institute)</a></li>

<li><a href="#alife-paper-review">ALife Paper Review</a></li>

<li><a href="#summary-of-asymptotic-burnout-and-homeostatic-awakening-a-possible-solution-to-the-fermi-paradox">Summary of "Asymptotic burnout and homeostatic awakening: a possible solution to the Fermi paradox?"</a></li>

<li><a href="#bringing-physics-to-life-an-ideas-lab-from-the-templeton-foundation">Bringing Physics to Life, an Ideas Lab from the Templeton Foundation</a></li>

<li><a href="#upcoming-deadlines">Upcoming Deadlines:</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="review-of-the-agent-learning-in-open-endedness-workshop">Review of the Agent Learning in Open-Endedness Workshop</h1>

<p><em>By <a href="https://twitter.com/kvfrans">Kevin Frans</a></em></p>

<p>Open-endedness is the idea of a system that "endlessly creates increasingly interesting designs". That's a simple concept with big implications, especially for those of us interested in AI and the emergence of intelligence. Because even with powerful learning algorithms, intelligence is one of those tricky things that's hard and complicated to specify. But that's the beauty of open-ended systems: they can generate unexpected designs, designs that go beyond the intention of the designer. And so even if intelligence is hard to create, it might be possible to create a system where intelligence naturally emerges. This weekend, a bunch of us thinking about how open-endedness can boost AI gathered at the Agent Learning in Open-Endedness (ALOE) workshop at ICLR.</p>

<p>Many projects were presented, mainly centering around the question of "how can we generate training tasks that are rich, learnable, yet increasingly complex?". XLand aims to create an open-ended set of tasks by 1) defining a distribution of games, and 2) making them all multi-agent. The key lesson is that XLand tasks are so varied and dense that agents have no choice but to generalize. Sam Earle presented work on procedural content generation, showing that AI models could be used as level generators, resulting in a competitive game between AI players and AI designers. PAIRED, presented by Natasha Jaques, examines the game theory of this framework, and shows that a strong training curriculum can arise from a game between a designer, an antagonist, and a protagonist. The designer tries to propose tasks which the antagonist can solve, but the protagonist cannot, a metric which empirically corresponds to tasks just on the learning boundary. Finally, Julius Togelius argued that our classic framework of "agents interacting with an environment" is too limiting, and we should explore new ground.</p>

<p>For more detailed notes, check out the <a href="https://kvfrans.com/notes-on-aloe/">full blog post</a></p>

<h1 id="artificial-life-reading-list">Artificial Life Reading List</h1>

<p>By <a href="https://anyaevostinar.github.io/">Anya E Vostinar</a></p>

<p>This is a reading list of sci-fi books (and a few tv shows/movies) that explore humanistic alife topics for a college-level reading-intensive course. Questions include 'What makes an individual?', 'What makes us human?', and 'Are androids human?'</p>

<p><a href="https://anyaevostinar.github.io/teaching/2022/06/17/alife-reading.html">Artificial Life Reading List</a></p>

<h1 id="running-a-life-simulation-for-60-hours">Running a Life Simulation for 60 hours!</h1>

<p><em>by <a href="https://scholar.social/@caranha">Claus Aranha</a></em></p>

<p>Remember <a href="https://leocaussan.itch.io/the-bibites">The Bibites</a>, a life simulation that we introduced back in <a href="https://alife-newsletter.github.io/Newsletter/edition_004.html#alife-project-the-bibites">Edition 04</a>?</p>

<p>A few weeks ago the simulator received an uppdate, so I decided to let a simulation run in my work computer for the week. It was very nice to check on how my bibites had evolved during my work breaks.</p>

<p><img alt="30 hours of bibites" src="https://alife-newsletter.github.io/Newsletter/images_edition_006/30h_bibites.jpg" /></p>

<p><em>the simulation at around 30 hours</em></p>

<p>Because there was no physical separation in the environment where the digital creatures lived, the population quickly converged. However, evolution continued, and it was very interesting to guess when a new mutation would take hold of the population (such as the ability to avoid other bibites), or be lost to genetic drift (such as the expression of colorful pheromones).</p>

<p>By the way, the author of the simulation recently released a similar video, where he follows 100 hours of simulation and prepares a simple phylogenetic tree of the species that came up. He also promised better tools to visualize the simulation, so look forward to that!</p>

<ul>

<li><a href="https://youtu.be/sEPh6bAQVP0">The result of 100 hours of simulation (Part I)</a></li>

<li><a href="https://youtu.be/xBQ3knSi0Uo">The result of 100 hours of simulation (Part II)</a></li>

</ul>

<h1 id="course-review-origins-of-life-by-complexity-explorer-santa-fe-institute">Course Review: Origins of Life (by Complexity Explorer - Santa Fe Institute)</h1>

<p><em>By <a href="http://twitter.com/imy_tk">Imy Khan</a></em></p>

<p>For a couple of years now, I have sought to improve my understanding of the fields of origins of life and astrobiology, as well as refresh (and/or improve) my working knowledge of physics and chemistry as they relate to living systems. This desire was both a personal one (I think origins of life and astrobiology as research areas are just cool) as well as “professional”, given the overlap between those fields and Artificial Life. </p>

<p>Many readers may agree when I say that diving into and (attempting to) teach yourself new areas can be a daunting and overwhelming endeavour. When it comes to learning about new areas and disciplines (often outside our areas of expertise), knowing where to start or what the foundations of the field are, and then to source the “best” material to learn the new concepts and theory, is a task that perhaps leads many people to either give up their attempts to learn altogether (or, alternatively, creates gaps in their foundational knowledge that need to be filled in later on). Herein lies the value of structured courses, in my humble opinion, where these problems are solved by experts in the area of interest. So, I was quite excited when I found that Complexity Explorer (Santa Fe Institute) was running an Origins of Life online course which started in June 2022. It was even nicer knowing that the course was free of charge (which, to the best of my knowledge, is true of all Complexity Explorer courses).</p>

<p>I chose to write this short review of this course for the ALife community, as I suspect I may not be the only person who may be interested in better understanding OoL/astrobiology or some of the related disciplines. In fact, studying “origins of life” isn’t strictly correct. Rather, what we are doing (I think) is learning about concepts and principles from other disciplines - including the earth sciences, biology, chemistry, and physics - as they relate to the emergence of the properties of what we call “life”, and then to question, explore, and try to figure out what the minimal (biological, chemical and physical) conditions might be in order for “life” to emerge. Or, what “life” would look like if those properties or parameters were different. That second point might make the tie-in to ALife a little clearer…! (There may be more to it, but so far, these are the things that have me interested in OoL research.)</p>

<p>I have been apprehensive about committing to online courses in the past, particularly as so many currently exist that it’s sometimes difficult to separate the good from the…less-good. But since Complexity Explorer/SFI have a reputation for delivering high-quality courses, I decided to take the plunge and commit to the course for the entire duration (11 weeks). Despite the fact that I have no formal background and very limited exposure to anything related to OoL/astrobiology, I have found this course to be a very accessible entry point into this field of research. The course instructors (Prof. Chris Kempes (SFI), Prof. Sarah Maurer (CCSU), and instructor Maria Kalambokidis (UMN)) have done an excellent job of putting together a well-thought-out roadmap of content in both the weekly topics (each week’s subtopics are carefully crafted and structured to build on top of each other) as well as throughout the course itself. Lectures have, so far, been easily digestible, well-presented, coherent and succinct (the length of each lecture is anywhere between 8-25ish minutes each). The instructors have also been thoughtful enough to provide a comprehensive list of references and supplementary material related to each week’s topics, addressing the previously-described problem of not knowing where to start when it comes to finding information on new topics. Crucially, the course has no prerequisites, though they do mention that it may be useful to have some background knowledge of algebra, introductory chemistry and biology. Though I have little knowledge of chemistry, I have not been overwhelmed by the chemistry-heavy units so far, but rather, found them fascinating and insightful. Perhaps this is indicative of how thoughtful and meticulous the instructors have been in choosing how to collate and present the information.</p>

<p>In terms of time commitments, I have been able to watch all the lectures, read the material, and make study notes accordingly within 3-4 hours per week. This is a fair commitment, in my view and like with any course, I suspect you will get out what you put in. If you are interested in learning about (or improving your basic knowledge about) OoL concepts and theories, but don’t know where to start, then this course gets my recommendation. There are (optional) assessments and quizzes to test comprehension, with a certificate of completion if you meet a certain mark threshold, but the course can also be completed without submitting any of those. Nevertheless, if you can carve out some time (3-4hrs per week) to commit to it, I think it will reward you accordingly. At the time of writing, I am on week 3 of 11 (this week’s topic is “Chemical Commonalities” which, amongst other things, will discuss some of the common chemical properties across different living systems, DNA as information, and chemical configurations) and I fully intend on continuing this momentum for the entire course. </p>

<p>Overall, this course is playing its role as an introductory course brilliantly, giving me a stronger understanding and appreciation of some of the core concepts and principles of the field. As a result, I suspect this will become a jumping-off point for me to be able to confidently dive into OoL research in the future with a more informed perspective.</p>

<h1 id="alife-paper-review">ALife Paper Review</h1>

<p><strong>"Evolutionary transition from a single RNA replicator to a multiple replicator network"</strong></p>

<p>by <a href="https://twitter.com/vespid">Mituyoshi Yamazaki</a></p>

<p>This research is an attempt to realize a host-parasite coevolution model aiming at Open-Ended Evolution.

<em><a href="https://webpark2056.sakura.ne.jp/papers/2022_Mizuuchi.pdf">https://webpark2056.sakura.ne.jp/papers/2022_Mizuuchi.pdf</a></em></p>

<h2 id="research-content">Research Content</h2>

<p>The following two conditions are necessary for evolution:</p>

<ul>

<li>Self-replication ability</li>

<li>Inheritance of changes in replication ability</li>

</ul>

<p>How to build a simple model that meets these conditions?</p>

<h3 id="previous-research">Previous Research</h3>

<p>In Spiegelmann's previous study, self-replicating RNA was evolved by feeding it raw material and an RNA-replicating enzyme to replicate it, and repeating the same procedure for the next generation. As a result, RNA converged on the shortest gene that has a trait with high replication efficiency. </p>

<p><em>Cause of convergence:</em>

- The selection pressure of RNA did not change because only RNA was passed in each procedure and the same type of RNA replication enzyme was added.

- The information encoded by RNA was meaningless (the genetic information encoding the protein was included but not used for replication procedure)

    - The susceptibility to replication depended only on the physical properties of RNA and the replication enzyme.</p>

<h3 id="research-by-professor-ichihashi">Research by Professor Ichihashi</h3>

<p>In this paper, Professor Ichihashi continues the previous work by introducing a cell-free protein synthesis, and implementing a model in which RNA makes an RNA-replicating enzyme and the replicating enzyme makes RNA. RNA mutations also affect replication enzymes, avoiding convergence by changing the selection pressure of the system.</p>

<p>Along with that change, they introduced a cellular structure. (In order to prevent the generated RNA-replicating enzyme from drifting somewhere, the cell structure pre-encloses RNA and the necessary nutrients. If it drifts, the tragedy of the commons arises).</p>

<p>As a result of conducting experiments on such a system, the introduction of a cell-free protein synthesis system was not enough, and it converged and stopped evolving.</p>

<p>At this point, the parasite had already developed, but it was suppressed to not inhibit the host's self-renewal. After removing the repression and subculturing for a while, co-evolution began with the RNA of the host and the RNA of the parasite, and new parasites were born.</p>

<h3 id="specifications-of-the-system-that-produces-parasites">Specifications of the system that produces parasites</h3>

<p>There is room for parasites to occur in this system (parasites seem to almost always appear) because there are vulnerabilities in the replication process that can be used by others. In this system, RNA does not replicate by itself, but has a structure that allows an RNA replication enzyme to replicate itself. RNA with a sequence ★ recognized by the replication enzyme as the replication target is replicated. The parasite is RNA of sequence ★ that lacks a gene that encodes a replicating enzyme, and because of this missing gene, the parasite's sequence is shorter and therefore it has a faster replication rate than that of the host RNA.</p>

<h2 id="impressions">Impressions</h2>

<h3 id="specifications-of-the-system-that-produces-parasites_1">Specifications of the system that produces parasites</h3>

<p>This does not depend on the specific implementation target, so it can be installed in any kind of system including software simulators. In particular, Professor Ikegami's Machines and Tapes system seems to be easy to embed because the model structure is similar.</p>

<h3 id="multi-phased-self-replication-process">Multi-phased self-replication process</h3>

<p>The multi-phased process automatically removes the difficulty of self-referencing.</p>

<h3 id="explanation-that-evolved-from-rna-world-to-single-cell">Explanation that evolved from RNA world to single cell</h3>

<p>This research / experiment is, as it is, an explanation of how the RNA world has evolved into a single cell.</p>

<p>Since RNA needs a cellular structure to make and retain a replicating enzyme, it becomes a prerequisite for self-renewal. From that starting point, it already is the simplest form of a cell and easily developed into a fully functional ancestral cell.</p>

<h1 id="summary-of-asymptotic-burnout-and-homeostatic-awakening-a-possible-solution-to-the-fermi-paradox">Summary of "Asymptotic burnout and homeostatic awakening: a possible solution to the Fermi paradox?"</h1>

<p><em>By the authors, Michael L. Wong and Stuart Bartlett</em></p>

<p>In this paper, we explore the potential connections between the emergence of cities and globally connected technological civilizations and the Fermi Paradox. With this perspective, we explore the hypothesis that planetary civilizations may inevitably face a self-induced catastrophe that we call “asymptotic burnout” caused by their underlying social dynamics that drive the superlinear scaling of key metrics, including total energy consumption. Civilizations that develop the capability to understand their own trajectory will have a window of time to affect a fundamental change to prioritize long-term homeostasis over unyielding growth, avoiding burnout via a consciously induced trajectory change that we call “homeostatic awakening.” We propose that the longstanding Fermi paradox may be explained by the inevitability of civilizations to either collapse from burnout or redirect themselves to prioritizing homeostasis, a state where cosmic expansion is no longer a goal, making them difficult to detect remotely.</p>

<p>For more details, check out the paper at <a href="https://royalsocietypublishing.org/doi/10.1098/rsif.2022.0029">https://royalsocietypublishing.org/doi/10.1098/rsif.2022.0029</a></p>

<h1 id="bringing-physics-to-life-an-ideas-lab-from-the-templeton-foundation">Bringing Physics to Life, an Ideas Lab from the Templeton Foundation</h1>

<p><em>by Lana Sinapayen</em></p>

<p>This event held in Czech Republic brought together early career scientists from 3 big fields: Artificial Life, Biological Chemistry, and Nonequilibrium Physics.

It was an intense workshop where we had one week to write several grants to apply for up to $5 million in total funding to tackle a research question related to Origins of Life research. Thankfully, the event was highly structured along a tried and tested schedule that saw us generate dozen of ideas individually or in teams, and gradually select the most promising to develop them through several cycles of writing and presentation. 

Without giving away any details, the topics broadly ranged from planetary science to information theory, alternatives to the RNA-world hypothesis, and new definitions of life.

It was exhausting but rewarding. I left having expanded my network of colleagues through true collaborative work rather than simple conference-style chitchat, and with many new ideas to advance my own research. 

The organization was top notch, the discussions between different fields both difficult and enriching. I would highly encourage anyone to apply to relevant "Ideas Lab" if they have a chance.</p>

<h1 id="upcoming-deadlines">Upcoming Deadlines:</h1>

<ul>

<li>Simulation of Adaptive Behaviour (SAB i.e. ANIMATS) - September 2022</li>

<li>European Simulation &amp; Modelling Conference (ESM, Oct 2022)</li>

<li><a href="https://iros2022.org/">IROS 2022</a> (October 23–27)</li>

</ul>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 5th edition of the Alife Newsletter, April 2022</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_005.html</link>
  <guid>edition_005</guid>
  <pubDate>01 Apr 2022 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>Welcome to the 5th issue of the ALife Newsletter. We have been gaining some momentum over the last few issues, and we are glad to see so many of you enjoying and contributing to this newsletter!</p>

<p>This edition is packed full of great content - from media and conference reviews, news from some recent competitions, and some more information about our upcoming podcast. Be sure to check it all out and let us know what you think.</p>

<p>The Newsletter is distributed by email, and archived on the International Society for Artificial Life's website.</p>

<p>You can subscribe <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>.</p>

<p>Contribute to any section of the next newsletter <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">here</a>!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#alife-art-project-alien">Alife Art: Project ALIEN</a></li>

<li><a href="#project-highlight-fingerpainting-fitness-landscapes">Project Highlight: Fingerpainting Fitness Landscapes</a></li>

<li><a href="#project-highlight-mfmrocks">Project Highlight: MFM.rocks</a></li>

<li><a href="#competition-highlight-evocraft">Competition Highlight: Evocraft</a></li>

<li><a href="#media-review-picture-a-scientist-documentary">Media Review: "Picture A Scientist" documentary</a></li>

<li><a href="#conference-review-acmieee-hri-human-robot-interaction-conference-2022">Conference Review: ACM/IEEE HRI (Human-Robot Interaction) Conference 2022</a></li>

<li><a href="#results-of-the-fiction-science-contest">Results of the Fiction Science Contest</a></li>

<li><a href="#upcoming-deadlines">Upcoming Deadlines:</a></li>

<li><a href="#alife-community-podcast-call-for-questions">ALife Community Podcast: Call for Questions</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="alife-art-project-alien">Alife Art: Project ALIEN</h1>

<p><em>Contributed by Christian Heinemann</em></p>

<p><a href="https://alien-project.org">ALIEN</a> is an open-source artificial life project which aims to bring together particle-based simulations for soft bodies with a programming model for distributed systems. In this context, agents are networks of connected particles, where the nodes possess capabilities that could be attributed to robotic or biological components: sensors, muscles, computational units and much more. The communication inside a particle network is performed by signals consisting of stateful and transient entities. They facilitate more complex behavior patterns such as food seeking, self-replication, controlled movements, attacking and digestion of resources, swarming behavior, etc. to be implemented in the networks. The simulator comes along with various examples ranging from pure mechanical to evolution simulations to play with. Own particle machines can be constructed with the built-in graph editing and programming environment. For instance, a self-replicating machine provided with enough resources could work as follows:</p>

<p><img alt="Self Replication" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/alien_selfreplication.png" /></p>

<p>From left to right: a possible replication cycle of a particle machine The replication process for this machine takes place in such a way that, starting from a center node, its own network structure is scanned and reconstructed in a spiral sequence. By injecting such a machine equipped with a functioning metabolism into a pristine world exposed to mutations, evolution simulations can be conducted. If desired, the user of the program can merely act as an observer and adjust some simulation parameters from time to time.</p>

<p><img alt="User Interface" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/alien_ui.png" /></p>

<p>The color of a particle has become more importance in recent updates. There are several color flavors available, and they can play a crucial role in the sensoring and digesting functions depending on the simulation setting. In this long-term diagram taken from the built-in simulation monitor, for instance, one can see how populations of replicators with different colors have gained the predominance at different time epochs.</p>

<p><img alt="Statistics" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/alien_statistics.png" /></p>

<p>An objective of this project is to encourage experimentation with worlds full of wonders that keep surprising the observers. ALIEN is powered by an own physics and rendering engine written in CUDA and thus requires an Nvidia graphics card.</p>

<h1 id="project-highlight-fingerpainting-fitness-landscapes">Project Highlight: Fingerpainting Fitness Landscapes</h1>

<p><em>Contributed by <a href="https://twitter.com/LuisZaman">Luis Zaman</a>, <a href="https://twitter.com/LuisZaman/status/1495251969094602755?t=vWoC0E0_AcBRkNYh3IgnRA&amp;s=19">Original Twitter Thread</a></em></p>

<p>While I was a graduate student, I had a bit of fun one weekend and made a touch screen simulation to play with fitness landscapes. @RELenski, @CharlesOfria, and I wrote about this tool back in 2012. <a href="https://zeeelab.github.io/FingerpaintingFitnessLandscapes.js/">Now a version lives online</a>!</p>

<p><img alt="Fingerpainting Opening" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_00.jpg" /></p>

<p>You can watch a population evolve in your browser! Here, we're watching the population neutrally move around the fitness landscape. Note how correlations in the fitness landscape emerge from coalescing lineages.</p>

<p><img alt="Random Walk Animation" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_01.gif" /></p>

<p>By painting in the canvas, you can create regions of higher fitness and watch as the population climbs new peaks.</p>

<p><img alt="Fingerpainting Animation" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_02.gif" /></p>

<p>You can "poke" the population by erasing regions of high fitness, and watch as individuals seemingly scurry to find high fitness regions!</p>

<p><img alt="Poking the Population" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_03.gif" /></p>

<p>We can see what happens if fitness is density dependent, where organisms depress the fitness landscape locally. This is depicted (and mechanistically implemented) by lightening the fitness landscape around each individual.</p>

<p><img alt="Density Fitness" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_04.gif" /></p>

<p>Sexual recombination is a great way to increase variation, but it can also collapse diversity where hybrid organisms "fall off" high fitness regions. We can see that directly in cute fitness landscapes!</p>

<p><img alt="Sexual Reproduction" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_05.gif" /></p>

<p>And one of my favorite fitness landscape phenomenon, survival of the flattest at high mutation rates, is easy to recreate! We can see the population favor the large but less fit region as we crank up the mutation rate.</p>

<p><img alt="Survival of the Flattest" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/fingerpaint_06.gif" /></p>

<p>I hope to keep adding to this (e.g., coevolution!), but please let me know if you have ideas. I'm certainly planning a few lessons in my classes using this, but would love to hear if others are interested!</p>

<p>(Addendum: <a href="https://zeeelab.github.io/FingerpaintingFitnessLandscapes.js/coevolution.html">Co-evolution has been added!</a>)</p>

<h1 id="project-highlight-mfmrocks">Project Highlight: MFM.rocks</h1>

<p><em>Contributed by <a href="https://twitter.com/walpolea">Andrew Walpole</a></em></p>

<p>If you're unfamiliar with Dave Ackley's Movable Feast Machine (MFM), it's a radically different architecture; an entirely new computational stack of hardware and software. An indefinitely-scalable, non-deterministic, tiled grid system meant to free itself from the fragility and constraints of a centralized computational model. (You can learn more about Dr. Ackley's system via <a href="https://t2tile.com/">the T2 Tile Project</a>, where over the last 3+ years he has video-documented his journey of building a hardware-based indefinitely scalable MFM grid.)</p>

<p><a href="https://mfm.rocks">Mfm.rocks</a> is my playground of sorts; an exploratorium for this uncharted computational model. Not quite having the confidence or know-how to dive into Dr. Ackley’s platform directly, the underlying mfm-js library was born out of an insatiable yearn to explore MFM concepts first-hand. And recently I’ve completely rewritten the <a href="https://github.com/walpolea/mfm-js">library (mfm-js 2.0)</a> to be substantially more performant, allowing for bigger grids and more play!</p>

<p>Most notably, the bug that really bit me was the idea that in a robust-first environment, we will need to lean into living-systems concepts – regeneration, organic growth, reproduction, systems-thinking – in order to build software that can resiliently compute within a hostile digital environment. And while I can’t say there is too much useful computing going on as of yet, exploring lower-level living-systems concepts is unlocking ideas. Here are a few of those elemental explorations.</p>

<p><strong>Directionals</strong></p>

<p>Directionals are the name I’ve given to grid travelers that use a sense of understanding directional heading, allowing for the ability to turn left or right or reverse on the grid. Here are a few: Fly, Mosquito, Bird and Wanderer.</p>

<p><img alt="Directionals" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_directionals.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=FLY&amp;atoms=FLY-15x11-15x46-38x33,MOSQUITO-58x15-58x56-70x31-71x53-85x17,BIRD-99x23-120x11,WANDERER-113x51-113x52-113x53-114x51-114x52-114x53-115x51-115x52-115x53">VIEW DIRECTIONAL DEMO</a></p>

<p><strong>Directors</strong></p>

<p>Directors, which can influence the heading of any Directional show how we might create spatial structures that lead a computational workflow.</p>

<p><img alt="Directors" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_directors.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=WANDERER&amp;atoms=DIRECTOR%20S-40x21-40x23-40x27-40x29-40x33-41x18-42x16-44x15,DIRECTOR%20E-41x35-42x37-44x39-46x39-47x39-50x39-54x39-57x39-61x39-65x39,WANDERER-43x23-44x18-44x30-46x35-52x37-53x16-59x38-60x16-66x37-68x17-69x26-69x34,DIRECTOR%20W-49x14-52x14-56x14-60x14-64x14-67x14-69x15-71x16-71x19,DIRECTOR%20N-68x39-70x37-71x22-71x25-71x29-71x32-71x35">VIEW DIRECTOR DEMO</a></p>

<p><strong>Looper</strong></p>

<p>Looper is really a culmination of both concepts, a Directional itself, it loops around leaving a trail of goop and Directors that traps any unsuspecting nearby Directional.</p>

<p><img alt="Looper" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_looper.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=MOSQUITO&amp;atoms=MOSQUITO-28x30-28x31-28x32-28x33-29x30-29x31-29x32-29x33-30x30-30x31-30x32-30x33-31x30-31x31-31x32-31x33,LOOPER-92x32">VIEW LOOPER DEMO</a></p>

<p><strong>OfSwamp</strong></p>

<p>OfSwamp has a Cell-like composure, but it came aobut as an exploration of Environments and Systems. Swampling will loop around and set up a Swamp environment where all OfSwamp types can freely traverse within, while non-swampkind have a much tougher time intruding. I had approached cell building in the past, but through the lens of an environment the concepts used to put this together ended up being very different.</p>

<p><img alt="OfSwamp" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_ofswamp.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=EMPTY&amp;atoms=MOSQUITO-9x31-16x14-21x48-37x55-55x33-69x19-84x30-92x47-109x55-120x31,SWAMPLING-31x26-33x25-33x28-64x43-65x42-95x25">VIEW OFSWAMP DEMO</a></p>

<p><strong>ForkBomb</strong></p>

<p>ForkBomb is sort of the infinite loop of the MFM grid, unabashedly consuming everything in its endless wake.</p>

<p><img alt="ForkBomb" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_forkbomb.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=FORKBOMB&amp;atoms=FORKBOMB-64x32">VIEW FORKBOMB DEMO</a></p>

<p><strong>AntiForkBomb and Sentry</strong></p>

<p>But Sentry, who spits out AntiForkBomb, can easily put a stop to this menace.</p>

<p><img alt="AntiForkBomb" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_antiforkbomb.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=FORKBOMB&amp;atoms=FORKBOMB-22x31,SENTRY-118x30-121x22-123x38">VIEW ANTIFORKBOMB DEMO</a></p>

<p><strong>Living Wall</strong></p>

<p>While some structures that are less robust easily get wiped out by ForkBomb, a Living Wall structure knows how to heal itself a bit as long as there are a few Sentry to keep it from getting entirely overridden.</p>

<p><img alt="Living Wall" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/mfm_livingwall.png" /></p>

<p><a href="https://mfm.rocks/?size=128,64&amp;speed=1&amp;selected=FORKBOMB&amp;atoms=FORKBOMB-22x31,LIVING%20WALL-67x19-67x20-67x21-67x22-67x23-67x24-67x25-67x26-67x27-68x18-68x19-68x20-68x21-68x22-68x23-68x24-68x25-68x26-68x27-68x28-69x17-69x18-69x19-69x20-69x21-69x22-69x23-69x24-69x25-69x26-69x27-69x28-69x29-70x16-70x17-70x18-70x19-70x20-70x21-70x22-70x26-70x27-70x28-70x29-71x16-71x17-71x18-71x19-71x20-71x27-71x28-71x29-72x16-72x17-72x18-72x19-72x27-72x28-72x29-73x16-73x17-73x18-73x19-73x27-73x28-73x29-74x16-74x17-74x18-74x19-74x27-74x28-74x29-75x16-75x17-75x18-75x19-75x26-75x27-75x28-75x29-76x16-76x17-76x18-76x19-76x20-76x21-76x26-76x27-76x28-76x29-77x17-77x18-77x19-77x20-77x21-77x22-77x23-77x24-77x25-77x26-77x27-77x28-78x18-78x19-78x20-78x21-78x22-78x23-78x24-78x25-78x26-78x27-78x28-79x20-79x21-79x22-79x23-79x24-79x25-79x26-79x27-80x21-80x22-80x23-80x24,SENTRY-72x22-74x21-74x24">VIEW LIVING WALL DEMO</a></p>

<p>It’s only been a few months of working with mfm-js 2.0 and I’m only just getting started with this new set of living-systems experiments. I would like to explore more around regeneration, and building computational systems using specialized structures and elemental environments on the grid. There are also more elements and demos available over on the 1.0 version (most notably, SwapWorm and CellBrane) which is still available to check out at https://mfm.rocks/v1/ as well as the game, Dungeon Grid, I built on top of the mfm-js library https://mfm.rocks/v1/game/. The project is open source and I welcome anyone interested in building elements to jump in. If you have any questions you can find me, Andrew Walpole, on <a href="https://twitter.com/walpolea">twitter</a> or <a href="https://discord.gg/rBV6Y6sWNY">the T2 Tile Discord Server</a>!</p>

<h1 id="competition-highlight-evocraft">Competition Highlight: Evocraft</h1>

<p><em>Contributed by <a href="https://twitter.com/enasmel">Elias Najarro</a></em></p>

<p>The purpose of this contest on open-endedness is to highlight the progress in algorithms that can create novel and increasingly complex artefacts. While most experiments in open-ended evolution have so far focused on simple toy domains, we believe Minecraft -with its almost unlimited possibilities- is the <a href="https://arxiv.org/abs/2012.04751">perfect environment</a> to study and compare such approaches. While other popular Minecraft competitions, like MineRL, have an agent-centric focus, in this competition the goal is to directly evolve Minecraft builds.</p>

<p>To facilitate the development of submissions, we provide the <a href="https://github.com/real-itu/Evocraft-py">EvoCraft API</a>: a python interface to Minecraft. EvoCraft is implemented as a mod for Minecraft that allows clients to manipulate blocks in a running Minecraft server programmatically through an API. The framework is specifically developed to facilitate experiments in artificial evolution. The competition framework also supports the recently added "redstone" circuit components in Minecraft, which allowed players to build amazing functional structures, such as bridge builders, battle robots, or even complete CPUs. Can an open-ended algorithm running in Minecraft discover similarly complex artefacts automatically? If you have an API feature that you would like to use that is currently missing, feel free to open an issue on the <a href="https://github.com/real-itu/Evocraft-py">GitHub repo</a>.</p>

<p>If you want to get familiar with the notion of open-ended algorithms, this is a good starting point: <a href="https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/">Open-endedness: The last grand challenge you’ve never heard of</a>. </p>

<h1 id="media-review-picture-a-scientist-documentary">Media Review: "Picture A Scientist" documentary</h1>

<p>By Aalok Varma</p>

<p><img alt="Poster for Picure a Scientist" src="https://alife-newsletter.github.io/Newsletter/images_edition_005/picture-a-scientist02-1623430515095.jpg" />

https://www.pictureascientist.com/</p>

<p>It’s well-known nowadays that science is riddled with gender stereotyping and undermining the work of female scientists. So much so that when children are asked to draw a scientist, they mostly draw white men in white lab coats. Gender inequality in science has cost not only the women who couldn’t pursue their passion, but also the scientific endeavour as a whole. “Picture A Scientist” follows some trailblazing women who have not only suffered at the hands of inequality, but have also fought back against it.

I would strongly recommend everyone watch this documentary for many reasons. First, it gives a voice to the women who have been either sexually or emotionally harassed by powerful men. Hearing some of the incidents is moving and is perhaps the best way to understand the ground reality of what it’s like to be a woman in science. Second, it provides statistics to appeal to our logical side. Data, after all, is the currency of scientific discourse, and is powerful enough to convince those who don’t want to rely on anecdotal evidence alone. For instance, Nancy Hopkins at MIT, who was denied extra lab space while her junior male colleagues were given larger lab spaces, went about measuring everyone’s lab spaces and provided concrete data to the administration to prove that there was, indeed, systemic gender inequality. It was only then that the administration at MIT took the problem seriously and put in measures to reduce their inequality footprint.

Lastly, I think the documentary provides new information even to those who may be aware of the problem and also its more insidious sides. For instance, I learnt about a psychological test (called the Implicit Association Test) that demonstrates that even those of us who are acutely aware of gender inequality and consciously put in efforts to combat it suffer from unconscious or implicit biases that contribute to the problem. It made me pause and think about how much more ground we have to cover before we really achieve parity, even if we are committed to the cause.

All this might make you think that the documentary is depressing, which is partly true. However, it is also hopeful, because it showcases the solidarity people are showing in addressing the issue and bringing about lasting change. Do check it out. I think it would be a rewarding watch.</p>

<p>"Picture A Scientist" is currently available for streaming on Netflix.</p>

<h1 id="conference-review-acmieee-hri-human-robot-interaction-conference-2022">Conference Review: ACM/IEEE HRI (Human-Robot Interaction) Conference 2022</h1>

<p><em>Contribution by Imy Khan <a href="https://twitter.com/imy_tk">(@imy_tk)</a></em></p>

<p>The ACM/IEEE HRI (Human-Robot Interaction) Conference is an annual conference on, as the name suggests, all things related to human and robot interaction. Like ALife, HRI brings together a diverse set of researchers: from computer scientists, AI researchers, roboticists, engineers, psychologists, and behavioural and social scientists. As seems to be the way of many conferences at the moment, this year’s conference was run entirely online, originally moving from its intended location of Sapporo, Japan. This is the third time it has moved online, with next year’s conference hopefully being conducted in-person in Stockholm, Sweden. Here’s hoping…!</p>

<p>The virtual conference itself was hosted using Hopin (www.hopin.com): a platform designed for hosting virtual events. This was my first experience using Hopin, with other conferences using platforms like Zoom, Gather.Town, and so on. Unfortunately, this experience was not a particularly good one. While the HRI conference is, traditionally busy, and attempts to pack in a lot of content over the course of the conference, there just seemed to be too much going on, and Hopin’s interface appeared to be quite clunky when navigating between sessions or finding key information. There were many “virtual stages”, running parallel workshops and special sessions along with an industry expo area, but no clear information on precisely what was happening in any of these stages. There was a persistent chat room embedded into the platform, too. While this seems like a good idea to have, it descended into researchers using it promote their workshops, special sessions, or their submissions, rather than a communal forum for discussion. Quite simply, this didn’t work, despite the fact that it probably should have (bring back IRC!). Overall, I don’t think Hopin was a particularly good platform to use, and it made engagement with some parts of the conference quite frustrating. This is, of course, my own personal opinion on the platform (not a reflection on the conference), and others may have really enjoyed the Hopin experience.</p>

<p>Though the conference overall was excellent, with far too many exciting talks to summarise in a single review, the key highlight for me was in Dr. Friederike Eyssel’s keynote - <em>“What’s Social about Social Robots? A Psychological Perspective”</em>. She concluded this talk by talking about research practices in HRI in a post-COVID19 world: that we should recognise that some countries and researchers have bit hit more by (restrictions imposed by) COVID-19 than others and that we should remain sensitive to this when we evaluate their research productivity, research methods, and their outputs. Because of these (ongoing) restrictions, many researchers may not have access to the same tools, methods, or platforms (in this case, complex, autonomous robots), and we should re-evaluate the way that “robot” research is being conducted. This may be of particular interest to researchers in Artificial Life, as it means that the use of simulations or virtual agents may, once again, be valued in these fields where they have, over time, fallen out of favour or have not been granted the space over other methods. So for ALifers who may be interested in expanding their dissemination or research options, it is plausible that the HRI community may be looking for researchers like us to help them give a (semi-)fresh lens to their research.</p>

<p>One interesting standout at this year’s conference was the number, and diversity, of social events on offer. These included virtual laboratory tours (via slides and videos, although a VR-component could have been very cool), a yoga session, a Dungeons &amp; Dragons one-shot campaign, a Judo workshop(!) and a karaoke night, where attendees were asked to partake in karaoke virtually. While I commend the idea, I did not attend that particular event, so I have no idea how well it would have transposed in a virtual setting. Nonetheless, I wanted to make mention of these social events as it is clear that many communities, like ours, are attempting to capture the social component of conferences; and are finding incredibly quirky and creative ways to go about it.</p>

<p>One additional note is that the conference, as I believe it has done for a few years, also offers a “fee waiver” option for first-time attendees, students, or researchers from a selection of socio-economic backgrounds. While many conferences offer reduced/waived fees for the latter two, it was my first time seeing waived fees for first-time attendees. This is a great marketing tool for HRI: expanding the network and grabbing the attention of researchers who may, otherwise, not have been interested in attending, and who may find ways to contribute to the field in the future.</p>

<p>Overall, HRI was a great conference despite the (poor) platform it was hosted on. While I don’t necessarily believe that it would be relevant to all ALifers, it seems like the research methods for HRI research could be swinging back in the direction of simulations and virtual agents. If HRI offer a “fee waiver” option next year (and a virtual option, too), I would encourage ALifers to take a look at attending - and perhaps even finding ways where your current work might fit into the world of human-robot interactions.</p>

<h1 id="results-of-the-fiction-science-contest">Results of the Fiction Science Contest</h1>

<p>by <a href="https://twitter.com/sina_lana">Lana Sinapayen</a></p>

<p>When I first thought of doing the <a href="https://sites.google.com/view/fiction-science/home">Fiction Science Contest</a>, I knew what the goal would be. You know when your code is not running and you find 10 old, unrelated, and so far undetected bugs before solving the real issue? The real bug was only a useful pretext: if you look for problems, you will find them. I wanted to create an occasion for science to find undetected bugs in its commonly accepted assumptions. I had no idea of what topic to choose, but thankfully my biologist colleague was inspired and that is how we came with the idea of fictional viruses hopping from the biological to the artificial world and vice versa. I recruited the famous-but-anonymous neuro-blogger and twitter critic (Neuroskeptic)[https://twitter.com/Neuro_Skeptic] as a 3rd judge and we launched the contest.</p>

<p>We received 11 entries, 1 of which was generated by an AI.

A recurrent topic in many entries was mRNA sequencing. Our participants imagined ways to exploit vulnerabilities in the computers used to analyse data from viruses: as the most obvious entry point of outside information, sequencing was a prime candidate for malicious tinkering. But some entries also wondered if natural evolution could cause feedback loops between computers and biological organisms. And finally, some entries imagined less nefarious motives for cross-domain infection: research!</p>

<p><a href="https://sites.google.com/view/fiction-science/archives">See the ranking and read the entries here.</a></p>

<p>And let us know what you think: far fetched? Plausible? Threatening? Did any of them changed the way you think about a given phenomenon? And of course, if you publish your impressions (blog / twitter / paper...) or have your own story to submit, we'll be glad to add the link to this page. Contact fiction.for.science {at} gmail.com</p>

<p>Finally, congratulations to the winners:</p>

<ul>

<li>

<p>Romain from France for <a href="https://drive.google.com/file/d/1nmVUOpAYcmHb2pgbGvPK9DCVV1zh1zEk/view">"Bio-infection through computer virus heavily suspected"</a>, winner for Prompt 1: First Case of Biological Organism Infected by Computer Virus.  </p>

</li>

<li>

<p>Claus ARANHA and Diego ARANHA (No relation) for <a href="https://drive.google.com/file/d/1iI4gfJmVAiIXGyMvY40lhXTOdjvhBC8L/view">"Nature finds a way"</a>, winner for Prompt 2: Computer Virus Nicknamed 'Akabake' Believed to Have Biological Origins. This submission got the highest score all categories.</p>

</li>

</ul>

<h1 id="upcoming-deadlines">Upcoming Deadlines:</h1>

<ul>

<li><a href="https://www.2022.alife.org/copy-of-special-sessions">ALIFE Workshops</a> -- Check the deadline for each workshop</li>

<li><a href="https://sab2022.sciencesconf.org/resource/page/id/5">Animals to Animats</a> -- May 9th</li>

<li><a href="https://evocraft.life/">Open Ended Evolution Challenge at GECCO2022</a> -- June, 15th</li>

<li><a href="https://virtualcreatures.github.io/">Virtual Creatures Competition</a> -- July, 1st</li>

</ul>

<h1 id="alife-community-podcast-call-for-questions">ALife Community Podcast: Call for Questions</h1>

<p>We are happy to announce that we will be recording the first episode of the ALife Community Podcast in May. Our first guest is due to be the current president of the ISAL board, Dr. Charles Ofria. We are looking for questions from the community to put forth to Dr. Ofria. If there is anything you would like to ask him, please email imytkhan {at} gmail.com with the subject "ALife Podcast Questions", or send a DM on Twitter to <em>Contribution by Imy Khan <a href="https://twitter.com/imy_tk">(@imy_tk)</a></em>

.</p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen {at} gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan {at} gmail.com</p>

</li>

</ul>



]]></description>
 </item> <item>
  <title>The 4th edition of the Alife Newsletter, February 2022</title>
  <link>https://alife-newsletter.github.io/Newsletter/edition_004.html</link>
  <guid>edition_004</guid>
  <pubDate>01 Feb 2022 00:00:00 GMT</pubDate>
<description><![CDATA[
<h1 id="a-word-from-the-team">A word from the team</h1>

<p>For this 4th issue, we are glad to welcome a new member to the ALife Newsletter team: a warm welcome to Katt Walker!</p>

<p>We hope you enjoy the contents!</p>

<p>The Newsletter is distributed by email, and archived on the International Society for Artificial Life's website.</p>

<p>You can subscribe <a href="https://forms.gle/QpQ68xhvSMt4wiv89">here</a>.</p>

<p>Contribute to any section of the next newsletter <a href="https://forms.gle/jv7FdtdbWVTaTFGd9">here</a>!</p>

<p>Lana, Imy, Mitsuyoshi, Claus and Katt.</p>

<div class="toc">

<ul>

<li><a href="#isal-voices-the-2022-virtual-creatures-competition">ISAL Voices: The 2022 Virtual Creatures Competition</a></li>

<li><a href="#paper-learning-sensorimotor-agency-in-cellular-automata">Paper: Learning Sensorimotor Agency in Cellular Automata</a></li>

<li><a href="#report-2nd-workshop-of-the-japanese-society-of-alife">Report: 2nd Workshop of the Japanese Society of Alife</a></li>

<li><a href="#review-interactions-between-learning-and-evolution-ackley-and-littman-1991">Review: Interactions Between Learning and Evolution (Ackley and Littman, 1991)</a></li>

<li><a href="#review-permutation-city">Review: Permutation City</a></li>

<li><a href="#review-of-the-alife-special-issue-at-the-japanese-society-of-ai-journal">Review of the Alife Special issue at the Japanese Society of AI Journal</a></li>

<li><a href="#fiction-science-contest">Fiction Science Contest</a></li>

<li><a href="#upcoming-deadlines">Upcoming Deadlines</a></li>

<li><a href="#alife-project-the-bibites">Alife Project: The bibites</a></li>

<li><a href="#interview-petr-salaba">Interview: Petr Salaba</a></li>

<li><a href="#introduction-of-the-era-board-membership">Introduction of the ERA Board membership</a></li>

<li><a href="#call-for-volunteers">Call for Volunteers</a></li>

</ul>

<h1 id="isal-voices-the-2022-virtual-creatures-competition">ISAL Voices: The 2022 Virtual Creatures Competition</h1>

<p>Since the early 1990’s, virtual creatures have captured the imagination of artists, engineers, philosophers and scientists. Virtual creatures can now be found in our favorite animated movies, the design of useful robots and novel organisms, and the genesis of better explanations of nature and all of its creatures.</p>

<p><strong>Be part of the next generation of virtual creatures, and enter the 2022 Virtual Creatures Competition (VCC)!</strong></p>

<p>The VCC is now soliciting short films (under five minutes) from thinkers, builders, and artists, of their latest simulated artificial lifeforms. Submissions will be judged on their contribution to science (new explanatory theories), engineering (technical achievement), and art (aesthetic appeal). To enter, submit your five-minute film, along with a one page summary, before July 1.</p>

<p><strong>Email submissions to</strong>: caitlin.grasso@uvm.edu</p>

<p><strong>Deadline</strong>: July 1, 2022</p>

<p><strong>Website</strong>: <a href="https://virtualcreatures.github.io">https://virtualcreatures.github.io</a></p>

<p><strong>Organizers</strong>: Caitlin Grasso, Kathryn Walker, Lana Sinapayen, Sam Kriegman.</p>

<h1 id="paper-learning-sensorimotor-agency-in-cellular-automata">Paper: Learning Sensorimotor Agency in Cellular Automata</h1>

<p><strong>Website:</strong> https://developmentalsystems.org/sensorimotor-lenia/ </p>

<p><img alt="Screenshot from the blog" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/inria_lenia.jpg" /></p>

<p><em>by Gautier HAMON, INRIA FLOWERS</em></p>

<p>In this blogpost, we propose an approach enabling to learn self-organizing agents capable of reacting to the perturbations induced by the environment, i.e. robust agents with sensorimotor capabilities. We provide a method based on curriculum learning, on diversity search and on gradient descent over a differentiable CA able to discover the rules leading to the emergence of such creatures.</p>

<h1 id="report-2nd-workshop-of-the-japanese-society-of-alife">Report: 2nd Workshop of the Japanese Society of Alife</h1>

<p><em>by Mikihiro Suda　(suda(at)websci.cs.tsukuba.ac.jp)</em></p>

<p>On 2022-12-06, I participated in the workshop of the Japanese Society of Artificial Life. The purpose of this workshop was to share and discuss a wide range of research on artificial life. In fact, what impressed me the most was the great variety of research fields presented. In the oral presentation session, three researchers gave presentations. I presented my research on human relationships as an ecosystem and extracting keystone relationships from social networks. The other two researchers presented a study on emergence in the legal world from a computational perspective, and a study on wealth distribution in a multi-agent simulation with agents with personalities. Just by looking at the contents of these three presentations, you can see the diversity of research discussed at the workshop.</p>

<p>In addition to the oral presentations, there were also poster sessions and keynote speeches. The poster session used an online communication tool called Gather, where 12 posters were displayed in a user interface that resembled an RPG game. I was impressed by the very cheerful atmosphere of the entire workshop. I think one of the reasons is that there were many young participants, and I was able to see everywhere that the discussions were friendly and active.</p>

<p><img alt="Participants of the workshop together in Gather" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/alifejapan.png" /></p>

<p>Overall, I feel that it was a very meaningful workshop. I am deeply grateful to have been able to participate in such an occasion.</p>

<h1 id="review-interactions-between-learning-and-evolution-ackley-and-littman-1991">Review: Interactions Between Learning and Evolution (Ackley and Littman, 1991)</h1>

<p><em>By Federico Pigozzi, University of Trieste (pigozzife@gmail.com)</em></p>

<p>Link: https://www.gwern.net/docs/reinforcement-learning/1992-ackley.pdf</p>

<p>The authors experiment with a grid-world environment, which rewards agents for eating food and punishes them for dying (either of starvation or being killed by predators). The agent model employs two networks: an evaluation network that predicts the goodness of a state, and an action network that selects the next action. A genetic algorithm evolves the evaluation network against a “survival” fitness function, while a temporal reinforcement learning algorithm learns the action network (over the course of a simulation), using the output of the evaluation network as reward.</p>

<p>The main result is that learning and evolution together were more successful than either alone in producing adaptive populations; the authors attributed the result to the Baldwin effect, by which agents used learning to stay alive while waiting for successful behaviours to be incorporated directly into the genetic code in the form of preferences.</p>

<p>Moreover, the authors found that successful inherited behaviours “shielded” the inherited preferences, allowing for deleterious mutations to accumulate and eventually leading to maladaptations and instability in the population dynamics. While the former result had already been witnessed in simulations, the latter revealed a novelty.</p>

<p>Reason why I liked it: (Effective) adaptation in animals emerges from the interplay between evolved, instinctive traits (e.g., body) and learned, plastic traits (e.g., behaviour). Starting from the seminal study of Hinton and Nowlan (1987), researchers have asked themselves how learning and evolution can extend each other. As a matter of example, we have recently witnessed a surge in robotics papers attempting to learn controllers while evolving morphologies, and it looks a very promising research direction for the future.</p>

<h1 id="review-permutation-city">Review: Permutation City</h1>

<p><em>by Tanner Lund (<a href="https://twitter.com/101010Lund">@101010Lund</a>)</em></p>

<p>Greg Egan asks the question “What counts as life?” in many different ways throughout the course of his 1994 novel Permutation City. In a world where brain copying and approximation is possible for the well-off and where virtual copies of people can live on after the donor’s death, what counts as immortality? Are you alive if you do not have a body? If you cannot age? If you were created outside of the universe you inhabit? If you edit the parts of yourself you don’t like in the “real world”?</p>

<p>Visionary Paul Durham is convinced there is another, more real form of virtual immortality than what brain scans offer, and he claims to have the capital and compute resources to pull it off. He enlists the help of Maria Deluca, an ALife researcher who dabbles in a cloud-based chemistry simulation environment called the Autoverse, to engineer the jewel in his crown. She is conflicted and suspicious, but what Paul wants her to design is too big a dream for her to pass up, even if she’s convinced it couldn’t ever really be run with the limits of modern computing systems. Neither of them fully understands what they are about to create together.</p>

<p>Permutation City expertly weaves philosophy, metaphysics, computer science, biology, and other disciplines into a compelling vision of a future where the pursuit of immortality is tied to the pursuit of artificial life. All of this is neatly explored in a compelling narrative featuring well rounded, believable characters who are not what they appear - neither the “real” humans nor their various digital counterparts. Though at times it is bleak and pessimistic, the book is also beautiful and full of wonder.</p>

<p>If we do ever create artificial life, what will we owe to our creations?</p>

<p>Who will we become?</p>

<h1 id="review-of-the-alife-special-issue-at-the-japanese-society-of-ai-journal">Review of the Alife Special issue at the Japanese Society of AI Journal</h1>

<p><em>by Hiroki Sayama, Binghamton University, SUNY (sayama@binghamton.edu)</em></p>

<p>The most recent issue of the Journal of the Japanese Society for Artificial Intelligence (JSAI Journal) is a special issue featuring ALife, edited by Yasuhiro Hashimoto, Claus Aranha and Mizuki Oka.</p>

<p>Articles are all written in Japanese, but you can still try and check out its contents using machine translation (and also enjoy the gorgeous cover illustration of the issue created by Shun Iwasawa). <a href="https://www.jstage.jst.go.jp/browse/jjsai/37/1/_contents/-char/ja">Read the special issue here</a></p>

<h1 id="fiction-science-contest">Fiction Science Contest</h1>

<p><em>by Lana Sinapayen (<a href="https://twitter/sina_lana">@sina_lana</a>)</em></p>

<p>Deadline: Feb. 28th</p>

<p>Announcing the Fiction Science Contest, an idea contest for scientists and scientifically-minded people!</p>

<p>Can fake discoveries inspire real-world science? We give you fake news, you convince us it could have been true.</p>

<p>Prizes: $100 for the best entry to the first prompt; $100 for the best entry to the second prompt; Special mentions for other excellent entries!</p>

<p>Two prompts: "First Case of Biological Organism Infected by Computer Virus" and "Computer Virus Nicknamed 'Akabake' Believed to Have Biological Origins".</p>

<p>Find the full text prompts and rules at the <a href="https://sites.google.com/view/fiction-science/home">contest webpage</a></p>

<h1 id="upcoming-deadlines">Upcoming Deadlines</h1>

<ul>

<li><a href="https://alife.org/conference/alife-2022/">ALife 2022</a> -- Submission Deadline: March, 1st</li>

<li><a href="https://evocraft.life/">Open Ended Evolution Challenge at GECCO2022</a> -- Submission Deadline: June, 15th</li>

<li><a href="https://virtualcreatures.github.io/">Virtual Creatures Competition</a> -- July, 1st</li>

</ul>

<h1 id="alife-project-the-bibites">Alife Project: The bibites</h1>

<h2 id="introduction-by-the-author">Introduction by the author</h2>

<p><em>by Leo Caussan</em></p>

<p><a href="https://leocaussan.itch.io/the-bibites">The Bibites</a> is an Artificial Life Project that emulates biological processes, physics, and mutation of both phenotypical and behavioral characteristics, resulting in evolution.</p>

<p>The Bibites eat to gain energy, which they must expend to sustain their metabolism, move around, grow, reproduce, and do other things.</p>

<p><img alt="Bibites Feeding on Pellets" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites1.png" /></p>

<p><em>Bibites of different species feeding on plant pellets</em></p>

<p>The Bibites is an evaluation-less simulation, what survives best is what is selected for. The bibites reproduce biologically, expending energy to produce offspring, which may present mutations. This results in natural selection.</p>

<p><img alt="A bibite with an egg" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites2a.png" />

<img alt="A young bibite" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites2b.png" /></p>

<p><em>A bibite with an egg it just laid (left) and the result young bibite that later came out of that egg (right)</em></p>

<p>On death, the bibites release the energy they contain (the energy they used to grow, their stored energy, etc.) is released in the form of meat pellets, which are also a potential food source for the bibites.</p>

<p><img alt="Meat left after a bibite dies" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites3.png" /></p>

<p>However, one of the genes a bibite can mutate is its diet. Basically, it’s a gene that ranges from fully herbivorous to fully carnivorous. Depending on their affinity toward a particular food source, they will be more or less efficient at extracting the energy out of that source, even potentially losing energy if they are incompatible enough.</p>

<p><img alt="Herbivore Bibite" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites4a.png" />

<img alt="Carnivore Bibite" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites4b.png" /></p>

<p><em>Note the different mouthparts between herbivores (left) and carnivores (right)</em></p>

<p>With this possibility, I’ve always wanted predation to develop naturally in the simulation, but never actually managed to see it arise.

That’s why I decided to launch an epic journey to uncover what dynamics are lacking in the simulation in order for predation to be a possible development.

And if a picture is worth a thousand words, here’s a video that must be worth at least a million words. <a href="https://www.youtube.com/watch?v=rPkMoFJNcLA">The Evolution of Predation in a Simulated Ecosystem</a></p>

<p><img alt="The latest Bibites video" src="https://alife-newsletter.github.io/Newsletter/images_edition_004/bibites5.png" /></p>

<h2 id="impressions-by-a-user">Impressions by a User</h2>

<p><em>by Joao Guilherme (twitter: @_joaogui1))</em></p>

<p>The Bibites: Digital Life (or just Bibites) is a very interesting Alife project. The system's main individuals are bibites, virtual cratures capable of movement, reproduction, feeding and evolution. They each have genes, which are passed to their children during reproduction, and "brains", simple neural networks that dictate their behaviour. There are a couple of fruitful ways to interact with the project, among them I've done 2:  Watching the youtube videos made by the developer and downloading the software and running your own simulations. On the channel one may find videos about the inner workings of the bibites, or about how ecological properties properties arise in the simulation, like herding, altruism, and in the newest series predation.  Playing with the simulations is also greatly rewarding, it's quite flexible and allows one to truly formulate hypothesis and explore their validity.

So overall, while not as mathematically or academically elegant as Lenia, I believe Bibites is a great example of an Alife project, and I recommend other members of the community play with the simulations and interact with the author on twitter and Reddit, to help shape future explorations.</p>

<h1 id="interview-petr-salaba">Interview: Petr Salaba</h1>

<p><em>(1) Could you give us a very quick introduction? Who you are, where you’re from, what your area is, etc?</em></p>

<p>My initial background in theatre and reportage photography. You can find photos of burning cars in the streets of Vancouver and nightlife parties in my portfolio. This has further synthesized into documentary filmmaking with the focus on communication of science. I’m currently finishing my masters at the Film and TV Faculty of the Performing Arts in Prague in the Department of Documentary Film. Besides filmmaking, I work part time at the Czech Technical University where I help to set up and coordinate interdisciplinary projects - for example a collaboration with the Czech National Institute Mental Health about machine learning analysis of sleep patterns for predicting affective mood changes in subliclinal population.</p>

<p><strong>On “ALife”</strong></p>

<p><em>(2) Why is your research Alife-like?</em></p>

<p>As an artist, I’m preparing a documentary film about the general concept of emergence. And as a science networker who dips into interesting topics across areas, I’m drawn into the theory of embodied cognition. The two areas that I’m currently exploring are about dance archeology and AAI. By dance archeology I mean the reconstruction and reinterpretation of the baroque dances that were recorded in symbolic Beauchamp-Feuillet notation. These baroque dances originated at the court of the king Louis XIV and are particularly interesting for the ritualistic and propagandistic effect they had. It is believed that Louis XIV managed to unprecedentedly consolidate power and gain authority through his grandeur ballet performances. I find this as a great example of epistemic significance of embodied cognition where we can observe cognition as a relation between mind, body, space and goal oriented action unfolding in real time. So I’m figuring out how to connect the research from the Laboratory of Chronorobotics at CTU with the analysis of the baroque dance patterns of the ballet dancers from the dance academy.</p>

<p>And AAI stands for animal assisted intervention. I think many people are excited about artificial intelligence because it offers some comparative perspective to our human cognition. But then I find that most of AI research provides a very isolationist perspective on cognition. So ethology in the context of animal assisted psychotherapy and emotional human-animal interaction seems to me as a very low hanging fruit for further research in comparative cognition. More than any formal research, this is a passion that I’m currently exploring as I’m learning how to ride a horse.</p>

<p><em>(3) Why do you do ALife research (especially if you have another main research field)?</em></p>

<p>I like the Alife approach to cognitive sciences because it is very bottom-up. And not only that it might make sense to go the Alife way in order to develop more advanced artificial intelligence, I think it’s also the way to even start communicating about cognition. This is useful for me when I’m thinking about how to talk about artificial intelligence or cognition in my art work. Most art and culture is drawn so much to artificial intelligence as some meaningful “other” that we can compare ourselves to. But I think that’s often intellectually very dishonest. To me it makes more sense to first explore general principles such as emergence or reinforcement feedback loops before we get speculating about human-like behaviour.</p>

<p><em>(4) What is your vision for the future of ALife research?</em></p>

<p>As I foreshadowed earlier I think it’s about the horses. Really. Equine neuroscience is still a very emerging field, yet through our mutual embodied cognition we have managed to gain a lot of utility from these animals for about 8 000 years. I think that the further study of equine cognition could enlighten us in the general principles of how the entire nervous system of an organism functions. We should focus more towards the perspective on cognition that takes into account all the sensory input from the environment and emotional regulation in the limbic system before the final evaluation in the neocortex.</p>

<p><strong>On Research</strong></p>

<p><em>(5) What convinced you to become a researcher?</em></p>

<p>As a filmmaker believing in effective altruism, I’ve been wondering what topics would make the most beneficial impact if I captured them in my films. And so communication of science seemed to me as a potentially impactful path and lots of fun. As I was making research for the development of my films, I realized that if I want to say something meaningful and intellectually honest, I should put a substantial effort into the research phase. This is far from usual in the filmmaking art world as there is rarely any budget for too much prior thinking. And so as I was meeting scientists across the fields, I was gaining horizontal understanding in different areas and I eventually drifted from filmmaking into the field of science development and science networking.  </p>

<p><em>(6) What is something that made you happy about doing research recently?</em></p>

<p>As an artist I’m happy when I read someone else’s research in cognitive sciences and neurobiology that validates some rationality of emotions. I like when something previously seen as wizardry is getting more evidence based ground.</p>

<p><em>(7) When was the last time that you felt like a scientist?</em></p>

<p>I still feel quite a lot like an impostor. But these questions do make me feel a bit like a scientist. On the other hand, I would argue that a toddler figuring out how their fingers move is also a scientist.</p>

<p><strong>General</strong></p>

<p><em>(8) Who are three non-ALIFE scientists/researchers/philosophers/etc that have inspired your work/research, and how?</em></p>

<p>I really enjoyed the documentary film In Silico by Noah Hutton. It’s about the Swiss based Human Brain Project that gained a 1 billion euro grant with the ambition to simulate human consciousness. The film is unusually critical towards the research project and it offers a unique inside view into the problem of over-promise that is rarely reflected in the media. Then I really enjoyed reading the research in psychology by Bessel van der Kolk (the author of The Body Keeps the Score) and Joseph Spinazzola (research on post traumatic stress and animal assisted intervention).</p>

<p><em>(9) What is some advice you would give to your younger-self or new researchers?</em></p>

<p>Don’t worry too much about your status. It’s fine to do embarrassing things if this is what it takes to act honestly. Your integrity is the biggest asset you have.</p>

<p><em>(10) Do you have anywork that you would like to promote?</em></p>

<p>You can watch this 5 minute short film <a href="https://vimeo.com/30485952">"Time Sealed"</a> I made some time ago. It’s about the tintype photography process. I could argue it’s an early Alife film since it’s about how chemistry creates emotional life like representation.</p>

<p><em>(11) Where can people find you? (Twitter/website/etc)</em></p>

<p>Here is my website: <a href="petrsalaba.cz">petrsalaba.cz</a>, until I update it, you can find there my photography and video work.</p>

<h1 id="introduction-of-the-era-board-membership">Introduction of the ERA Board membership</h1>

<p><em>By Imy Khan (<a href="https://twitter.com/imy_tk">@imy_tk</a>)</em></p>

<p>October 2021 saw the introduction of six new ERA (Emerging Researchers in ALife) board members for the 2021/22 term. We’d like to introduce these members to the ALife community. The group spans both PhD and post-PhD members located all across the globe, and represent a diverse set of experiences, expertise, and research interests.</p>

<ul>

<li><strong>General Chair</strong>: Abe Leite - a first-year PhD student at Stony Brook University (USA).</li>

<li><strong>Vice Chair</strong>: Barbora Hudcova - a second-year PhD student at Czech Technical University (Czech Republic)</li>

<li><strong>ISAL Board Representative</strong>: Richard Löffler - a post-doc researcher at the University of Trento. (Italy)</li>

<li><strong>Communications Chair</strong>: Thomas Chen (tbc)</li>

<li><strong>Equity Chair</strong>: Imy Khan - a researcher at the University of Hertfordshire and University of Sussex (UK).</li>

<li><strong>Conference Chair</strong>: Federico Pigozzi - a second-year PhD student at the ​​University of Trieste (Italy)</li>

</ul>

<p>The board is already hard at work making many changes which they will communicate in the next newsletter. If you are interested in joining the ERA group, feel free to join the <a href="https://join.slack.com/t/isalstudents/shared_invite/zt-5t9huf34-bw3sKCY3mlfhEsIg4xcPCg">Slack channel</a></p>

<h1 id="call-for-volunteers">Call for Volunteers</h1>

<ul>

<li>

<p>The newsletter is looking for volunteers to curate content and come up with new ideas! Contact lana.sinapayen@gmail.com</p>

</li>

<li>

<p>The <a href="https://alife.org/encyclopedia/">Encyclopedia of Artificial Life</a> is live and needs contributions!</p>

</li>

<li>

<p>How cool would it be to have an ALife podcast? If you are interested in helping out contact imytkhan@gmail.com</p>

</li>

</ul>



]]></description>
 </item>
</channel>
</rss>
